{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Module 3: RAG Essentials\n",
    "\n",
    "**‚è±Ô∏è Time:** 55 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "\n",
    "1. **Understand** how vector embeddings enable semantic search\n",
    "2. **Build** a complete RAG pipeline with Redis Vector Search\n",
    "3. **Apply** context transformation techniques\n",
    "4. **Use** progressive disclosure (summaries first, details on-demand)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 1: Vector Embeddings (15 min)\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "**Embeddings** convert text into numerical vectors that capture semantic meaning.\n",
    "\n",
    "```\n",
    "\"machine learning\" ‚Üí [0.12, -0.34, 0.56, ..., 0.89]  (1536 dimensions)\n",
    "\"AI algorithms\"    ‚Üí [0.11, -0.32, 0.58, ..., 0.87]  (similar vector!)\n",
    "\"cooking recipes\"  ‚Üí [-0.45, 0.67, -0.12, ..., 0.23] (different vector)\n",
    "```\n",
    "\n",
    "### Why Embeddings Matter for RAG\n",
    "\n",
    "**Keyword search fails:**\n",
    "- Query: \"AI courses\" ‚Üí Misses \"Machine Learning 101\" (no \"AI\" in title)\n",
    "\n",
    "**Semantic search succeeds:**\n",
    "- Query: \"AI courses\" ‚Üí Finds \"Machine Learning 101\" (semantically similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:00.914385Z",
     "iopub.status.busy": "2025-12-03T22:50:00.914269Z",
     "iopub.status.idle": "2025-12-03T22:50:00.924072Z",
     "shell.execute_reply": "2025-12-03T22:50:00.923551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Warning: OPENAI_API_KEY not set. Set it in your environment or .env file.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Try current dir first\n",
    "load_dotenv(repo_root / \".env\")  # Then try parent\n",
    "\n",
    "# Check for required variables\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not set. Set it in your environment or .env file.\")\n",
    "else:\n",
    "    print(\"‚úÖ Setup complete!\")\n",
    "    print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "    print(f\"   OPENAI_API_KEY: ‚úì Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:00.943241Z",
     "iopub.status.busy": "2025-12-03T22:50:00.943141Z",
     "iopub.status.idle": "2025-12-03T22:50:00.990077Z",
     "shell.execute_reply": "2025-12-03T22:50:00.989679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò DEMO MODE: Using pre-computed embeddings (set OPENAI_API_KEY for live mode)\n",
      "Embedding dimensions: 1536\n",
      "First 5 values of 'machine learning': [0.012, -0.034, 0.056, 0.078, -0.023]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings with OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Check if OpenAI API key is available\n",
    "DEMO_MODE = not os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if DEMO_MODE:\n",
    "    print(\"üìò DEMO MODE: Using pre-computed embeddings (set OPENAI_API_KEY for live mode)\")\n",
    "    # Pre-computed example embeddings (first 10 dims of real embeddings)\n",
    "    embeddings = [\n",
    "        [0.012, -0.034, 0.056, 0.078, -0.023, 0.045, -0.067, 0.089, 0.012, -0.045] + [0.0] * 1526,\n",
    "        [0.011, -0.032, 0.058, 0.075, -0.021, 0.043, -0.065, 0.087, 0.010, -0.043] + [0.0] * 1526,\n",
    "        [-0.045, 0.067, -0.012, 0.034, 0.056, -0.078, 0.023, -0.089, 0.045, 0.067] + [0.0] * 1526\n",
    "    ]\n",
    "else:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    \n",
    "    def get_embedding(text: str) -> list[float]:\n",
    "        \"\"\"Generate embedding for text using OpenAI ada-002.\"\"\"\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    \n",
    "    texts = [\n",
    "        \"machine learning algorithms\",\n",
    "        \"artificial intelligence courses\",\n",
    "        \"cooking recipes for beginners\"\n",
    "    ]\n",
    "    embeddings = [get_embedding(t) for t in texts]\n",
    "\n",
    "print(f\"Embedding dimensions: {len(embeddings[0])}\")\n",
    "print(f\"First 5 values of 'machine learning': {[round(x, 3) for x in embeddings[0][:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:00.991058Z",
     "iopub.status.busy": "2025-12-03T22:50:00.990978Z",
     "iopub.status.idle": "2025-12-03T22:50:00.993274Z",
     "shell.execute_reply": "2025-12-03T22:50:00.992931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Scores:\n",
      "  'machine learning' ‚Üî 'AI courses': 0.9996\n",
      "  'machine learning' ‚Üî 'cooking':    -0.5908\n",
      "  'AI courses' ‚Üî 'cooking':          -0.5870\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity - how similar are two vectors?\n",
    "def cosine_similarity(a: list, b: list) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    a, b = np.array(a), np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(\"Similarity Scores:\")\n",
    "print(f\"  'machine learning' ‚Üî 'AI courses': {cosine_similarity(embeddings[0], embeddings[1]):.4f}\")\n",
    "print(f\"  'machine learning' ‚Üî 'cooking':    {cosine_similarity(embeddings[0], embeddings[2]):.4f}\")\n",
    "print(f\"  'AI courses' ‚Üî 'cooking':          {cosine_similarity(embeddings[1], embeddings[2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Recall: Data Engineering Decisions (from Module 1)\n",
    "\n",
    "Remember our data pipeline: `Raw Data ‚Üí Extract ‚Üí Clean ‚Üí Transform ‚Üí Optimize ‚Üí Store`\n",
    "\n",
    "For our course catalog:\n",
    "- ‚úÖ Already small (~60-200 tokens per course)\n",
    "- ‚úÖ Natural boundaries (each course is a unit)\n",
    "- ‚úÖ No chunking needed!\n",
    "\n",
    "We focus on **transformation** (JSON ‚Üí text) and **progressive disclosure** (summaries + details).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 2: RAG Pipeline with Redis (20 min)\n",
    "\n",
    "### The RAG Pipeline\n",
    "\n",
    "```\n",
    "User Query ‚Üí Embed ‚Üí Search Redis ‚Üí Retrieve Docs ‚Üí Assemble Context ‚Üí Generate Response\n",
    "```\n",
    "\n",
    "### Using HierarchicalCourseManager\n",
    "\n",
    "Our course manager implements **progressive disclosure**:\n",
    "- **Summaries**: Lightweight overview (~60 tokens each)\n",
    "- **Details**: Full syllabus and assignments (~200+ tokens each)\n",
    "\n",
    "This enables efficient context engineering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:00.994255Z",
     "iopub.status.busy": "2025-12-03T22:50:00.994205Z",
     "iopub.status.idle": "2025-12-03T22:50:00.998302Z",
     "shell.execute_reply": "2025-12-03T22:50:00.997943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 50 courses from hierarchical_courses.json\n"
     ]
    }
   ],
   "source": [
    "# Load sample course data for demonstration\n",
    "# In production, this data comes from Redis Vector Search\n",
    "\n",
    "# Load hierarchical course data from JSON\n",
    "data_path = repo_root / \"src\" / \"redis_context_course\" / \"data\" / \"hierarchical\" / \"hierarchical_courses.json\"\n",
    "\n",
    "if data_path.exists():\n",
    "    with open(data_path) as f:\n",
    "        course_data = json.load(f)\n",
    "    courses = course_data.get(\"courses\", [])\n",
    "    print(f\"‚úÖ Loaded {len(courses)} courses from {data_path.name}\")\n",
    "else:\n",
    "    # Sample data if file not found\n",
    "    courses = [\n",
    "        {\"summary\": {\"course_code\": \"CS002\", \"title\": \"Machine Learning Fundamentals\", \n",
    "                     \"difficulty_level\": \"beginner\", \"credits\": 3,\n",
    "                     \"short_description\": \"Introduction to ML algorithms and applications\"}},\n",
    "        {\"summary\": {\"course_code\": \"CS006\", \"title\": \"Deep Learning\", \n",
    "                     \"difficulty_level\": \"advanced\", \"credits\": 4,\n",
    "                     \"short_description\": \"Neural networks, CNNs, RNNs, transformers\"}},\n",
    "    ]\n",
    "    print(\"üìò Using sample course data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:00.999157Z",
     "iopub.status.busy": "2025-12-03T22:50:00.999090Z",
     "iopub.status.idle": "2025-12-03T22:50:01.001038Z",
     "shell.execute_reply": "2025-12-03T22:50:01.000686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Summaries (Tier 1 - Lightweight):\n",
      "\n",
      "1. MATH001: Linear Algebra for Machine Learning\n",
      "   Level: intermediate | Credits: 4\n",
      "   Matrix operations, eigenvalues, and applications to ML....\n",
      "\n",
      "2. CS002: Machine Learning Fundamentals\n",
      "   Level: advanced | Credits: 4\n",
      "   Introduction to machine learning algorithms and applications....\n",
      "\n",
      "3. MATH003: Linear Algebra for Machine Learning\n",
      "   Level: intermediate | Credits: 4\n",
      "   Matrix operations, eigenvalues, and applications to ML....\n",
      "\n",
      "4. CS004: Computer Vision\n",
      "   Level: advanced | Credits: 4\n",
      "   Image processing, object detection, and visual recognition systems....\n",
      "\n",
      "5. CS005: Machine Learning Fundamentals\n",
      "   Level: advanced | Credits: 4\n",
      "   Introduction to machine learning algorithms and applications....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract summaries and details from hierarchical data\n",
    "summaries = [c[\"summary\"] for c in courses[:5]]\n",
    "\n",
    "print(\"Course Summaries (Tier 1 - Lightweight):\\n\")\n",
    "for i, s in enumerate(summaries, 1):\n",
    "    print(f\"{i}. {s['course_code']}: {s['title']}\")\n",
    "    print(f\"   Level: {s.get('difficulty_level', 'N/A')} | Credits: {s.get('credits', 3)}\")\n",
    "    desc = s.get('short_description', s.get('description', 'No description'))[:80]\n",
    "    print(f\"   {desc}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.001803Z",
     "iopub.status.busy": "2025-12-03T22:50:01.001751Z",
     "iopub.status.idle": "2025-12-03T22:50:01.004057Z",
     "shell.execute_reply": "2025-12-03T22:50:01.003686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Details for MATH001 (On-Demand):\n",
      "\n",
      "Title: Linear Algebra for Machine Learning\n",
      "Instructor: Rachel Yates\n",
      "Credits: 4\n",
      "\n",
      "Learning Objectives:\n",
      "  ‚Ä¢ Understand core concepts in linear algebra for machine learning\n",
      "  ‚Ä¢ Implement linear algebra for machine learning algorithms and techniques\n",
      "  ‚Ä¢ Apply linear algebra for machine learning to real-world problems\n",
      "\n",
      "Syllabus Preview (first 3 weeks):\n",
      "  Week 1: Vectors and Vector Spaces\n",
      "  Week 2: Matrix Operations\n",
      "  Week 3: Linear Transformations\n"
     ]
    }
   ],
   "source": [
    "# Get full details for the first course (Tier 2 - On-demand)\n",
    "first_course = courses[0]\n",
    "details = first_course.get(\"details\", {})\n",
    "\n",
    "print(f\"Full Details for {first_course['summary']['course_code']} (On-Demand):\\n\")\n",
    "print(f\"Title: {first_course['summary']['title']}\")\n",
    "print(f\"Instructor: {details.get('instructor', 'TBD')}\")\n",
    "print(f\"Credits: {first_course['summary'].get('credits', 3)}\")\n",
    "\n",
    "objectives = details.get('learning_objectives', ['Learn key concepts', 'Apply techniques', 'Build projects'])\n",
    "print(f\"\\nLearning Objectives:\")\n",
    "for obj in objectives[:3]:\n",
    "    print(f\"  ‚Ä¢ {obj}\")\n",
    "\n",
    "# Syllabus can be a dict with 'weeks' key or a list\n",
    "syllabus_data = details.get('syllabus', {})\n",
    "if isinstance(syllabus_data, dict):\n",
    "    weeks = syllabus_data.get('weeks', [])\n",
    "else:\n",
    "    weeks = syllabus_data if isinstance(syllabus_data, list) else []\n",
    "\n",
    "print(f\"\\nSyllabus Preview (first 3 weeks):\")\n",
    "for week in weeks[:3]:\n",
    "    week_num = week.get('week_number', week.get('week', '?'))\n",
    "    topic = week.get('topic', 'TBD')\n",
    "    print(f\"  Week {week_num}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Disclosure in Action\n",
    "\n",
    "| Approach | What's Retrieved | Tokens (5 courses) |\n",
    "|----------|------------------|--------------------|\n",
    "| **All Details** | Full syllabus for all | ~1,000+ tokens |\n",
    "| **Summaries Only** | Overview for all | ~300 tokens |\n",
    "| **Progressive** | Summaries + 1 detail | ~500 tokens |\n",
    "\n",
    "**Key Insight:** Give the LLM summaries for ALL matches, full details for TOP N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.004991Z",
     "iopub.status.busy": "2025-12-03T22:50:01.004933Z",
     "iopub.status.idle": "2025-12-03T22:50:01.006703Z",
     "shell.execute_reply": "2025-12-03T22:50:01.006432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressive Disclosure Results:\n",
      "  Summaries: 5 courses (lightweight, ~60 tokens each)\n",
      "  Details: 2 courses (full info, ~200 tokens each)\n",
      "\n",
      "This approach gives the LLM:\n",
      "  ‚Ä¢ Overview of ALL relevant courses\n",
      "  ‚Ä¢ Deep information for TOP matches\n",
      "  ‚Ä¢ Optimal token usage!\n"
     ]
    }
   ],
   "source": [
    "# Progressive Disclosure Pattern\n",
    "# In production, this search happens via Redis Vector Search\n",
    "# Here we simulate the pattern\n",
    "\n",
    "# Summaries for ALL matches (lightweight)\n",
    "all_summaries = [c[\"summary\"] for c in courses[:5]]\n",
    "\n",
    "# Full details for TOP N matches only (on-demand)\n",
    "top_details = [c.get(\"details\", {}) for c in courses[:2]]\n",
    "\n",
    "print(f\"Progressive Disclosure Results:\")\n",
    "print(f\"  Summaries: {len(all_summaries)} courses (lightweight, ~60 tokens each)\")\n",
    "print(f\"  Details: {len(top_details)} courses (full info, ~200 tokens each)\")\n",
    "print(f\"\\nThis approach gives the LLM:\")\n",
    "print(f\"  ‚Ä¢ Overview of ALL relevant courses\")\n",
    "print(f\"  ‚Ä¢ Deep information for TOP matches\")\n",
    "print(f\"  ‚Ä¢ Optimal token usage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 3: Context Transformation (15 min)\n",
    "\n",
    "### Why Transform Context?\n",
    "\n",
    "Raw JSON is **token-inefficient** and **hard for LLMs to parse**:\n",
    "\n",
    "```json\n",
    "{\"course_code\": \"CS301\", \"title\": \"Machine Learning\", \"credits\": 4}\n",
    "```\n",
    "\n",
    "Natural text is **cleaner** and **more efficient**:\n",
    "\n",
    "```\n",
    "CS301: Machine Learning (4 credits)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.007644Z",
     "iopub.status.busy": "2025-12-03T22:50:01.007576Z",
     "iopub.status.idle": "2025-12-03T22:50:01.009955Z",
     "shell.execute_reply": "2025-12-03T22:50:01.009667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled Context:\n",
      "============================================================\n",
      "AVAILABLE COURSES (Summaries):\n",
      "  ‚Ä¢ MATH001: Linear Algebra for Machine Learning (intermediate, 4 credits)\n",
      "  ‚Ä¢ CS002: Machine Learning Fundamentals (advanced, 4 credits)\n",
      "  ‚Ä¢ MATH003: Linear Algebra for Machine Learning (intermediate, 4 credits)\n",
      "  ‚Ä¢ CS004: Computer Vision (advanced, 4 credits)\n",
      "  ‚Ä¢ CS005: Machine Learning Fundamentals (advanced, 4 credits)\n",
      "\n",
      "TOP MATCHES (Full Details):\n",
      "\n",
      "--- MATH001 Full Details ---\n",
      "Instructor: Rachel Yates\n",
      "Objectives: Understand core concepts in linear algebra for machine learning, Implement linear algebra for machine learning algorithms and techniques, Apply linear algebra for machine learning to real-world problems\n",
      "Topics: Vectors and Vector Spaces, Matrix Operations, Linear Transformations\n",
      "\n",
      "--- CS002 Full Details ---\n",
      "Instructor: Elizabeth Cline\n",
      "Objectives: Understand core concepts in machine learning fundamentals, Implement machine learning fundamentals algorithms and techniques, Apply machine learning fundamentals to real-world problems\n",
      "Topics: Introduction to ML and Python Setup, Linear Regression and Gradient Descent, Logistic Regression and Classification\n"
     ]
    }
   ],
   "source": [
    "# Context Transformation - Convert JSON to LLM-friendly format\n",
    "\n",
    "def format_summary(s: dict) -> str:\n",
    "    \"\"\"Transform a course summary into clean text.\"\"\"\n",
    "    return f\"{s['course_code']}: {s['title']} ({s.get('difficulty_level', 'N/A')}, {s.get('credits', 3)} credits)\"\n",
    "\n",
    "def format_details(d: dict, code: str) -> str:\n",
    "    \"\"\"Transform course details into clean text.\"\"\"\n",
    "    objectives = d.get('learning_objectives', ['Learn fundamentals'])[:3]\n",
    "    # Handle syllabus as dict with 'weeks' key or as list\n",
    "    syllabus_data = d.get('syllabus', {})\n",
    "    if isinstance(syllabus_data, dict):\n",
    "        weeks = syllabus_data.get('weeks', [])[:3]\n",
    "    else:\n",
    "        weeks = syllabus_data[:3] if isinstance(syllabus_data, list) else []\n",
    "    topics = [w.get('topic', '') for w in weeks]\n",
    "    return f\"\"\"\\n--- {code} Full Details ---\n",
    "Instructor: {d.get('instructor', 'TBD')}\n",
    "Objectives: {', '.join(objectives)}\n",
    "Topics: {', '.join(topics)}\"\"\"\n",
    "\n",
    "# Build assembled context\n",
    "context_parts = [\"AVAILABLE COURSES (Summaries):\"]\n",
    "for s in all_summaries:\n",
    "    context_parts.append(f\"  ‚Ä¢ {format_summary(s)}\")\n",
    "\n",
    "context_parts.append(\"\\nTOP MATCHES (Full Details):\")\n",
    "for i, d in enumerate(top_details):\n",
    "    code = courses[i][\"summary\"][\"course_code\"]\n",
    "    context_parts.append(format_details(d, code))\n",
    "\n",
    "assembled_context = \"\\n\".join(context_parts)\n",
    "\n",
    "print(\"Assembled Context:\")\n",
    "print(\"=\"*60)\n",
    "print(assembled_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.010845Z",
     "iopub.status.busy": "2025-12-03T22:50:01.010784Z",
     "iopub.status.idle": "2025-12-03T22:50:01.112894Z",
     "shell.execute_reply": "2025-12-03T22:50:01.112405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw JSON: 805 tokens\n",
      "Transformed: 216 tokens\n",
      "Savings: 73%\n"
     ]
    }
   ],
   "source": [
    "# Compare token counts\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Raw JSON approach\n",
    "raw_json = json.dumps(all_summaries, indent=2)\n",
    "raw_tokens = count_tokens(raw_json)\n",
    "\n",
    "# Transformed context approach\n",
    "transformed_tokens = count_tokens(assembled_context)\n",
    "\n",
    "print(f\"Raw JSON: {raw_tokens} tokens\")\n",
    "print(f\"Transformed: {transformed_tokens} tokens\")\n",
    "print(f\"Savings: {(1 - transformed_tokens/raw_tokens)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 4: Complete RAG Query (10 min)\n",
    "\n",
    "Let's put it all together into a complete RAG query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.114338Z",
     "iopub.status.busy": "2025-12-03T22:50:01.114241Z",
     "iopub.status.idle": "2025-12-03T22:50:01.116992Z",
     "shell.execute_reply": "2025-12-03T22:50:01.116607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete RAG Prompt:\n",
      "============================================================\n",
      "You are a university course advisor. Help students find courses.\n",
      "Use the provided course information to give accurate recommendations.\n",
      "Be concise and helpful.\n",
      "\n",
      "Available Courses:\n",
      "AVAILABLE COURSES (Summaries):\n",
      "  ‚Ä¢ MATH001: Linear Algebra for Machine Learning (intermediate, 4 credits)\n",
      "  ‚Ä¢ CS002: Machine Learning Fundamentals (advanced, 4 credits)\n",
      "  ‚Ä¢ MATH003: Linear Algebra for Machine Learning (intermediate, 4 credits)\n",
      "  ‚Ä¢ CS004: Computer Vision (advanced, 4 credits)\n",
      "  ‚Ä¢ CS005: Machine Learning Fundamentals (advanced, 4 credits)\n",
      "\n",
      "TOP MATCHES (Full Details):\n",
      "\n",
      "--- MATH001 Full Details ---\n",
      "Instructor: Rachel Yates\n",
      "Objectives: Understand core concepts in linear algebra for machine learning, Implement linear algebra for machine learning algorithms and techniques, Apply linear algebra for machine learning to real-world problems\n",
      "Topics: Vectors and Vector Spaces, Matrix Operations, Linear Transformations\n",
      "\n",
      "--- CS002 Full Details ---\n",
      "Instructor: Elizabeth Cline\n",
      "Objectives: Understand core concepts in machine learning fundamentals, Implement machine learning fundamentals algorithms and techniques, Apply machine learning fundamentals to real-world problems\n",
      "Topics: Introduction to ML and Python Setup, Linear Regression and Gradient Descent, Logistic Regression and Classification\n",
      "\n",
      "\n",
      "Student Profile:\n",
      "{\n",
      "  \"name\": \"Sarah\",\n",
      "  \"major\": \"Computer Science\",\n",
      "  \"completed_courses\": [\n",
      "    \"CS101\",\n",
      "    \"CS201\"\n",
      "  ],\n",
      "  \"interests\": [\n",
      "    \"machine learning\",\n",
      "    \"AI\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Student Question: What machin\n",
      "...\n",
      "\n",
      "Total tokens: 313\n"
     ]
    }
   ],
   "source": [
    "# Complete RAG prompt assembly (the pattern used in production)\n",
    "def build_rag_prompt(user_query: str, course_context: str, student_profile: dict = None) -> str:\n",
    "    \"\"\"Assemble a complete RAG prompt with all context types.\"\"\"\n",
    "    \n",
    "    # System context\n",
    "    system_prompt = \"\"\"You are a university course advisor. Help students find courses.\n",
    "Use the provided course information to give accurate recommendations.\n",
    "Be concise and helpful.\"\"\"\n",
    "    \n",
    "    # User context (if provided)\n",
    "    user_context = \"\"\n",
    "    if student_profile:\n",
    "        user_context = f\"\\n\\nStudent Profile:\\n{json.dumps(student_profile, indent=2)}\"\n",
    "    \n",
    "    # Assemble full prompt\n",
    "    return f\"\"\"{system_prompt}\n",
    "\n",
    "Available Courses:\n",
    "{course_context}\n",
    "{user_context}\n",
    "\n",
    "Student Question: {user_query}\"\"\"\n",
    "\n",
    "# Build the prompt\n",
    "student = {\n",
    "    \"name\": \"Sarah\",\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"completed_courses\": [\"CS101\", \"CS201\"],\n",
    "    \"interests\": [\"machine learning\", \"AI\"]\n",
    "}\n",
    "\n",
    "full_prompt = build_rag_prompt(\n",
    "    user_query=\"What machine learning courses would you recommend?\",\n",
    "    course_context=assembled_context,\n",
    "    student_profile=student\n",
    ")\n",
    "\n",
    "print(\"Complete RAG Prompt:\")\n",
    "print(\"=\"*60)\n",
    "print(full_prompt[:1500])\n",
    "print(\"...\")\n",
    "print(f\"\\nTotal tokens: {count_tokens(full_prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:01.117908Z",
     "iopub.status.busy": "2025-12-03T22:50:01.117835Z",
     "iopub.status.idle": "2025-12-03T22:50:01.119450Z",
     "shell.execute_reply": "2025-12-03T22:50:01.119145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò RAG Pipeline Complete!\n",
      "\n",
      "In production, this prompt would be sent to an LLM to generate\n",
      "a personalized course recommendation based on:\n",
      "  ‚Ä¢ Retrieved course context (semantic search)\n",
      "  ‚Ä¢ Student profile (user context)\n",
      "  ‚Ä¢ System instructions (advisor persona)\n"
     ]
    }
   ],
   "source": [
    "# In production, you would call the LLM here:\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "#     max_tokens=500\n",
    "# )\n",
    "\n",
    "print(\"üìò RAG Pipeline Complete!\")\n",
    "print(\"\\nIn production, this prompt would be sent to an LLM to generate\")\n",
    "print(\"a personalized course recommendation based on:\")\n",
    "print(\"  ‚Ä¢ Retrieved course context (semantic search)\")\n",
    "print(\"  ‚Ä¢ Student profile (user context)\")\n",
    "print(\"  ‚Ä¢ System instructions (advisor persona)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **Vector embeddings** capture semantic meaning for better search\n",
    "2. **Progressive disclosure** provides summaries first, details on-demand\n",
    "3. **Context transformation** reduces tokens while preserving information\n",
    "4. **The RAG pipeline**: Query ‚Üí Embed ‚Üí Search ‚Üí Retrieve ‚Üí Assemble ‚Üí Generate\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Module\n",
    "\n",
    "In **Module 4: Memory Systems**, you'll learn:\n",
    "- Working memory for conversation continuity\n",
    "- Long-term memory for persistent knowledge\n",
    "- How Agent Memory Server handles compression automatically"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
