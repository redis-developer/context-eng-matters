{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fab7a26bf5c3a5",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Module 3: Chunking and Data Modeling for RAG\n",
    "\n",
    "## From Basic RAG to Production-Ready Knowledge Bases\n",
    "\n",
    "In Module 2, you built a working RAG system with hierarchical search. Now you'll learn the critical engineering decisions that separate toy demos from production systems: **when and how to chunk your data**.\n",
    "\n",
    "**The Critical Question:** Does my data need chunking?\n",
    "\n",
    "This module teaches you that **chunking is a design choice, not a default step**. Just like database schema design, how you structure your knowledge base dramatically affects retrieval quality, token efficiency, and system performance.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**1. The \"Don't Chunk\" Strategy:**\n",
    "- When whole-document embedding is the right choice\n",
    "- Why structured records (courses, products, FAQs) often don't need chunking\n",
    "- How to recognize natural retrieval boundaries in your data\n",
    "\n",
    "**2. When Chunking Helps:**\n",
    "- Document types that benefit from chunking (research papers, long-form content)\n",
    "- Research-backed insights: \"Lost in the Middle\", \"Context Rot\"\n",
    "- How chunking improves retrieval precision\n",
    "\n",
    "**3. Chunking Strategies:**\n",
    "- Document-based (structure-aware): Split by sections/headers\n",
    "- Fixed-size (token-based): Using LangChain's RecursiveCharacterTextSplitter\n",
    "- Semantic (meaning-based): Using embeddings to detect topic shifts\n",
    "- Trade-offs and decision framework\n",
    "\n",
    "**4. Data Modeling for RAG:**\n",
    "- The hierarchical pattern: summaries + details\n",
    "- Engineering workflow: Extract â†’ Clean â†’ Transform â†’ Optimize â†’ Store\n",
    "- Real-world examples with Redis University course catalog\n",
    "\n",
    "**â±ï¸ Estimated Time:** 60-75 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Module 2: RAG Fundamentals and Implementation\n",
    "- Redis 8 running locally with course data loaded\n",
    "- OpenAI API key set\n",
    "- Understanding of vector embeddings and semantic search\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c04ea493c9b4a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a9f0372e941e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment variables loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Handle both running from workshop/ directory and from project root\n",
    "if Path.cwd().name == \"workshop\":\n",
    "    project_root = Path.cwd().parent\n",
    "else:\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables from project root\n",
    "env_path = project_root / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\"\"âš ï¸  Missing required environment variables: {', '.join(missing_vars)}\n",
    "\n",
    "Please create a .env file with:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "REDIS_URL=redis://localhost:6379\n",
    "\"\"\")\n",
    "    sys.exit(1)\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "print(\"âœ… Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d320da647edaf123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dependencies loaded\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import redis\n",
    "import tiktoken\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Import hierarchical components (from Module 2)\n",
    "from redis_context_course.hierarchical_manager import HierarchicalCourseManager\n",
    "from redis_context_course.hierarchical_context import HierarchicalContextAssembler\n",
    "\n",
    "# Initialize\n",
    "hierarchical_manager = HierarchicalCourseManager(redis_client=redis.from_url(REDIS_URL, decode_responses=True))\n",
    "context_assembler = HierarchicalContextAssembler()\n",
    "redis_client = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Token counter\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "print(\"âœ… Dependencies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2efd2fd5842a5e9",
   "metadata": {},
   "source": [
    "## Part 1: Data Modeling - The Foundation of RAG Quality\n",
    "\n",
    "### The Critical First Question: What is My Natural Retrieval Unit?\n",
    "\n",
    "Before thinking about chunking, ask: **\"What is the natural unit of information I want to retrieve?\"**\n",
    "\n",
    "This is similar to database design - you wouldn't store all customer data in one row, and you shouldn't embed all document content in one vector without thinking about retrieval patterns.\n",
    "\n",
    "**Examples of Natural Retrieval Units:**\n",
    "\n",
    "| Domain | Natural Unit | Why |\n",
    "|--------|-------------|-----|\n",
    "| **Course Catalog** | Individual course | Each course is self-contained, complete |\n",
    "| **Product Catalog** | Individual product | All product info should be retrieved together |\n",
    "| **FAQ Database** | Question + Answer pair | Q&A is an atomic unit |\n",
    "| **Research Papers** | Section or paragraph | Different sections answer different queries |\n",
    "| **Legal Contracts** | Clause or section | Need clause-level precision |\n",
    "| **Support Tickets** | Individual ticket | Single issue with context |\n",
    "\n",
    "Let's see this in practice with our course catalog:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5125abde3b3ad",
   "metadata": {},
   "source": [
    "### Example: Course Catalog - A Natural Retrieval Unit\n",
    "\n",
    "Let's examine a single course to understand why it's already an optimal retrieval unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b763338dc9b9e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:24:29 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "09:24:29 redisvl.index.index INFO   Index already exists, not overwriting.\n",
      "09:24:29 redis_context_course.hierarchical_manager INFO   Created summary index: course_summaries\n",
      "09:24:29 redis_context_course.hierarchical_manager INFO   Found 3 course summaries for query: programming courses\n",
      "ðŸ“š Sample Course: CS003\n",
      "================================================================================\n",
      "Title: Programming Fundamentals with C++\n",
      "Department: Computer Science\n",
      "Level: beginner\n",
      "Credits: 3\n",
      "Instructor: Angie Henderson\n",
      "\n",
      "Description:\n",
      "Core programming concepts using C++ for beginners.\n",
      "\n",
      "Prerequisites: None\n",
      "Tags: programming, c++, beginner, fundamentals, systems\n",
      "================================================================================\n",
      "\n",
      "Token count: 39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a sample course to analyze using search\n",
    "sample_courses = await hierarchical_manager.search_summaries(\n",
    "    query=\"programming courses\", limit=3\n",
    ")\n",
    "sample_course = sample_courses[0]  # Get first course\n",
    "\n",
    "# Generate embedding text if not present\n",
    "if not sample_course.embedding_text:\n",
    "    sample_course.generate_embedding_text()\n",
    "\n",
    "# Display the course summary\n",
    "print(f\"\"\"ðŸ“š Sample Course: {sample_course.course_code}\n",
    "{'=' * 80}\n",
    "Title: {sample_course.title}\n",
    "Department: {sample_course.department}\n",
    "Level: {sample_course.difficulty_level.value}\n",
    "Credits: {sample_course.credits}\n",
    "Instructor: {sample_course.instructor}\n",
    "\n",
    "Description:\n",
    "{sample_course.short_description}\n",
    "\n",
    "Prerequisites: {', '.join(sample_course.prerequisite_codes) if sample_course.prerequisite_codes else 'None'}\n",
    "Tags: {', '.join(sample_course.tags) if sample_course.tags else 'None'}\n",
    "{'=' * 80}\n",
    "\n",
    "Token count: {count_tokens(sample_course.embedding_text)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0c2bc03a500fb",
   "metadata": {},
   "source": [
    "### Analysis: Why Courses Don't Need Chunking\n",
    "\n",
    "**Semantic Completeness:** âœ… Each course is self-contained\n",
    "- All information about the course is in one record\n",
    "- No cross-references to other sections\n",
    "- Natural boundary exists (one course = one retrieval unit)\n",
    "\n",
    "**Query Patterns:** âœ… Users ask about specific courses or course types\n",
    "- \"What machine learning courses are available?\"\n",
    "- \"Tell me about CS016\"\n",
    "- \"What are the prerequisites for RU102JS?\"\n",
    "\n",
    "**Retrieval Precision:** âœ… Whole-course embedding maximizes relevance\n",
    "- When a user asks about a course, they need ALL the information\n",
    "- Splitting would fragment related information (e.g., separating prerequisites from description)\n",
    "- Each course is already the optimal retrieval unit\n",
    "\n",
    "**Token Efficiency:** âœ… Courses are reasonably sized (~150-200 tokens each)\n",
    "- Not too large (no wasted context)\n",
    "- Not too small (no fragmentation)\n",
    "\n",
    "**Decision:** âŒ **Don't chunk course data** - it's already optimally structured!\n",
    "\n",
    "This is the **\"don't chunk\" strategy** - a valid and often optimal choice for structured records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9ef0558e87e03",
   "metadata": {},
   "source": [
    "### The Hierarchical Pattern: A Better Data Model\n",
    "\n",
    "Instead of chunking, we use a **hierarchical pattern** with two tiers:\n",
    "\n",
    "**Tier 1: Summaries (Lightweight)**\n",
    "- Searchable, compact course overviews\n",
    "- Stored in vector index for fast retrieval\n",
    "- ~150-200 tokens each\n",
    "\n",
    "**Tier 2: Details (On-Demand)**\n",
    "- Full course information with all fields\n",
    "- Retrieved only when needed\n",
    "- Stored as plain Redis keys (not in vector index)\n",
    "\n",
    "This is **data modeling**, not chunking - we're structuring data for optimal retrieval patterns.\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10899a005e07b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:24:50 redis_context_course.hierarchical_manager INFO   Hierarchical search: 'beginner programming courses' (summaries=5, details=3)\n",
      "09:24:52 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "09:24:52 redis_context_course.hierarchical_manager INFO   Found 5 course summaries for query: beginner programming courses\n",
      "09:24:52 redis_context_course.hierarchical_manager INFO   Fetched 3 course details\n",
      "09:24:52 redis_context_course.hierarchical_manager INFO   Hierarchical search complete: 5 summaries, 3 details\n",
      "ðŸ” Query: \"beginner programming courses\"\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Tier 1: Summary Results (5 courses)\n",
      "\n",
      "1. CS001: Introduction to Programming with Python (DifficultyLevel.BEGINNER)\n",
      "2. CS002: Web Development Fundamentals (DifficultyLevel.BEGINNER)\n",
      "3. CS003: Programming Fundamentals with C++ (DifficultyLevel.BEGINNER)\n",
      "4. CS012: Machine Learning Fundamentals (DifficultyLevel.ADVANCED)\n",
      "5. CS006: Web Development (DifficultyLevel.INTERMEDIATE)\n",
      "\n",
      "================================================================================\n",
      "ðŸ“„ Tier 2: Detailed Information (top 3 courses)\n",
      "\n",
      "\n",
      "CS001: Introduction to Programming with Python\n",
      "Department: Computer Science | Credits: 3\n",
      "Prerequisites: None\n",
      "\n",
      "Description: Learn programming fundamentals using Python for beginners. This course introduces students to computational thinking, problem-solving, and programming basics. No prior experience required. Students wi...\n",
      "\n",
      "\n",
      "CS002: Web Development Fundamentals\n",
      "Department: Computer Science | Credits: 3\n",
      "Prerequisites: None\n",
      "\n",
      "Description: Introduction to web programming with HTML, CSS, and JavaScript. This beginner-friendly course teaches students how to build interactive websites from scratch. No prior programming experience required....\n",
      "\n",
      "\n",
      "CS003: Programming Fundamentals with C++\n",
      "Department: Computer Science | Credits: 3\n",
      "Prerequisites: None\n",
      "\n",
      "Description: Core programming concepts using C++ for beginners. This course introduces students to programming fundamentals using C++, focusing on computational thinking, problem-solving, and software development....\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š Context Statistics:\n",
      "- Summaries: 5 courses\n",
      "- Details: 3 courses\n",
      "- Total tokens: 3,486\n",
      "- Retrieval pattern: Hierarchical (summaries + details)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical retrieval example\n",
    "query = \"beginner programming courses\"\n",
    "\n",
    "# Tier 1: Search summaries (fast, lightweight)\n",
    "summaries, details = await hierarchical_manager.hierarchical_search(\n",
    "    query=query,\n",
    "    summary_limit=5,  # Get 5 summary matches\n",
    "    detail_limit=3,   # Fetch full details for top 3\n",
    ")\n",
    "\n",
    "print(f\"\"\"ðŸ” Query: \"{query}\"\n",
    "{'=' * 80}\n",
    "\n",
    "ðŸ“Š Tier 1: Summary Results (5 courses)\n",
    "\"\"\")\n",
    "\n",
    "for i, summary in enumerate(summaries, 1):\n",
    "    print(f\"{i}. {summary.course_code}: {summary.title} ({summary.difficulty_level})\")\n",
    "\n",
    "print(f\"\"\"\n",
    "{'=' * 80}\n",
    "ðŸ“„ Tier 2: Detailed Information (top 3 courses)\n",
    "\"\"\")\n",
    "\n",
    "for detail in details:\n",
    "    prereq_codes = [p.course_code for p in detail.prerequisites] if detail.prerequisites else []\n",
    "    print(f\"\"\"\n",
    "{detail.course_code}: {detail.title}\n",
    "Department: {detail.department} | Credits: {detail.credits}\n",
    "Prerequisites: {', '.join(prereq_codes) if prereq_codes else 'None'}\n",
    "\n",
    "Description: {detail.full_description[:200]}...\n",
    "\"\"\")\n",
    "\n",
    "# Assemble context\n",
    "context = context_assembler.assemble_hierarchical_context(summaries, details, query)\n",
    "context_tokens = count_tokens(context)\n",
    "\n",
    "print(f\"\"\"\n",
    "{'=' * 80}\n",
    "ðŸ“Š Context Statistics:\n",
    "- Summaries: 5 courses\n",
    "- Details: 3 courses\n",
    "- Total tokens: {context_tokens:,}\n",
    "- Retrieval pattern: Hierarchical (summaries + details)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0dbcd5795aedec",
   "metadata": {},
   "source": [
    "**Key Takeaway:** For structured records like courses, the hierarchical pattern (summaries + details) is superior to chunking because it respects natural data boundaries and retrieval patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: When Documents DO Need Chunking\n",
    "\n",
    "Now let's look at a completely different type of data: **long-form documents** with multiple distinct topics.\n",
    "\n",
    "### Example: Research Paper\n",
    "\n",
    "Let's create a sample research paper about Redis vector search optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dc692ca494be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample research paper about Redis vector search\n",
    "research_paper = \"\"\"\n",
    "# Optimizing Vector Search Performance in Redis\n",
    "\n",
    "## Abstract\n",
    "This paper presents a comprehensive analysis of vector search optimization techniques in Redis,\n",
    "examining the trade-offs between search quality, latency, and memory usage. We evaluate multiple\n",
    "indexing strategies including HNSW and FLAT indexes across datasets ranging from 10K to 10M vectors.\n",
    "Our results demonstrate that careful index configuration can improve search latency by up to 10x\n",
    "while maintaining 95%+ recall. We also introduce novel compression techniques that reduce memory\n",
    "usage by 75% with minimal impact on search quality.\n",
    "\n",
    "## 1. Introduction\n",
    "Vector databases have become essential infrastructure for modern AI applications, enabling semantic\n",
    "search, recommendation systems, and retrieval-augmented generation (RAG). Redis, traditionally known\n",
    "as an in-memory data structure store, has evolved to support high-performance vector search through\n",
    "the RediSearch module. However, optimizing vector search performance requires understanding complex\n",
    "trade-offs between multiple dimensions: search quality (recall), query latency, memory usage, and\n",
    "index build time.\n",
    "\n",
    "This paper makes three key contributions: (1) A systematic evaluation of HNSW parameter configurations\n",
    "across different dataset sizes and query patterns, (2) Novel compression techniques that reduce memory\n",
    "footprint while preserving search quality, and (3) Practical recommendations for production deployments\n",
    "based on real-world workload analysis.\n",
    "\n",
    "[... continues for several more pages ...]\n",
    "\n",
    "## 2. Background and Related Work\n",
    "Previous work on vector search optimization has focused primarily on algorithmic improvements to\n",
    "approximate nearest neighbor (ANN) search. Malkov and Yashunin (2018) introduced HNSW (Hierarchical\n",
    "Navigable Small World), which has become the de facto standard for high-dimensional vector search.\n",
    "Johnson et al. (2019) developed FAISS, demonstrating that product quantization can significantly\n",
    "reduce memory usage. More recently, Guo et al. (2020) proposed DiskANN for billion-scale search\n",
    "with SSD-based storage.\n",
    "\n",
    "However, these works primarily focus on standalone vector search systems. Our work specifically\n",
    "addresses the unique challenges of integrating vector search into Redis, a multi-model database\n",
    "that must balance vector search performance with other data structure operations.\n",
    "\n",
    "[... continues ...]\n",
    "\n",
    "## 3. Performance Analysis and Results\n",
    "\n",
    "### 3.1 HNSW Configuration Trade-offs\n",
    "\n",
    "Table 1 shows the performance comparison across different HNSW configurations. As M increases from 16 to 64,\n",
    "we observe significant improvements in recall (0.89 to 0.97) but at the cost of increased latency (2.1ms to 8.7ms)\n",
    "and memory usage (1.2GB to 3.8GB). The sweet spot for most real-world workloads is M=32 with ef_construction=200,\n",
    "which achieves 0.94 recall with 4.3ms latency.\n",
    "\n",
    "Table 1: HNSW Performance Comparison\n",
    "| M  | ef_construction | Recall@10 | Latency (ms) | Memory (GB) | Build Time (min) |\n",
    "|----|-----------------|-----------|--------------|-------------|------------------|\n",
    "| 16 | 100            | 0.89      | 2.1          | 1.2         | 8                |\n",
    "| 32 | 200            | 0.94      | 4.3          | 2.1         | 15               |\n",
    "| 64 | 400            | 0.97      | 8.7          | 3.8         | 32               |\n",
    "\n",
    "The data clearly demonstrates the fundamental trade-off between search quality and resource consumption.\n",
    "For applications requiring high recall (>0.95), the increased latency and memory costs are unavoidable.\n",
    "\n",
    "### 3.2 Mathematical Model\n",
    "\n",
    "The recall-latency trade-off can be modeled as a quadratic function of the HNSW parameters:\n",
    "\n",
    "Latency(M, ef) = Î±Â·MÂ² + Î²Â·ef + Î³\n",
    "\n",
    "Where:\n",
    "- M = number of connections per layer (controls graph connectivity)\n",
    "- ef = size of dynamic candidate list (controls search breadth)\n",
    "- Î±, Î², Î³ = dataset-specific constants (fitted from experimental data)\n",
    "\n",
    "For our e-commerce dataset, we fitted: Î±=0.002, Î²=0.015, Î³=1.2 (RÂ²=0.94)\n",
    "\n",
    "[... continues ...]\n",
    "\n",
    "## 4. Implementation Recommendations\n",
    "\n",
    "Based on our findings, we recommend the following configuration for real-world deployments:\n",
    "\n",
    "```python\n",
    "# Optimal HNSW configuration for balanced performance\n",
    "index_params = {\n",
    "    \"M\": 32,                  # Balance recall and latency\n",
    "    \"ef_construction\": 200,   # Higher quality index\n",
    "    \"ef_runtime\": 100         # Fast search with good recall\n",
    "}\n",
    "```\n",
    "\n",
    "This configuration achieves 0.94 recall with 4.3ms p95 latency, suitable for most real-time applications.\n",
    "\n",
    "## 5. Conclusion\n",
    "Our findings demonstrate that vector search optimization is fundamentally about understanding\n",
    "YOUR specific requirements and constraints. There is no one-size-fits-all configuration.\n",
    "\"\"\"\n",
    "\n",
    "paper_tokens = count_tokens(research_paper)\n",
    "print(f\"\"\"ðŸ“„ Sample Research Paper\n",
    "{'=' * 80}\n",
    "Title: \"Optimizing Vector Search Performance in Redis\"\n",
    "\n",
    "Structure:\n",
    "- Abstract\n",
    "- Introduction\n",
    "- Background and Related Work\n",
    "- Performance Analysis and Results\n",
    "- Implementation Recommendations\n",
    "- Conclusion\n",
    "\n",
    "Token count: {paper_tokens:,}\n",
    "Word count: ~{len(research_paper.split())}\n",
    "{'=' * 80}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7e06337016528",
   "metadata": {},
   "source": [
    "### Analysis: Why This Research Paper NEEDS Chunking\n",
    "\n",
    "Let's compare the course catalog (doesn't need chunking) with the research paper (does need chunking):\n",
    "\n",
    "| Factor | Course Catalog | Research Paper |\n",
    "|--------|---------------|----------------|\n",
    "| **Document Structure** | Single topic per record | Multiple distinct sections |\n",
    "| **Semantic Completeness** | Each course is self-contained | Sections cover different topics and types (text, formulas, charts, etc.) |\n",
    "| **Query Patterns** | \"Show me CS courses\" | \"What compression techniques?\" |\n",
    "| **Optimal Retrieval Unit** | Whole course | Specific section |\n",
    "| **Chunking Decision** | âŒ Don't chunk | âœ… Chunk by section |\n",
    "\n",
    "**Why the research paper needs chunking:**\n",
    "\n",
    "**1. Multiple Distinct Topics:**\n",
    "- Abstract, Introduction, Background, Results, Conclusion each cover different aspects\n",
    "- A query about \"compression techniques\" only needs the relevant section, not the entire paper\n",
    "\n",
    "**2. Retrieval Precision:**\n",
    "- Without chunking: Retrieve entire 1,500-token paper for every query\n",
    "- With chunking: Retrieve only the 200-300 token section that's relevant\n",
    "- Result: 80% reduction in irrelevant context\n",
    "\n",
    "**3. Query-Specific Needs:**\n",
    "\n",
    "| Query | Needs | Without Chunking | With Chunking |\n",
    "|-------|-------|------------------|---------------|\n",
    "| \"What compression techniques?\" | Methodology section | Entire paper (1,500 tokens) | Methodology (300 tokens) |\n",
    "| \"What were recall results?\" | Results + Table | Entire paper (1,500 tokens) | Results section (250 tokens) |\n",
    "| \"How does HNSW work?\" | Background + Formula | Entire paper (1,500 tokens) | Background (200 tokens) |\n",
    "| \"Recommended config?\" | Implementation section | Entire paper (1,500 tokens) | Implementation (150 tokens) |\n",
    "\n",
    "**Impact:** 5-10x reduction in irrelevant context, leading to faster responses and better quality.\n",
    "\n",
    "**ðŸ’¡ Key Insight:** Chunking isn't about fitting in context windows - it's about **data modeling for retrieval**. Just like you wouldn't store all customer data in one database row, you shouldn't embed all document content in one vector when sections serve different purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d079e72743b37",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Research Background - Why Chunking Matters\n",
    "\n",
    "Even with large context windows (128K+ tokens), research shows that **how you structure context matters more than fitting everything in**.\n",
    "\n",
    "### Key Research Findings\n",
    "\n",
    "**1. \"Lost in the Middle\" (Stanford/UC Berkeley, 2023)**\n",
    "\n",
    "*Source: [arXiv:2307.03172](https://arxiv.org/abs/2307.03172)*\n",
    "\n",
    "- LLMs exhibit **U-shaped attention**: high recall at beginning/end, degraded in middle\n",
    "- Happens even in models designed for long contexts\n",
    "- **Implication:** Chunking ensures relevant sections are retrieved and placed prominently, not buried\n",
    "\n",
    "**2. \"Context Rot\" (Chroma Research, 2025)**\n",
    "\n",
    "*Source: [research.trychroma.com/context-rot](https://research.trychroma.com/context-rot)*\n",
    "\n",
    "- Performance degrades as input length increases, even when relevant info is present\n",
    "- **Distractor effect**: Irrelevant content actively hurts model performance\n",
    "- Even 4 distractor documents can significantly degrade output quality\n",
    "- **Implication:** Smaller, focused chunks reduce \"distractor tokens\"\n",
    "\n",
    "**3. Needle in the Haystack (NIAH) Benchmark**\n",
    "\n",
    "*Source: [github.com/gkamradt/LLMTest_NeedleInAHaystack](https://github.com/gkamradt/LLMTest_NeedleInAHaystack)*\n",
    "\n",
    "- Models often fail to retrieve information buried in long context\n",
    "- Performance varies by position (middle is worst)\n",
    "- **Limitation:** Tests lexical retrieval only, not semantic understanding\n",
    "- **Implication:** For structured data, NIAH is irrelevantâ€”each record IS the needle\n",
    "\n",
    "**The Key Insight:**\n",
    "\n",
    "These findings inform design decisions but don't prescribe universal rules:\n",
    "\n",
    "- **Structured records** (courses, products, FAQs): \"Lost in the middle\" doesn't applyâ€”each record is already focused\n",
    "- **Long-form documents** (papers, books): Context rot and positional bias become relevantâ€”chunking helps\n",
    "- **Mixed content**: Real-world data rarely fits neat categoriesâ€”experiment with YOUR data\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Chunking Strategies - Three Approaches\n",
    "\n",
    "Once you've determined your data needs chunking, the next question is: **How should you chunk it?**\n",
    "\n",
    "There's no single \"best\" strategy - the optimal approach depends on YOUR data characteristics and query patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14864605b206341",
   "metadata": {},
   "source": [
    "### Strategy 1: Document-Based Chunking (Structure-Aware)\n",
    "\n",
    "**Concept:** Split documents based on their inherent structure (sections, paragraphs, headings).\n",
    "\n",
    "**Best for:** Structured documents with clear logical divisions (research papers, technical docs, books)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f523c504991979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Document-Based Chunking\n",
    "# Split research paper by sections (using markdown headers)\n",
    "\n",
    "\n",
    "def chunk_by_structure(text: str, separator: str = \"\\n## \") -> List[str]:\n",
    "    \"\"\"Split text by structural markers (e.g., markdown headers).\"\"\"\n",
    "\n",
    "    # Split by headers\n",
    "    sections = text.split(separator)\n",
    "\n",
    "    # Clean and format chunks\n",
    "    chunks = []\n",
    "    for i, section in enumerate(sections):\n",
    "        if section.strip():\n",
    "            # Add header back (except for first chunk which is title)\n",
    "            if i > 0:\n",
    "                chunk = \"## \" + section\n",
    "            else:\n",
    "                chunk = section\n",
    "            chunks.append(chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Apply to research paper\n",
    "structure_chunks = chunk_by_structure(research_paper)\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 1: Document-Based (Structure-Aware) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Number of chunks: {len(structure_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(structure_chunks):\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    # Show first 100 chars of each chunk\n",
    "    preview = chunk[:300].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108caf4be1a606b4",
   "metadata": {},
   "source": [
    "**Strategy 1 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- Respects document structure (sections stay together)\n",
    "- Semantically coherent (each chunk is a complete section)\n",
    "- Easy to implement for structured documents\n",
    "- **Keeps tables, formulas, and code WITH their context**\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- Variable chunk sizes (some sections longer than others)\n",
    "- Requires documents to have clear structure\n",
    "- May create chunks that are still too large\n",
    "\n",
    "ðŸŽ¯ **Best for:**\n",
    "- Research papers with clear sections\n",
    "- Technical documentation with headers\n",
    "- Books with chapters/sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca013174da787352",
   "metadata": {},
   "source": [
    "### Strategy 2: Fixed-Size Chunking (Token-Based)\n",
    "\n",
    "**Concept:** Split text into chunks of a predetermined size (e.g., 512 tokens) with overlap.\n",
    "\n",
    "**Best for:** Unstructured text, quick prototyping, when you need consistent chunk sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70130fcdc66f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Fixed-Size Chunking (Using LangChain)\n",
    "# Industry-standard approach with smart boundary detection\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter with smart boundary detection\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  # Target chunk size in characters\n",
    "    chunk_overlap=100,  # Overlap to preserve context\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # Try these in order\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "print(\"ðŸ”„ Running fixed-size chunking with LangChain...\")\n",
    "print(\"   Trying to split on: paragraphs â†’ sentences â†’ words â†’ characters\\n\")\n",
    "\n",
    "# Apply to research paper\n",
    "fixed_chunks_docs = text_splitter.create_documents([research_paper])\n",
    "fixed_chunks = [doc.page_content for doc in fixed_chunks_docs]\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 2: Fixed-Size (LangChain) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Target chunk size: 800 characters (~200 words)\n",
    "Overlap: 100 characters\n",
    "Number of chunks: {len(fixed_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(fixed_chunks[:5]):  # Show first 5\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    preview = chunk[:100].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\")\n",
    "\n",
    "print(f\"... ({len(fixed_chunks) - 5} more chunks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afda8cda87c128",
   "metadata": {},
   "source": [
    "**Strategy 2 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- **Respects natural boundaries**: Tries paragraphs â†’ sentences â†’ words â†’ characters\n",
    "- Consistent chunk sizes (predictable token usage)\n",
    "- Works on any text (structured or unstructured)\n",
    "- **Doesn't split mid-sentence** (unless absolutely necessary)\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- Ignores document structure (doesn't understand sections)\n",
    "- Can break semantic coherence (may split related content)\n",
    "- Overlap creates redundancy (increases storage/cost)\n",
    "\n",
    "ðŸŽ¯ **Best for:**\n",
    "- Unstructured text (no clear sections)\n",
    "- Quick prototyping and baselines\n",
    "- When consistent chunk sizes are required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d3ece2f9f06b8",
   "metadata": {},
   "source": [
    "### Strategy 3: Semantic Chunking (Meaning-Based)\n",
    "\n",
    "**Concept:** Split text based on semantic similarity using embeddings - create new chunks when topic changes significantly.\n",
    "\n",
    "**How it works:**\n",
    "1. Split text into sentences or paragraphs\n",
    "2. Generate embeddings for each segment\n",
    "3. Calculate similarity between consecutive segments\n",
    "4. Create chunk boundaries where similarity drops (topic shift detected)\n",
    "\n",
    "**Best for:** Dense academic text, legal documents, narratives where semantic boundaries don't align with structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01f496f5384cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Semantic Chunking (Using LangChain)\n",
    "# Industry-standard approach with local embeddings (no API costs!)\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "# Suppress tokenizer warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Initialize local embeddings (no API costs!)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# Create semantic chunker with percentile-based breakpoint detection\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",  # Split at bottom 25% of similarities\n",
    "    breakpoint_threshold_amount=25,  # 25th percentile\n",
    "    buffer_size=1,  # Compare consecutive sentences\n",
    ")\n",
    "\n",
    "print(\"ðŸ”„ Running semantic chunking with LangChain...\")\n",
    "print(\"   Using local embeddings (sentence-transformers/all-MiniLM-L6-v2)\")\n",
    "print(\"   Breakpoint detection: 25th percentile of similarity scores\\n\")\n",
    "\n",
    "# Apply to research paper\n",
    "semantic_chunks_docs = semantic_chunker.create_documents([research_paper])\n",
    "\n",
    "# Extract text from Document objects\n",
    "semantic_chunks = [doc.page_content for doc in semantic_chunks_docs]\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 3: Semantic (LangChain) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Number of chunks: {len(semantic_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(semantic_chunks[:5]):  # Show first 5\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    preview = chunk[:100].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\")\n",
    "\n",
    "if len(semantic_chunks) > 5:\n",
    "    print(f\"... ({len(semantic_chunks) - 5} more chunks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39c7fe9faa9a03",
   "metadata": {},
   "source": [
    "**Strategy 3 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- **Meaning-aware**: Chunks based on topic shifts, not arbitrary boundaries\n",
    "- **Adaptive**: Chunk sizes vary based on content coherence\n",
    "- **Better retrieval**: Each chunk is semantically focused\n",
    "- **Free**: Uses local embeddings (no API costs)\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- Slower processing (requires embedding generation)\n",
    "- Variable chunk sizes (harder to predict token usage)\n",
    "- May not respect document structure (sections, headers)\n",
    "- Requires tuning (threshold, buffer size)\n",
    "\n",
    "ðŸŽ¯ **Best for:**\n",
    "- Dense academic text\n",
    "- Legal documents\n",
    "- Narratives and stories\n",
    "- Content where semantic boundaries don't align with structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d0828e8512bd8",
   "metadata": {},
   "source": [
    "### Comparing Chunking Strategies: Decision Framework\n",
    "\n",
    "Now let's compare all strategies side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cd8dfad49c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'=' * 80}\n",
    "CHUNKING STRATEGY COMPARISON\n",
    "{'=' * 80}\n",
    "\n",
    "Document: Research Paper ({paper_tokens:,} tokens)\n",
    "\n",
    "Strategy              | Chunks | Avg Size | Complexity | Best For\n",
    "--------------------- | ------ | -------- | ---------- | --------\n",
    "Document-Based        | {len(structure_chunks):>6} | {sum(count_tokens(c) for c in structure_chunks) // len(structure_chunks):>8} | Low        | Structured docs\n",
    "Fixed-Size            | {len(fixed_chunks):>6} | {sum(count_tokens(c) for c in fixed_chunks) // len(fixed_chunks):>8} | Low        | Unstructured text\n",
    "Semantic              | {len(semantic_chunks):>6} | {sum(count_tokens(c) for c in semantic_chunks) // len(semantic_chunks):>8} | High       | Dense academic text\n",
    "\n",
    "{'=' * 80}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c058c97c25c9b3",
   "metadata": {},
   "source": [
    "### YOUR Chunking Decision Framework\n",
    "\n",
    "Chunking strategy is a **design choice** that depends on your specific context. There's no universal \"correct\" chunk size.\n",
    "\n",
    "**Step 1: Start with Document Type**\n",
    "\n",
    "| Document Type | Default Approach | Reasoning |\n",
    "|---------------|------------------|----------|\n",
    "| **Structured records** (courses, products, FAQs) | Don't chunk | Natural boundaries already exist |\n",
    "| **Long-form text** (papers, books, docs) | Consider chunking | May need retrieval precision |\n",
    "| **PDFs with visual layout** | Page-level | Preserves tables, figures |\n",
    "| **Code** | Function/class boundaries | Semantic structure matters |\n",
    "\n",
    "**Step 2: Evaluate These Factors**\n",
    "\n",
    "1. **Semantic completeness:** Is each item self-contained?\n",
    "   - âœ… Yes â†’ Don't chunk (preserve natural boundaries)\n",
    "   - âŒ No â†’ Consider chunking strategy\n",
    "\n",
    "2. **Query patterns:** What will users ask?\n",
    "   - Specific facts â†’ Smaller, focused chunks help\n",
    "   - Summaries/overviews â†’ Larger chunks or hierarchical\n",
    "   - Mixed â†’ Consider hierarchical approach\n",
    "\n",
    "3. **Topic density:** How many distinct topics per document?\n",
    "   - Single topic â†’ Whole-document embedding often works\n",
    "   - Multiple distinct topics â†’ Chunking may improve precision\n",
    "\n",
    "**Example Decisions:**\n",
    "\n",
    "| Domain | Data Characteristics | Decision | Why |\n",
    "|--------|---------------------|----------|-----|\n",
    "| **Course Catalog** | Small, self-contained records | **Don't chunk** | Each course is a complete retrieval unit |\n",
    "| **Research Papers** | Multi-section, dense topics | Document-Based | Sections are natural semantic units |\n",
    "| **Support Tickets** | Single issue per ticket | **Don't chunk** | Already at optimal granularity |\n",
    "| **Legal Contracts** | Nested structure, many clauses | Hierarchical | Need both overview and clause-level detail |\n",
    "\n",
    "> ðŸ’¡ **Key Takeaway:** Ask \"What is my natural retrieval unit?\" before deciding on a chunking strategy. For many structured data use cases, the answer is \"don't chunk.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fde7b8f9ea7523",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Advanced Chunking - Three Distinct Document Types\n",
    "\n",
    "The chunking strategies we've covered (document-based, fixed-size, semantic) are foundational. But real-world documents often contain **heterogeneous content** that requires specialized handling.\n",
    "\n",
    "**Important:** Chunking is **subjective and document-dependent**. The optimal strategy depends on:\n",
    "- Document type and structure\n",
    "- Content heterogeneity (text, tables, figures, equations, code)\n",
    "- Query patterns (overview vs. specific facts)\n",
    "- Domain requirements (legal precision, scientific accuracy)\n",
    "- Models being used (embedding model, LLM capabilities)\n",
    "- Performance metrics (retrieval precision, answer quality, latency, cost)\n",
    "\n",
    "Let's examine three distinct document types that require different approaches:\n",
    "\n",
    "1. **Research Papers & Long-Form Documents** (Multimodal Content)\n",
    "2. **Legal Contracts & Clause-Level Documents** (Knowledge Graphs)\n",
    "3. **Transcripts & Meeting Notes** (Speaker-Aware Chunking)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Document Type 1: Research Papers & Long-Form Documents (Multimodal Content)\n",
    "\n",
    "**This category is broad and subjective** - it includes research papers, books, technical manuals, financial reports, even contracts (which we'll discuss separately). The key characteristic is **heterogeneous content types** that require specialized handling.\n",
    "\n",
    "**Why Standard Chunking May Fail:**\n",
    "\n",
    "Research papers and long-form documents contain:\n",
    "- **Text**: Paragraphs, sections, abstracts\n",
    "- **Tables**: Structured data with captions\n",
    "- **Figures and charts**: Visual information with captions\n",
    "- **Mathematical formulas**: Equations with variable definitions\n",
    "- **Code snippets**: Implementation examples\n",
    "- **References**: Citations and bibliographies\n",
    "\n",
    "**Research-Backed Benefits of Chunking:**\n",
    "\n",
    "1. **Token Limit Management** (Anthropic, 2024)\n",
    "   - Even with 200K context windows, focused chunks improve retrieval precision\n",
    "   - Reduces \"distractor tokens\" that hurt model performance\n",
    "\n",
    "2. **Improved Retrieval Precision** (Anthropic Contextual Retrieval, 2024)\n",
    "   - **49-67% reduction in retrieval failures** with proper chunking\n",
    "   - Smaller, focused chunks match queries more precisely\n",
    "\n",
    "3. **Context Preservation** (Industry Best Practice)\n",
    "   - **Chunk overlap (10-20%)** preserves context across boundaries\n",
    "   - Prevents information loss at chunk boundaries\n",
    "\n",
    "4. **Computational Efficiency** (Redis/Virginia Tech, arXiv:2504.02268, 2025)\n",
    "   - Smaller chunks = faster embedding generation\n",
    "   - Reduced memory footprint for vector storage\n",
    "\n",
    "**Chunking Strategies for Long-Form Documents:**\n",
    "\n",
    "**1. Page-Level Chunking**\n",
    "- Split by page boundaries (for PDFs)\n",
    "- Preserves tables, figures, and layout\n",
    "- Best for: Financial reports, legal documents, scanned documents\n",
    "\n",
    "**2. Structure-Aware Chunking (Markdown/HTML)**\n",
    "- Split by headings, sections, chapters\n",
    "- Respects document hierarchy\n",
    "- Best for: Technical documentation, research papers, books\n",
    "\n",
    "**3. Recursive Chunking**\n",
    "- Try progressively smaller separators: paragraphs â†’ sentences â†’ words â†’ characters\n",
    "- LangChain's `RecursiveCharacterTextSplitter` implements this\n",
    "- Best for: Unstructured text, mixed content\n",
    "\n",
    "**4. Semantic Chunking**\n",
    "- Use embeddings to detect topic shifts\n",
    "- Create boundaries where similarity drops\n",
    "- Best for: Dense academic text, narratives\n",
    "\n",
    "**5. Hybrid Approaches**\n",
    "- Combine multiple strategies (e.g., structure-aware + semantic)\n",
    "- Most flexible but more complex\n",
    "- Best for: Complex documents with mixed content types\n",
    "\n",
    "**Chunk Overlap: The Critical Detail**\n",
    "\n",
    "**Why overlap matters:**\n",
    "- Information at chunk boundaries can be lost\n",
    "- Context from previous chunk helps understand current chunk\n",
    "- Prevents fragmentation of related content\n",
    "\n",
    "**Recommended overlap:** 10-20% of chunk size\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "# Without overlap - information loss at boundaries\n",
    "Chunk 1: \"...the HNSW algorithm uses hierarchical layers.\"\n",
    "Chunk 2: \"Each layer contains a subset of nodes...\"\n",
    "# Lost: What does \"each layer\" refer to?\n",
    "\n",
    "# With 20% overlap - context preserved\n",
    "Chunk 1: \"...the HNSW algorithm uses hierarchical layers.\"\n",
    "Chunk 2: \"the HNSW algorithm uses hierarchical layers. Each layer contains a subset of nodes...\"\n",
    "# Preserved: Clear reference to HNSW algorithm\n",
    "```"
   ],
   "id": "b7abdc374a1a3453"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Real-World Example: Analyzing a Research Paper\n",
    "\n",
    "Let's analyze an actual research paper to understand chunking decisions:\n",
    "\n",
    "**Paper:** \"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and Synthetic Data\"\n",
    "**Source:** arXiv:2504.02268 (Redis/Virginia Tech, April 2025)\n",
    "**Length:** 12 pages, ~42,000 characters\n",
    "\n",
    "**Paper Structure:**\n",
    "- Abstract (1 paragraph)\n",
    "- Introduction (2 pages)\n",
    "- Methodology (3 pages with formulas and tables)\n",
    "- Experimental Results (3 pages with charts and tables)\n",
    "- Discussion & Conclusion (2 pages)\n",
    "- References (1 page)\n",
    "\n",
    "**Content Types:**\n",
    "- Text (paragraphs, sections)\n",
    "- Mathematical formulas (cache hit rate calculations)\n",
    "- Tables (13 embedding models compared)\n",
    "- Figures (bar charts showing performance)\n",
    "- Code snippets (implementation examples)\n",
    "\n",
    "**Critical Question: Is chunking the ONLY way to process this paper?**\n",
    "\n",
    "**Answer: NO.** There are multiple approaches:\n",
    "\n",
    "**Option 1: Hierarchical Retrieval (No Chunking)**\n",
    "- Store abstract/summary as searchable vector\n",
    "- Store full paper as plain text (Redis key)\n",
    "- Retrieve summary first, fetch full paper if needed\n",
    "- **Pros:** Simple, preserves document integrity\n",
    "- **Cons:** May retrieve entire paper when only one section is needed\n",
    "\n",
    "**Option 2: Section-Based Chunking (Structure-Aware)**\n",
    "- Chunk by sections: Abstract, Introduction, Methodology, Results, Discussion\n",
    "- Each section is a separate vector\n",
    "- **Pros:** Respects document structure, semantically coherent\n",
    "- **Cons:** Variable chunk sizes, may still be too large\n",
    "\n",
    "**Option 3: Hybrid Approach (Recommended)**\n",
    "- **Level 1:** Abstract/summary (searchable vector)\n",
    "- **Level 2:** Section-level chunks (Introduction, Methodology, Results, etc.)\n",
    "- **Level 3:** Full paper (plain text, on-demand)\n",
    "- **Pros:** Flexible retrieval, supports both overview and specific queries\n",
    "- **Cons:** More complex to implement\n",
    "\n",
    "**Option 4: Multimodal RAG**\n",
    "- Extract tables and figures separately\n",
    "- Use vision models to process charts/graphs\n",
    "- Chunk text separately from visual content\n",
    "- **Pros:** Handles multimodal content properly\n",
    "- **Cons:** Requires vision models, more complex\n",
    "\n",
    "**Expert Recommendation:** **Option 3 (Hybrid)** for this paper because:\n",
    "- Supports both \"What is this paper about?\" (Level 1) and \"What compression techniques were used?\" (Level 2)\n",
    "- Balances simplicity with retrieval precision\n",
    "- Can fall back to full paper (Level 3) if needed"
   ],
   "id": "23e90434abf7470f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Handling Multimodal Content: Tables, Figures, Equations, Code\n",
    "\n",
    "**The Challenge:** Standard text chunking breaks multimodal content.\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "**1. Tables**\n",
    "\n",
    "**âŒ Don't:**\n",
    "- Split tables across chunks\n",
    "- Separate table from caption\n",
    "- Lose column headers\n",
    "\n",
    "**âœ… Do:**\n",
    "- Chunk table WITH caption and explanation\n",
    "- Preserve table structure (use markdown or HTML)\n",
    "- Add metadata: `{\"content_type\": \"table\", \"table_title\": \"...\"}`\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "chunk = {\n",
    "    \"text\": \"\"\"\n",
    "    Table 1: Embedding Model Performance Comparison\n",
    "\n",
    "    | Model | Dimensions | Hit Rate | Latency |\n",
    "    |-------|-----------|----------|---------|\n",
    "    | text-embedding-3-small | 1536 | 0.85 | 12ms |\n",
    "    | all-MiniLM-L6-v2 | 384 | 0.78 | 8ms |\n",
    "\n",
    "    The table shows that text-embedding-3-small achieves higher hit rates\n",
    "    but with increased latency compared to all-MiniLM-L6-v2.\n",
    "    \"\"\",\n",
    "    \"metadata\": {\"content_type\": \"table\", \"section\": \"Results\"}\n",
    "}\n",
    "```\n",
    "\n",
    "**2. Mathematical Formulas**\n",
    "\n",
    "**âŒ Don't:**\n",
    "- Separate formula from explanation\n",
    "- Lose variable definitions\n",
    "- Strip LaTeX formatting\n",
    "\n",
    "**âœ… Do:**\n",
    "- Chunk formula WITH explanation and variable definitions\n",
    "- Preserve LaTeX or MathML\n",
    "- Add interpretation in plain text\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "chunk = {\n",
    "    \"text\": \"\"\"\n",
    "    Cache Hit Rate Calculation:\n",
    "\n",
    "    hit_rate = (cache_hits / total_queries) Ã— 100\n",
    "\n",
    "    Where:\n",
    "    - cache_hits: Number of queries served from cache\n",
    "    - total_queries: Total number of queries received\n",
    "\n",
    "    This formula measures the percentage of queries that can be answered\n",
    "    from the cache without calling the LLM.\n",
    "    \"\"\",\n",
    "    \"metadata\": {\"content_type\": \"formula\", \"section\": \"Methodology\"}\n",
    "}\n",
    "```\n",
    "\n",
    "**3. Figures and Charts**\n",
    "\n",
    "**âŒ Don't:**\n",
    "- Ignore figures (they contain critical information!)\n",
    "- Separate figure from caption\n",
    "- Lose visual patterns\n",
    "\n",
    "**âœ… Do:**\n",
    "- Chunk figure caption WITH discussion\n",
    "- Describe visual patterns in text\n",
    "- Consider multimodal RAG (vision models) for complex figures\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "chunk = {\n",
    "    \"text\": \"\"\"\n",
    "    Figure 3: Cache Hit Rate vs. Embedding Model Dimensionality\n",
    "\n",
    "    The bar chart shows cache hit rates for 13 embedding models, ranging\n",
    "    from 384 to 3072 dimensions. Key findings:\n",
    "    - Higher dimensionality correlates with higher hit rates (0.78 â†’ 0.92)\n",
    "    - Diminishing returns above 1536 dimensions\n",
    "    - text-embedding-3-large (3072d) achieves 0.92 hit rate\n",
    "\n",
    "    This suggests that semantic caching benefits from high-quality embeddings\n",
    "    with sufficient dimensionality to capture query nuances.\n",
    "    \"\"\",\n",
    "    \"metadata\": {\"content_type\": \"figure\", \"section\": \"Results\"}\n",
    "}\n",
    "```\n",
    "\n",
    "**4. Code Snippets**\n",
    "\n",
    "**âŒ Don't:**\n",
    "- Separate code from context\n",
    "- Lose function/class definitions\n",
    "- Strip comments\n",
    "\n",
    "**âœ… Do:**\n",
    "- Chunk code WITH context and rationale\n",
    "- Preserve syntax highlighting\n",
    "- Include usage examples\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "chunk = {\n",
    "    \"text\": \"\"\"\n",
    "    Implementation: Semantic Cache Lookup\n",
    "\n",
    "    ```python\n",
    "    def semantic_cache_lookup(query_embedding, threshold=0.95):\n",
    "        # Search for similar queries in cache\n",
    "        results = redis_client.ft(\"cache_idx\").search(\n",
    "            Query(f\"*=>[KNN 1 @embedding $vec]\")\n",
    "            .return_fields(\"response\", \"similarity\")\n",
    "            .dialect(2),\n",
    "            {\"vec\": query_embedding}\n",
    "        )\n",
    "\n",
    "        if results.docs and results.docs[0].similarity >= threshold:\n",
    "            return results.docs[0].response  # Cache hit\n",
    "        return None  # Cache miss\n",
    "    ```\n",
    "\n",
    "    This function performs semantic cache lookup using Redis vector search.\n",
    "    If a similar query (similarity >= 0.95) exists in cache, return cached response.\n",
    "    Otherwise, call the LLM and cache the new response.\n",
    "    \"\"\",\n",
    "    \"metadata\": {\"content_type\": \"code\", \"language\": \"python\"}\n",
    "}\n",
    "```\n",
    "\n",
    "**Summary: Multimodal Content Chunking Principles**\n",
    "\n",
    "1. **Context is king**: Always keep content WITH its explanation\n",
    "2. **Preserve structure**: Tables, formulas, code need formatting\n",
    "3. **Add metadata**: Content type, section, language help retrieval\n",
    "4. **Describe visuals**: Convert visual patterns to text\n",
    "5. **Experiment**: Test different strategies with YOUR documents"
   ],
   "id": "f03ae3f2b2e41f4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Document Type 2: Legal Contracts & Clause-Level Documents\n",
    "\n",
    "**Why Legal Documents Are Different:**\n",
    "\n",
    "Legal contracts represent the **most challenging category** for chunking because they require sophisticated data engineering beyond simple text splitting.\n",
    "\n",
    "**Unique Characteristics:**\n",
    "\n",
    "1. **Clause-Level Granularity**\n",
    "   - Each clause has specific legal meaning\n",
    "   - Clauses are numbered hierarchically (Section 3.2.1, etc.)\n",
    "   - Need precise retrieval at clause level\n",
    "\n",
    "2. **Cross-References**\n",
    "   - \"As defined in Section 1.5...\"\n",
    "   - \"Subject to the terms of Section 2.1...\"\n",
    "   - Clauses reference other clauses frequently\n",
    "\n",
    "3. **Hierarchical Dependencies**\n",
    "   - Parent sections contain child clauses\n",
    "   - Amendments modify earlier provisions\n",
    "   - Context requires understanding hierarchy\n",
    "\n",
    "4. **Legal Precedence and Overrides**\n",
    "   - Some clauses modify or override others\n",
    "   - \"Notwithstanding Section 2.1...\" creates dependency\n",
    "   - Amendment clauses change earlier provisions\n",
    "\n",
    "5. **Rich Metadata Requirements**\n",
    "   - Clause type (termination, payment, liability, etc.)\n",
    "   - Parties involved (which party has obligations)\n",
    "   - Effective dates and conditions\n",
    "   - Jurisdiction and governing law\n",
    "\n",
    "**What This Requires:**\n",
    "\n",
    "Simple chunking is **insufficient** for legal documents. You need:\n",
    "\n",
    "**1. Advanced Data Modeling**\n",
    "- **Knowledge graphs** to capture clause relationships\n",
    "- **Hierarchical structures** to preserve document organization\n",
    "- **Dependency tracking** for cross-references\n",
    "\n",
    "**Example knowledge graph:**\n",
    "```\n",
    "Clause 3.2 (Payment Terms)\n",
    "  â”œâ”€ references â†’ Clause 1.5 (Definitions: \"Net 30\")\n",
    "  â”œâ”€ modified_by â†’ Clause 8.1 (Amendment: \"Net 45 for Q4\")\n",
    "  â””â”€ depends_on â†’ Clause 2.1 (Delivery Conditions)\n",
    "```\n",
    "\n",
    "**2. Custom Chunking Logic**\n",
    "- Domain-specific rules for legal document structure\n",
    "- Clause boundary detection (not just paragraphs)\n",
    "- Preservation of numbering and hierarchy\n",
    "\n",
    "**3. Context Assembly Strategies**\n",
    "- **Recursive retrieval**: When retrieving Clause 3.2, also fetch referenced clauses\n",
    "- **Graph traversal**: Follow dependency links to build complete context\n",
    "- **Hierarchical expansion**: Include parent section context\n",
    "\n",
    "**Example Retrieval Flow:**\n",
    "```\n",
    "Query: \"What are the payment terms?\"\n",
    "\n",
    "1. Retrieve: Clause 3.2 (Payment Terms)\n",
    "2. Detect references: \"as defined in Section 1.5\"\n",
    "3. Fetch: Clause 1.5 (Definitions)\n",
    "4. Detect modifications: Clause 8.1 modifies 3.2\n",
    "5. Fetch: Clause 8.1 (Amendment)\n",
    "6. Assemble context: [3.2 + 1.5 + 8.1] with relationship metadata\n",
    "```\n",
    "\n",
    "**ðŸ’¡ Discussion Question:**\n",
    "\n",
    "Do you agree that legal contracts represent a fundamentally different challenge that goes beyond chunking into the realm of complex data engineering and knowledge modeling?\n",
    "\n",
    "**Our Position:** Yes, absolutely. Legal documents require:\n",
    "- **Not just chunking**, but **relationship modeling**\n",
    "- **Not just retrieval**, but **dependency resolution**\n",
    "- **Not just embeddings**, but **structured knowledge graphs**\n",
    "\n",
    "This is an **advanced topic beyond the scope of this module**, but it's important to recognize when simple chunking strategies are insufficient.\n",
    "\n",
    "**Recommendation:** For legal document RAG systems:\n",
    "1. Start with clause-level chunking as a baseline\n",
    "2. Add metadata enrichment (clause type, parties, dates)\n",
    "3. Build knowledge graphs for relationships\n",
    "4. Implement recursive retrieval for dependencies\n",
    "5. Consider specialized legal NLP tools (e.g., LexNLP, Blackstone)\n",
    "\n",
    "This is a **research-level problem** that requires domain expertise in both legal document structure and advanced RAG techniques."
   ],
   "id": "c13480a3c7450005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Document Type 3: Transcripts & Meeting Notes\n",
    "\n",
    "**Document Characteristics:**\n",
    "- Conversational flow with speaker changes\n",
    "- Temporal structure (time-based progression)\n",
    "- Topic shifts without clear structural markers\n",
    "- Interruptions, overlaps, and informal language\n",
    "- Context depends on who said what and when\n",
    "\n",
    "**Examples:**\n",
    "- Meeting transcripts (Zoom, Teams, Google Meet)\n",
    "- Podcast transcripts\n",
    "- Interview transcripts\n",
    "- Customer service call recordings\n",
    "- Presentation Q&A sessions\n",
    "\n",
    "**Why Standard Chunking Fails:**\n",
    "\n",
    "Traditional chunking strategies (fixed-size, semantic) don't account for:\n",
    "- **Speaker identity**: Who said what matters for context\n",
    "- **Temporal flow**: Conversations build on previous statements\n",
    "- **Turn-taking**: Natural conversation boundaries\n",
    "- **Topic drift**: Conversations meander without clear section breaks\n",
    "\n",
    "**Specialized Chunking Strategies for Transcripts:**\n",
    "\n",
    "**Strategy 1: Speaker-Based Chunking**\n",
    "\n",
    "**Concept:** Chunk by speaker turns, keeping each speaker's complete statement together.\n",
    "\n",
    "**Best for:** Interviews, Q&A sessions, debates\n",
    "\n",
    "**Pros:**\n",
    "- Preserves speaker context\n",
    "- Natural conversation boundaries\n",
    "- Easy to attribute statements\n",
    "\n",
    "**Cons:**\n",
    "- Variable chunk sizes (some speakers talk more)\n",
    "- May split related topics across speakers\n",
    "\n",
    "**Strategy 2: Time-Based Chunking**\n",
    "\n",
    "**Concept:** Chunk by time intervals (e.g., 2-minute segments).\n",
    "\n",
    "**Best for:** Long meetings, podcasts, lectures\n",
    "\n",
    "**Pros:**\n",
    "- Consistent chunk sizes\n",
    "- Easy to reference (\"at 15:30 in the meeting\")\n",
    "- Works well for long recordings\n",
    "\n",
    "**Cons:**\n",
    "- May split mid-sentence or mid-topic\n",
    "- Doesn't respect conversation flow\n",
    "\n",
    "**Strategy 3: Topic-Based Chunking (Semantic + Speaker-Aware)**\n",
    "\n",
    "**Concept:** Detect topic shifts using embeddings + speaker changes.\n",
    "\n",
    "**Best for:** Multi-topic meetings, panel discussions\n",
    "\n",
    "**Pros:**\n",
    "- Respects both topic and speaker boundaries\n",
    "- Most semantically coherent chunks\n",
    "- Adapts to conversation structure\n",
    "\n",
    "**Cons:**\n",
    "- Computationally expensive (embeddings for each utterance)\n",
    "- Requires speaker diarization\n",
    "\n",
    "**Strategy 4: Silence-Aware Merging**\n",
    "\n",
    "**Concept:** Use silence/pauses in audio to detect natural boundaries.\n",
    "\n",
    "**Best for:** Presentations, lectures with clear pauses\n",
    "\n",
    "**How it works:**\n",
    "- Audio processing detects pauses (e.g., >2 seconds of silence)\n",
    "- Merge utterances between pauses into chunks\n",
    "- Preserves natural speaking rhythm\n",
    "\n",
    "**Source:** VoxRAG (arXiv:2505.17326, 2025) - transcription-free RAG using silence-aware chunking\n",
    "\n",
    "**Pros:**\n",
    "- Natural conversation boundaries\n",
    "- Works without speaker diarization\n",
    "- Respects speaker's pacing\n",
    "\n",
    "**Cons:**\n",
    "- Requires audio access (not just transcript)\n",
    "- Pauses don't always align with topic shifts\n",
    "\n",
    "**Advanced Technique: Speaker Diarization + Chunking**\n",
    "\n",
    "**What is Speaker Diarization?**\n",
    "- Automatic detection of \"who spoke when\"\n",
    "- Assigns speaker labels (Speaker 1, Speaker 2, etc.)\n",
    "- Essential for multi-speaker transcripts\n",
    "\n",
    "**How to combine with chunking:**\n",
    "1. **Diarize audio** â†’ identify speakers\n",
    "2. **Transcribe with speaker labels** â†’ \"Speaker A: Hello...\"\n",
    "3. **Chunk by speaker + topic** â†’ preserve context\n",
    "\n",
    "**Tools:**\n",
    "- **Whisper**: Fast transcription with speaker labels\n",
    "- **pyannote.audio**: State-of-the-art speaker diarization\n",
    "- **AssemblyAI**: Commercial API with built-in diarization\n",
    "\n",
    "**Example Use Case: Meeting Minutes RAG**\n",
    "\n",
    "**Scenario:** Build a RAG system for company meeting transcripts.\n",
    "\n",
    "**Requirements:**\n",
    "- Answer questions like \"What did Sarah say about the budget?\"\n",
    "- Retrieve action items assigned to specific people\n",
    "- Find discussions about specific topics\n",
    "\n",
    "**Recommended Approach:**\n",
    "1. **Transcribe with speaker diarization** (Whisper + pyannote)\n",
    "2. **Chunk by speaker + topic** (hybrid approach)\n",
    "3. **Enrich with metadata**:\n",
    "   - Speaker name\n",
    "   - Timestamp\n",
    "   - Meeting title/date\n",
    "   - Detected topics (using LLM)\n",
    "4. **Store chunks with metadata** in vector DB\n",
    "5. **Implement metadata filtering** (e.g., \"speaker:Sarah AND topic:budget\")\n",
    "\n",
    "**Metadata Enrichment Example:**\n",
    "```python\n",
    "chunk = {\n",
    "    \"text\": \"Sarah: I think we should increase the marketing budget by 20%...\",\n",
    "    \"metadata\": {\n",
    "        \"speaker\": \"Sarah Johnson\",\n",
    "        \"timestamp\": \"00:15:30\",\n",
    "        \"meeting\": \"Q4 Planning - 2025-04-15\",\n",
    "        \"topic\": \"budget\",\n",
    "        \"action_item\": False\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**ðŸ’¡ Key Insight:** Transcripts require **context-aware chunking** that preserves:\n",
    "- **Who** said it (speaker identity)\n",
    "- **When** they said it (temporal context)\n",
    "- **What** they were discussing (topic/semantic content)\n",
    "\n",
    "Simple text chunking loses this critical context.\n",
    "\n",
    "**Recommendation:** For transcript RAG systems:\n",
    "1. Start with speaker-based chunking as baseline\n",
    "2. Add speaker diarization for multi-speaker content\n",
    "3. Enrich chunks with metadata (speaker, time, topic)\n",
    "4. Consider hybrid chunking (speaker + semantic) for complex conversations\n",
    "5. Use metadata filtering to improve retrieval precision\n",
    "\n",
    "This is an **emerging area** with active research (VoxRAG, 2025) exploring transcription-free approaches."
   ],
   "id": "7ba68f2b5bb9c0e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Part 6: Implementation Guidance - Choosing Your Chunking Strategy\n",
    "\n",
    "The optimal chunking strategy requires **experimentation** based on your specific context. There's no universal \"best practice.\"\n",
    "\n",
    "**Factors to Consider:**\n",
    "\n",
    "1. **Specific Use Case and Query Patterns**\n",
    "   - What questions will users ask?\n",
    "   - Do they need summaries or specific facts?\n",
    "   - Are queries broad or narrow?\n",
    "\n",
    "2. **Document Type and Structure**\n",
    "   - Structured (sections, headers) or unstructured (prose)?\n",
    "   - Multi-modal (text + images + tables) or text-only?\n",
    "   - Single-topic or multi-topic documents?\n",
    "\n",
    "3. **Models Being Used**\n",
    "   - **Embedding model**: Context window size, quality on long vs. short text\n",
    "   - **LLM**: Context window, attention patterns, cost per token\n",
    "   - **Multimodal capabilities**: Can it handle images, tables?\n",
    "\n",
    "4. **Performance Metrics**\n",
    "   - **Retrieval precision**: Are you getting the right chunks?\n",
    "   - **Answer quality**: Are LLM responses accurate and complete?\n",
    "   - **Latency**: How fast do you need results?\n",
    "   - **Cost**: Token usage, API calls, storage\n",
    "\n",
    "**Key Metrics to Track:**\n",
    "\n",
    "| Metric | What It Measures | How to Evaluate |\n",
    "|--------|------------------|-----------------|\n",
    "| **Retrieval Precision** | Are the right chunks retrieved? | Manual review or automated eval (LLM-as-judge) |\n",
    "| **Answer Quality** | Are LLM responses accurate? | Human evaluation or LLM-based scoring |\n",
    "| **Token Efficiency** | How many tokens per query? | Count tokens in retrieved chunks |\n",
    "| **Latency** | How fast is retrieval? | Measure end-to-end query time |\n",
    "| **Coverage** | Do chunks cover all important info? | Check if key facts are retrievable |\n",
    "\n",
    "**Iterative Improvement Process:**\n",
    "\n",
    "1. **Start simple**: Begin with fixed-size or document-based chunking\n",
    "2. **Measure baseline**: Establish performance metrics\n",
    "3. **Identify failures**: Where does retrieval fail? Where are answers wrong?\n",
    "4. **Hypothesize improvements**: \"Tables are being split\" â†’ Try structure-aware chunking\n",
    "5. **Test and compare**: Measure impact of changes\n",
    "6. **Iterate**: Repeat until performance is acceptable\n",
    "\n",
    "**Common Failure Patterns and Solutions:**\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|--------------|----------|\n",
    "| Tables split across chunks | Fixed-size chunking | Use structure-aware chunking |\n",
    "| Formulas without context | Naive chunking | Keep formulas with explanations |\n",
    "| Missing cross-references | Single-chunk retrieval | Implement recursive retrieval |\n",
    "| Generic answers | Chunks too large | Reduce chunk size or use semantic chunking |\n",
    "| Incomplete answers | Chunks too small | Increase chunk size or add overlap |\n",
    "\n",
    "**ðŸ’¡ Final Insight:**\n",
    "\n",
    "Chunking is **data modeling for retrieval**. Just like database schema design, there's no one-size-fits-all solution. The \"best\" chunking strategy is the one that:\n",
    "- Matches your document structure\n",
    "- Aligns with your query patterns\n",
    "- Meets your performance requirements\n",
    "- Balances complexity with maintainability\n",
    "\n",
    "**Experiment, measure, iterate.** This is engineering, not magic."
   ],
   "id": "14bacb84aa7e55ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "**1. Data Modeling is the Foundation of RAG Quality**\n",
    "- The critical first question: \"What is my natural retrieval unit?\"\n",
    "- For structured records (courses, products, FAQs), the answer is often \"don't chunk\"\n",
    "- For long-form documents (papers, books), chunking may improve retrieval precision\n",
    "\n",
    "**2. The \"Don't Chunk\" Strategy is Valid**\n",
    "- Course catalogs, product listings, FAQ entries don't need chunking\n",
    "- Each record is already semantically complete and self-contained\n",
    "- Chunking would fragment related information and hurt quality\n",
    "- Use hierarchical patterns (summaries + details) instead\n",
    "\n",
    "**3. When Chunking Helps**\n",
    "- Long-form documents with multiple distinct topics\n",
    "- Research papers, technical documentation, books, legal contracts\n",
    "- Improves retrieval precision by reducing irrelevant context\n",
    "- Research-backed: \"Lost in the Middle\", \"Context Rot\" show why structure matters\n",
    "\n",
    "**4. Three Core Chunking Strategies**\n",
    "- **Document-Based (Structure-Aware):** Split by sections/headers - best for structured documents\n",
    "- **Fixed-Size (Token-Based):** Split into fixed chunks with overlap - best for unstructured text\n",
    "- **Semantic (Meaning-Based):** Split based on topic shifts - best for dense academic text\n",
    "- Choose based on YOUR data characteristics and query patterns\n",
    "\n",
    "**5. Advanced Chunking for Three Document Types**\n",
    "\n",
    "**Research Papers & Long-Form Documents (Multimodal Content):**\n",
    "- Heterogeneous content: text, tables, figures, equations, code\n",
    "- **49-67% improvement** in retrieval with proper chunking (Anthropic, 2024)\n",
    "- Chunk overlap (10-20%) preserves context across boundaries\n",
    "- Keep multimodal content WITH context (table + caption, formula + definitions)\n",
    "- Hybrid approach recommended: summary + section-based + multimodal handling\n",
    "\n",
    "**Legal Contracts & Clause-Level Documents:**\n",
    "- Most challenging category requiring sophisticated data engineering\n",
    "- Clause-level granularity, cross-references, hierarchical dependencies\n",
    "- Simple chunking is insufficient - requires knowledge graphs\n",
    "- Recursive retrieval to fetch referenced clauses\n",
    "- **Advanced topic beyond this module** - recognize when chunking isn't enough\n",
    "\n",
    "**Transcripts & Meeting Notes:**\n",
    "- Speaker identity, temporal flow, topic drift\n",
    "- Four strategies: speaker-based, time-based, topic-based, silence-aware\n",
    "- Speaker diarization: automatic \"who spoke when\" detection\n",
    "- Metadata enrichment: speaker, timestamp, meeting, topic\n",
    "- Emerging area with active research (VoxRAG, 2025)\n",
    "\n",
    "**6. Chunking is Subjective and Document-Dependent**\n",
    "- Optimal strategy depends on: document type, content, query patterns, models, performance metrics\n",
    "- No universal \"best practice\" - experimentation required\n",
    "- Measure: retrieval precision, answer quality, latency, cost\n",
    "- Iterate: start simple, identify failures, hypothesize improvements, test\n",
    "\n",
    "**7. The Engineering Mindset**\n",
    "- Chunking is a design choice, not a default step\n",
    "- Like database schema design, structure affects retrieval quality\n",
    "- No one-size-fits-all solution - analyze YOUR data and requirements\n",
    "- **Experiment, measure, iterate** - this is engineering, not magic\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**Ask these questions:**\n",
    "\n",
    "1. **What is my natural retrieval unit?**\n",
    "   - Single record (course, product) â†’ Don't chunk\n",
    "   - Document section (paper, book) â†’ Consider chunking\n",
    "   - Clause (legal contract) â†’ Advanced chunking + knowledge graphs\n",
    "   - Speaker turn (transcript) â†’ Speaker-aware chunking\n",
    "\n",
    "2. **What are my query patterns?**\n",
    "   - \"Show me CS courses\" â†’ Whole-record embedding\n",
    "   - \"What compression techniques?\" â†’ Section-level chunking\n",
    "   - \"What did Sarah say about budget?\" â†’ Speaker + topic filtering\n",
    "\n",
    "3. **How many distinct topics per document?**\n",
    "   - Single topic â†’ Whole-document embedding\n",
    "   - Multiple topics â†’ Chunking improves precision\n",
    "\n",
    "4. **What content types are present?**\n",
    "   - Text-only â†’ Standard chunking strategies\n",
    "   - Multimodal (tables, figures, equations) â†’ Specialized handling\n",
    "   - Conversational (transcripts) â†’ Speaker-aware chunking\n",
    "\n",
    "**Example Decisions:**\n",
    "\n",
    "| Domain | Data Type | Decision | Strategy |\n",
    "|--------|-----------|----------|----------|\n",
    "| **Course Catalog** | Structured records | Don't chunk | Hierarchical (summaries + details) |\n",
    "| **Research Papers** | Multi-section, multimodal | Chunk | Hybrid (summary + sections + multimodal) |\n",
    "| **Support Tickets** | Single-issue records | Don't chunk | Whole-record embedding |\n",
    "| **Legal Contracts** | Multi-clause, cross-references | Advanced | Knowledge graphs + recursive retrieval |\n",
    "| **Meeting Transcripts** | Conversational, temporal | Chunk | Speaker-aware + time-based + metadata |\n",
    "| **Product Docs** | Mixed structure | Chunk | Fixed-size or semantic |\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "> **Chunking isn't about fitting in context windows - it's about data modeling for retrieval.**\n",
    ">\n",
    "> Just like you wouldn't store all customer data in one database row, you shouldn't embed all document content in one vector without thinking about retrieval patterns.\n",
    "\n",
    "**Critical Insights from This Module:**\n",
    "\n",
    "1. **Chunking is subjective** - depends on document type, content, queries, models, and performance requirements\n",
    "2. **Chunking is NOT always necessary** - for structured records, often don't chunk\n",
    "3. **Chunking is ONE approach** - alternatives include hierarchical retrieval, knowledge graphs, multimodal RAG\n",
    "4. **Multimodal content needs special handling** - tables WITH captions, formulas WITH definitions\n",
    "5. **Legal contracts go beyond chunking** - require knowledge graphs and recursive retrieval\n",
    "6. **Transcripts need context-aware chunking** - preserve who, when, and what\n",
    "7. **Experimentation is required** - no universal \"best practice\"\n",
    "8. **Chunking is data modeling for retrieval** - like database schema design\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Module 4: Memory Systems for Context Engineering\n",
    "\n",
    "Now that you understand data modeling and chunking for knowledge bases, you'll learn to manage conversation context:\n",
    "- **Working Memory:** Track conversation history within a session\n",
    "- **Long-term Memory:** Remember user preferences across sessions\n",
    "- **Memory-Enhanced RAG:** Combine retrieved knowledge with conversation memory\n",
    "- **Redis Agent Memory Server:** Automatic memory extraction and retrieval\n",
    "\n",
    "```\n",
    "Module 1: Context Engineering Fundamentals\n",
    "    â†“\n",
    "Module 2: RAG Fundamentals â† Completed\n",
    "    â†“\n",
    "Module 3: Chunking and Data Modeling â† You are here\n",
    "    â†“\n",
    "Module 4: Memory Systems â† Next\n",
    "    â†“\n",
    "Module 5: Building Agents (Complete System)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "### Exercise 1: Analyze Your Data\n",
    "Think about a dataset you work with. Answer these questions:\n",
    "1. What is the natural retrieval unit?\n",
    "2. Does it need chunking? Why or why not?\n",
    "3. If yes, which chunking strategy would you use?\n",
    "\n",
    "### Exercise 2: Design a Chunking Strategy\n",
    "For each document type, choose the best approach:\n",
    "1. Product catalog with 1,000 items\n",
    "2. 50-page technical manual with chapters\n",
    "3. Customer support tickets (avg 200 words each)\n",
    "4. Legal contracts (avg 20 pages, multiple clauses)\n",
    "\n",
    "### Exercise 3: Experiment with Chunking\n",
    "Take the research paper example and:\n",
    "1. Try all three chunking strategies\n",
    "2. Compare the number of chunks and average size\n",
    "3. Which strategy would work best for queries about \"HNSW configuration\"?\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "**Chunking Strategies:**\n",
    "- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)\n",
    "- [LlamaIndex Node Parsers](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/)\n",
    "\n",
    "**Research Papers:**\n",
    "- [\"Lost in the Middle\" (arXiv:2307.03172)](https://arxiv.org/abs/2307.03172) - U-shaped attention patterns in LLMs\n",
    "- [\"Context Rot\" (Chroma Research, 2025)](https://research.trychroma.com/context-rot) - Performance degradation with input length\n",
    "- [Needle in the Haystack Benchmark](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) - Retrieval in long contexts\n",
    "- [\"Contextual Retrieval\" (Anthropic, 2024)](https://www.anthropic.com/news/contextual-retrieval) - 49-67% reduction in retrieval failures\n",
    "- [\"Advancing Semantic Caching for LLMs\" (arXiv:2504.02268)](https://arxiv.org/abs/2504.02268) - Redis/Virginia Tech research\n",
    "- [\"VoxRAG\" (arXiv:2505.17326, 2025)](https://arxiv.org/abs/2505.17326) - Transcription-free RAG with silence-aware chunking\n",
    "\n",
    "**Advanced Topics:**\n",
    "- [Multi-Graph Multi-Agent Systems for Legal Documents (Medium, 2024)](https://medium.com/enterprise-rag/legal-document-rag-multi-graph-multi-agent-recursive-retrieval-through-legal-clauses-c90e073e0052)\n",
    "- [GraphRAG for Commercial Contracts (Neo4j, 2024)](https://neo4j.com/blog/developer/agentic-graphrag-for-commercial-contracts/)\n",
    "\n",
    "**Data Modeling for RAG:**\n",
    "- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Anthropic Prompt Engineering](https://docs.anthropic.com/claude/docs/prompt-engineering)\n",
    "\n",
    "**Vector Databases:**\n",
    "- [Redis Vector Search Documentation](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [RedisVL Python Library](https://github.com/RedisVentures/redisvl)\n",
    "\n",
    "**Speaker Diarization Tools:**\n",
    "- [Whisper (OpenAI)](https://github.com/openai/whisper) - Fast transcription\n",
    "- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - State-of-the-art speaker diarization\n",
    "- [AssemblyAI](https://www.assemblyai.com/) - Commercial API with built-in diarization\n"
   ],
   "id": "aa799680fdaaef82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
