{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Module 4: Memory Systems\n",
    "\n",
    "**‚è±Ô∏è Time:** 45 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "\n",
    "1. **Understand** why memory is essential for context engineering\n",
    "2. **Implement** working memory for conversation continuity\n",
    "3. **Use** long-term memory for persistent knowledge\n",
    "4. **Know** how Agent Memory Server handles compression automatically\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 1: Why Memory Matters (10 min)\n",
    "\n",
    "### The Grounding Problem\n",
    "\n",
    "**Without memory**, agents can't understand references:\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ‚ùå \"What does 'it' refer to? Please specify which course.\"\n",
    "```\n",
    "\n",
    "**With memory**, natural conversation flows:\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ‚úÖ \"CS401 requires CS301 (Intro to ML) and MATH201 (Linear Algebra).\"\n",
    "```\n",
    "\n",
    "### Two Types of Memory\n",
    "\n",
    "| Memory Type | Scope | Persistence | Example |\n",
    "|-------------|-------|-------------|--------|\n",
    "| **Working Memory** | Session | Temporary | Current conversation |\n",
    "| **Long-term Memory** | User | Persistent | \"Sarah prefers online courses\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.878000Z",
     "iopub.status.busy": "2025-12-03T22:50:02.877808Z",
     "iopub.status.idle": "2025-12-03T22:50:02.888020Z",
     "shell.execute_reply": "2025-12-03T22:50:02.887510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n",
      "   Agent Memory Server: http://localhost:8088\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Try current dir first\n",
    "load_dotenv(repo_root / \".env\")  # Then try parent\n",
    "\n",
    "AMS_URL = os.getenv(\"AGENT_MEMORY_SERVER_URL\", \"http://localhost:8088\")\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"   Agent Memory Server: {AMS_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 2: Working Memory with Agent Memory Server (15 min)\n",
    "\n",
    "### What is Agent Memory Server?\n",
    "\n",
    "**Agent Memory Server** is a Redis-backed service that provides:\n",
    "- Working memory (conversation history)\n",
    "- Long-term memory (semantic search over facts)\n",
    "- **Automatic compression** (truncation, sliding window, summarization)\n",
    "\n",
    "### Key Benefit: Compression is Handled For You\n",
    "\n",
    "You don't need to implement:\n",
    "- Token counting and truncation\n",
    "- Sliding window management\n",
    "- Conversation summarization\n",
    "\n",
    "**Agent Memory Server does this automatically!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.907197Z",
     "iopub.status.busy": "2025-12-03T22:50:02.907092Z",
     "iopub.status.idle": "2025-12-03T22:50:02.909898Z",
     "shell.execute_reply": "2025-12-03T22:50:02.909588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory system initialized (demo mode)\n",
      "   In production: Agent Memory Server provides Redis-backed persistence\n"
     ]
    }
   ],
   "source": [
    "# Working Memory Simulation\n",
    "# In production, this uses Agent Memory Server (Redis-backed)\n",
    "# Here we demonstrate the pattern with a simple in-memory implementation\n",
    "\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "@dataclass\n",
    "class WorkingMemory:\n",
    "    session_id: str\n",
    "    messages: List[Message] = field(default_factory=list)\n",
    "\n",
    "# Simple in-memory store (Agent Memory Server uses Redis)\n",
    "memory_store: Dict[str, WorkingMemory] = {}\n",
    "\n",
    "print(\"‚úÖ Memory system initialized (demo mode)\")\n",
    "print(\"   In production: Agent Memory Server provides Redis-backed persistence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.911283Z",
     "iopub.status.busy": "2025-12-03T22:50:02.911171Z",
     "iopub.status.idle": "2025-12-03T22:50:02.913586Z",
     "shell.execute_reply": "2025-12-03T22:50:02.913193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stored 4 messages in session b551e804...\n"
     ]
    }
   ],
   "source": [
    "# Working Memory: Store conversation messages\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "# Simulate a conversation\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"I'm interested in machine learning courses.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found several ML courses. CS301 is great for beginners.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the prerequisites for that one?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"CS301 requires CS201 (Data Structures), which you've completed!\"}\n",
    "]\n",
    "\n",
    "# Store messages in working memory\n",
    "working_memory = WorkingMemory(session_id=session_id)\n",
    "for msg in messages:\n",
    "    working_memory.messages.append(Message(role=msg[\"role\"], content=msg[\"content\"]))\n",
    "\n",
    "memory_store[session_id] = working_memory\n",
    "\n",
    "print(f\"‚úÖ Stored {len(messages)} messages in session {session_id[:8]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.914682Z",
     "iopub.status.busy": "2025-12-03T22:50:02.914603Z",
     "iopub.status.idle": "2025-12-03T22:50:02.916421Z",
     "shell.execute_reply": "2025-12-03T22:50:02.916160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Memory Contents:\n",
      "============================================================\n",
      "USER: I'm interested in machine learning courses.\n",
      "ASSISTANT: I found several ML courses. CS301 is great for beginners.\n",
      "USER: What are the prerequisites for that one?\n",
      "ASSISTANT: CS301 requires CS201 (Data Structures), which you've completed!\n",
      "============================================================\n",
      "\n",
      "Total messages: 4\n"
     ]
    }
   ],
   "source": [
    "# Retrieve working memory\n",
    "retrieved_memory = memory_store[session_id]\n",
    "\n",
    "print(\"Working Memory Contents:\")\n",
    "print(\"=\"*60)\n",
    "for msg in retrieved_memory.messages:\n",
    "    print(f\"{msg.role.upper()}: {msg.content}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal messages: {len(retrieved_memory.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 3: Long-term Memory (10 min)\n",
    "\n",
    "### What is Long-term Memory?\n",
    "\n",
    "Long-term memory stores **facts** that persist across sessions:\n",
    "- User preferences (\"prefers online courses\")\n",
    "- Important information (\"completed CS201\")\n",
    "- Learned context (\"interested in AI career\")\n",
    "\n",
    "### Semantic Search Over Facts\n",
    "\n",
    "Unlike working memory (sequential), long-term memory uses **semantic search**:\n",
    "- Query: \"What format does the student prefer?\"\n",
    "- Finds: \"Sarah prefers online courses\" (even without exact match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.917582Z",
     "iopub.status.busy": "2025-12-03T22:50:02.917512Z",
     "iopub.status.idle": "2025-12-03T22:50:02.920245Z",
     "shell.execute_reply": "2025-12-03T22:50:02.919905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stored 5 facts for sarah_chen_001\n"
     ]
    }
   ],
   "source": [
    "# Long-term Memory: Store facts that persist across sessions\n",
    "# In production, Agent Memory Server stores these with embeddings for semantic search\n",
    "\n",
    "@dataclass\n",
    "class LongTermFact:\n",
    "    text: str\n",
    "    user_id: str\n",
    "    keywords: List[str] = field(default_factory=list)\n",
    "\n",
    "# Simple long-term memory store\n",
    "long_term_store: Dict[str, List[LongTermFact]] = {}\n",
    "\n",
    "student_id = \"sarah_chen_001\"\n",
    "\n",
    "facts = [\n",
    "    (\"Sarah prefers online courses due to her work schedule.\", [\"online\", \"preference\", \"format\"]),\n",
    "    (\"Sarah has completed CS101, CS201, and MATH101.\", [\"completed\", \"courses\", \"prerequisites\"]),\n",
    "    (\"Sarah is interested in machine learning and AI.\", [\"interest\", \"machine learning\", \"AI\"]),\n",
    "    (\"Sarah's career goal is to become an AI Engineer.\", [\"career\", \"goal\", \"AI\"]),\n",
    "    (\"Sarah learns best through hands-on projects.\", [\"learning\", \"preference\", \"projects\"])\n",
    "]\n",
    "\n",
    "long_term_store[student_id] = [\n",
    "    LongTermFact(text=text, user_id=student_id, keywords=kw) for text, kw in facts\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Stored {len(facts)} facts for {student_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.921342Z",
     "iopub.status.busy": "2025-12-03T22:50:02.921281Z",
     "iopub.status.idle": "2025-12-03T22:50:02.923709Z",
     "shell.execute_reply": "2025-12-03T22:50:02.923429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'What courses has the student taken?'\n",
      "\n",
      "Relevant Facts:\n",
      "  1. Sarah has completed CS101, CS201, and MATH101.\n",
      "  2. Sarah prefers online courses due to her work schedule.\n",
      "  3. Sarah is interested in machine learning and AI.\n"
     ]
    }
   ],
   "source": [
    "# Semantic search simulation (keyword-based for demo)\n",
    "# In production, Agent Memory Server uses vector embeddings for true semantic search\n",
    "\n",
    "def search_facts(user_id: str, query: str, top_k: int = 3) -> List[LongTermFact]:\n",
    "    \"\"\"Simple keyword-based search (production uses embeddings).\"\"\"\n",
    "    user_facts = long_term_store.get(user_id, [])\n",
    "    query_words = set(query.lower().split())\n",
    "    \n",
    "    # Score by keyword overlap\n",
    "    scored = []\n",
    "    for fact in user_facts:\n",
    "        fact_words = set(fact.text.lower().split()) | set(kw.lower() for kw in fact.keywords)\n",
    "        score = len(query_words & fact_words)\n",
    "        scored.append((score, fact))\n",
    "    \n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [fact for _, fact in scored[:top_k]]\n",
    "\n",
    "query = \"What courses has the student taken?\"\n",
    "results = search_facts(student_id, query)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nRelevant Facts:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.924831Z",
     "iopub.status.busy": "2025-12-03T22:50:02.924774Z",
     "iopub.status.idle": "2025-12-03T22:50:02.926504Z",
     "shell.execute_reply": "2025-12-03T22:50:02.926216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'learning preferences'\n",
      "\n",
      "Relevant Facts:\n",
      "  1. Sarah is interested in machine learning and AI.\n",
      "  2. Sarah learns best through hands-on projects.\n",
      "  3. Sarah prefers online courses due to her work schedule.\n"
     ]
    }
   ],
   "source": [
    "# Another semantic search\n",
    "query = \"learning preferences\"\n",
    "results = search_facts(student_id, query)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nRelevant Facts:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 4: Automatic Compression (10 min)\n",
    "\n",
    "### The Compression Problem\n",
    "\n",
    "As conversations grow, they exceed token limits. Solutions:\n",
    "\n",
    "| Strategy | How It Works | Trade-off |\n",
    "|----------|--------------|----------|\n",
    "| **Truncation** | Keep last N messages | Loses early context |\n",
    "| **Sliding Window** | Keep recent + important | Complexity |\n",
    "| **Summarization** | LLM summarizes history | Cost + latency |\n",
    "\n",
    "### Agent Memory Server Handles This!\n",
    "\n",
    "**You don't need to implement compression.** Agent Memory Server:\n",
    "- Automatically manages conversation length\n",
    "- Applies appropriate compression strategies\n",
    "- Extracts and stores important facts to long-term memory\n",
    "\n",
    "**This is why we use Agent Memory Server instead of building from scratch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.927461Z",
     "iopub.status.busy": "2025-12-03T22:50:02.927403Z",
     "iopub.status.idle": "2025-12-03T22:50:02.929180Z",
     "shell.execute_reply": "2025-12-03T22:50:02.928759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Memory Server Compression Strategies:\n",
      "============================================================\n",
      "1. TRUNCATION: Keeps last N messages when limit exceeded\n",
      "2. SLIDING WINDOW: Keeps recent + pinned important messages\n",
      "3. SUMMARIZATION: LLM summarizes older messages\n",
      "4. FACT EXTRACTION: Important info ‚Üí long-term memory\n",
      "============================================================\n",
      "\n",
      "‚úÖ All handled automatically by Agent Memory Server!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate automatic context management\n",
    "# Agent Memory Server handles this - you just call get_working_memory()\n",
    "\n",
    "# The server automatically:\n",
    "# 1. Tracks conversation length\n",
    "# 2. Applies compression when needed\n",
    "# 3. Extracts facts to long-term memory\n",
    "\n",
    "print(\"Agent Memory Server Compression Strategies:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. TRUNCATION: Keeps last N messages when limit exceeded\")\n",
    "print(\"2. SLIDING WINDOW: Keeps recent + pinned important messages\")\n",
    "print(\"3. SUMMARIZATION: LLM summarizes older messages\")\n",
    "print(\"4. FACT EXTRACTION: Important info ‚Üí long-term memory\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ All handled automatically by Agent Memory Server!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-Enhanced RAG Query\n",
    "\n",
    "Now let's combine memory with our RAG system from Module 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.930190Z",
     "iopub.status.busy": "2025-12-03T22:50:02.930136Z",
     "iopub.status.idle": "2025-12-03T22:50:02.932372Z",
     "shell.execute_reply": "2025-12-03T22:50:02.932058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-Enhanced RAG Prompt:\n",
      "============================================================\n",
      "You are a course advisor with memory of past conversations.\n",
      "\n",
      "Student Facts:\n",
      "- Sarah prefers online courses due to her work schedule.\n",
      "- Sarah has completed CS101, CS201, and MATH101.\n",
      "- Sarah is interested in machine learning and AI.\n",
      "\n",
      "Recent Conversation:\n",
      "user: I'm interested in machine learning courses.\n",
      "assistant: I found several ML courses. CS301 is great for beginners.\n",
      "user: What are the prerequisites for that one?\n",
      "assistant: CS301 requires CS201 (Data Structures), which you've completed!\n",
      "\n",
      "Available Courses:\n",
      "  ‚Ä¢ CS301: Machine Learning (intermediate, 4 credits)\n",
      "  ‚Ä¢ CS401: Deep Learning (advanced, 4 credits)\n",
      "  ‚Ä¢ CS402: Natural Language Processing (advanced, 3 credits)\n",
      "\n",
      "Current Question: Based on my interests, what advanced courses should I take next?\n"
     ]
    }
   ],
   "source": [
    "# Memory-enhanced RAG prompt assembly\n",
    "# This shows how memory integrates with RAG\n",
    "\n",
    "def build_memory_enhanced_prompt(user_query: str, session_id: str, user_id: str) -> str:\n",
    "    \"\"\"Build a RAG prompt with working and long-term memory.\"\"\"\n",
    "    \n",
    "    # 1. Get working memory (conversation history)\n",
    "    working_mem = memory_store.get(session_id, WorkingMemory(session_id=session_id))\n",
    "    \n",
    "    # 2. Search long-term memory for relevant facts\n",
    "    long_term_facts = search_facts(user_id, user_query, top_k=3)\n",
    "    \n",
    "    # 3. Assemble full context\n",
    "    system_prompt = \"You are a course advisor with memory of past conversations.\"\n",
    "    \n",
    "    # Format conversation history\n",
    "    history = \"\\n\".join([f\"{m.role}: {m.content}\" for m in working_mem.messages[-6:]])\n",
    "    \n",
    "    # Format long-term facts\n",
    "    facts = \"\\n\".join([f\"- {f.text}\" for f in long_term_facts])\n",
    "    \n",
    "    # Sample course context (from Module 2)\n",
    "    course_context = \"\"\"Available Courses:\n",
    "  ‚Ä¢ CS301: Machine Learning (intermediate, 4 credits)\n",
    "  ‚Ä¢ CS401: Deep Learning (advanced, 4 credits)\n",
    "  ‚Ä¢ CS402: Natural Language Processing (advanced, 3 credits)\"\"\"\n",
    "    \n",
    "    return f\"\"\"{system_prompt}\n",
    "\n",
    "Student Facts:\n",
    "{facts}\n",
    "\n",
    "Recent Conversation:\n",
    "{history}\n",
    "\n",
    "{course_context}\n",
    "\n",
    "Current Question: {user_query}\"\"\"\n",
    "\n",
    "# Build the prompt\n",
    "prompt = build_memory_enhanced_prompt(\n",
    "    user_query=\"Based on my interests, what advanced courses should I take next?\",\n",
    "    session_id=session_id,\n",
    "    user_id=student_id\n",
    ")\n",
    "\n",
    "print(\"Memory-Enhanced RAG Prompt:\")\n",
    "print(\"=\"*60)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T22:50:02.933341Z",
     "iopub.status.busy": "2025-12-03T22:50:02.933286Z",
     "iopub.status.idle": "2025-12-03T22:50:02.934958Z",
     "shell.execute_reply": "2025-12-03T22:50:02.934629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Memory-Enhanced RAG Complete!\n",
      "\n",
      "The prompt includes:\n",
      "  ‚Ä¢ System instructions (advisor persona)\n",
      "  ‚Ä¢ Long-term facts (student preferences, history)\n",
      "  ‚Ä¢ Working memory (recent conversation)\n",
      "  ‚Ä¢ Retrieved courses (from semantic search)\n",
      "\n",
      "This enables personalized, context-aware responses!\n"
     ]
    }
   ],
   "source": [
    "# In production, this prompt would be sent to an LLM:\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#     max_tokens=500\n",
    "# )\n",
    "\n",
    "print(\"üìò Memory-Enhanced RAG Complete!\")\n",
    "print(\"\\nThe prompt includes:\")\n",
    "print(\"  ‚Ä¢ System instructions (advisor persona)\")\n",
    "print(\"  ‚Ä¢ Long-term facts (student preferences, history)\")\n",
    "print(\"  ‚Ä¢ Working memory (recent conversation)\")\n",
    "print(\"  ‚Ä¢ Retrieved courses (from semantic search)\")\n",
    "print(\"\\nThis enables personalized, context-aware responses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **Working memory** enables conversation continuity (session-scoped)\n",
    "2. **Long-term memory** stores persistent facts (user-scoped)\n",
    "3. **Semantic search** finds relevant facts without exact matches\n",
    "4. **Agent Memory Server** handles compression automatically\n",
    "5. **Memory + RAG** creates truly intelligent assistants\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Next Module\n",
    "\n",
    "In **Module 5: Building Agents**, you'll learn:\n",
    "- LangGraph fundamentals (nodes, edges, state)\n",
    "- Memory tools that LLMs can call\n",
    "- Building a complete course advisor agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
