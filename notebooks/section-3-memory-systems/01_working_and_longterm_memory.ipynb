{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19be531208b364b",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üß† Working and Long-Term Memory\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 45-60 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** why memory is essential for context engineering\n",
    "2. **Implement** working memory for conversation continuity\n",
    "3. **Use** long-term memory for persistent user knowledge\n",
    "4. **Integrate** memory with your Section 2 RAG system\n",
    "5. **Build** a complete memory-enhanced course advisor\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Recap\n",
    "\n",
    "### **Section 1: The Four Context Types**\n",
    "\n",
    "Recall the four context types from Section 1:\n",
    "\n",
    "1. **System Context** (Static) - Role, instructions, guidelines\n",
    "2. **User Context** (Dynamic, User-Specific) - Profile, preferences, goals\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - **‚Üê Memory enables this!**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - RAG results\n",
    "\n",
    "### **Section 2: Stateless RAG**\n",
    "\n",
    "Your Section 2 RAG system was **stateless**:\n",
    "\n",
    "```python\n",
    "async def rag_query(query, student_profile):\n",
    "    # 1. Search courses (Retrieved Context)\n",
    "    courses = await course_manager.search_courses(query)\n",
    "\n",
    "    # 2. Assemble context (System + User + Retrieved)\n",
    "    context = assemble_context(system_prompt, student_profile, courses)\n",
    "\n",
    "    # 3. Generate response\n",
    "    response = llm.invoke(context)\n",
    "\n",
    "    # ‚ùå No conversation history stored\n",
    "    # ‚ùå Each query is independent\n",
    "    # ‚ùå Can't reference previous messages\n",
    "```\n",
    "\n",
    "**The Problem:** Every query starts from scratch. No conversation continuity.\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Why Agents Need Memory: The Grounding Problem\n",
    "\n",
    "Before diving into implementation, let's understand the fundamental problem that memory solves.\n",
    "\n",
    "**Grounding** means understanding what users are referring to. Natural conversation is full of references:\n",
    "\n",
    "### **Without Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ‚ùå \"What does 'it' refer to? Please specify which course.\"\n",
    "\n",
    "User: \"The course we just discussed!\"\n",
    "Agent: ‚ùå \"I don't have access to previous messages. Which course?\"\n",
    "```\n",
    "\n",
    "**This is a terrible user experience.**\n",
    "\n",
    "### Types of References That Need Grounding\n",
    "\n",
    "**Pronouns:**\n",
    "- \"it\", \"that course\", \"those\", \"this one\"\n",
    "- \"he\", \"she\", \"they\" (referring to people)\n",
    "\n",
    "**Descriptions:**\n",
    "- \"the easy one\", \"the online course\"\n",
    "- \"my advisor\", \"that professor\"\n",
    "\n",
    "**Implicit context:**\n",
    "- \"Can I take it?\" ‚Üí Take what?\n",
    "- \"When does it start?\" ‚Üí What starts?\n",
    "\n",
    "**Temporal references:**\n",
    "- \"you mentioned\", \"earlier\", \"last time\"\n",
    "\n",
    "### **With Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers...\"\n",
    "[Stores: User asked about CS401]\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: [Checks memory: \"its\" = CS401]\n",
    "Agent: ‚úÖ \"CS401 requires CS201 and MATH301\"\n",
    "\n",
    "User: \"Can I take it?\"\n",
    "Agent: [Checks memory: \"it\" = CS401, checks student transcript]\n",
    "Agent: ‚úÖ \"You've completed CS201 but still need MATH301\"\n",
    "```\n",
    "\n",
    "**Now the conversation flows naturally!**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Two Types of Memory\n",
    "\n",
    "### **1. Working Memory (Session-Scoped)**\n",
    "\n",
    " - **What:** Conversation messages from the current session\n",
    " - **Purpose:** Reference resolution, conversation continuity\n",
    " - **Lifetime:** Persists for the session\n",
    " - **Storage:** Conversation remains accessible when you return to the same session\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Session: session_123\n",
    "Messages:\n",
    "  1. User: \"Tell me about CS401\"\n",
    "  2. Agent: \"CS401 is Machine Learning...\"\n",
    "  3. User: \"What are its prerequisites?\"\n",
    "  4. Agent: \"CS401 requires CS201 and MATH301\"\n",
    "```\n",
    "\n",
    "**Key Point:** Just like ChatGPT or Claude, when you return to a conversation, the working memory is still there. The conversation doesn't disappear!\n",
    "\n",
    "### **2. Long-term Memory (Cross-Session)**\n",
    "\n",
    " - **What:** Persistent knowledge (user preferences, domain facts, business rules)\n",
    " - **Purpose:** Personalization AND consistent application behavior across sessions\n",
    " - **Lifetime:** Permanent (until explicitly deleted)\n",
    " - **Scope:** Can be user-specific OR application-wide\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "**User-Scoped (Personalization):**\n",
    "```\n",
    "User: student_sarah\n",
    "  - \"Prefers online courses over in-person\"\n",
    "  - \"Major: Computer Science, focus on AI/ML\"\n",
    "  - \"Goal: Graduate Spring 2026\"\n",
    "  - \"Completed: CS101, CS201, MATH301\"\n",
    "```\n",
    "\n",
    "**Application-Scoped (Domain Knowledge):**\n",
    "```\n",
    "Domain: course_requirements\n",
    "  - \"CS401 requires CS201 as prerequisite\"\n",
    "  - \"Maximum course load is 18 credits per semester\"\n",
    "  - \"Registration opens 2 weeks before semester start\"\n",
    "  - \"Lab courses require campus attendance\"\n",
    "```\n",
    "\n",
    "### **Comparison: Working vs. Long-term Memory**\n",
    "\n",
    "| Working Memory | Long-term Memory |\n",
    "|----------------|------------------|\n",
    "| **Session-scoped** | **User-scoped OR Application-scoped** |\n",
    "| Current conversation | Important facts, rules, knowledge |\n",
    "| Persists for session | Persists across sessions |\n",
    "| Full message history | Extracted knowledge (user + domain) |\n",
    "| Loaded/saved each turn | Searched when needed |\n",
    "| **Challenge:** Context window limits | **Challenge:** Storage growth |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Setup and Environment\n",
    "\n",
    "Let's set up our environment with the necessary dependencies and connections. We'll build on Section 2's RAG foundation and add memory capabilities.\n",
    "\n",
    "### ‚ö†Ô∏è Prerequisites\n",
    "\n",
    "**Before running this notebook, make sure you have:**\n",
    "\n",
    "1. **Docker Desktop running** - Required for Redis and Agent Memory Server\n",
    "\n",
    "2. **Environment variables** - Create a `.env` file in the project root directory:\n",
    "   ```bash\n",
    "   # Copy the example file (if it exists)\n",
    "   cd ../..\n",
    "   # Or create .env manually with:\n",
    "   # OPENAI_API_KEY=your_actual_openai_api_key_here\n",
    "   # REDIS_URL=redis://localhost:6379\n",
    "   # AGENT_MEMORY_URL=http://localhost:8088\n",
    "   ```\n",
    "\n",
    "3. **Start services** - Make sure Redis and Agent Memory Server are running:\n",
    "   ```bash\n",
    "   # Start Redis and Agent Memory Server using docker-compose\n",
    "   cd ../..\n",
    "   docker-compose up -d\n",
    "   ```\n",
    "\n",
    "**Note:** Using docker-compose will:\n",
    "- ‚úÖ Start Redis on port 6379\n",
    "- ‚úÖ Start Agent Memory Server on port 8088\n",
    "- ‚úÖ Configure networking between services\n",
    "- ‚úÖ Persist data in Docker volumes\n",
    "\n",
    "If the Memory Server is not available, the notebook will skip memory-related demos but will still run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8736deb126c3f16",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268deee3282f75",
   "metadata": {},
   "source": [
    "### Automated Setup Check\n",
    "\n",
    "Let's run the setup script to ensure all services are running properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df05c4a01f7d55e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:38.656600Z",
     "iopub.status.busy": "2025-12-09T19:44:38.656440Z",
     "iopub.status.idle": "2025-12-09T19:44:38.730872Z",
     "shell.execute_reply": "2025-12-09T19:44:38.730371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if required services are running...\n",
      "\n",
      "‚úÖ Redis is running\n",
      "‚úÖ Agent Memory Server is running\n",
      "\n",
      "If services are not running, start them with:\n",
      "  cd ../..\n",
      "  docker-compose up -d\n"
     ]
    }
   ],
   "source": [
    "# Check if services are running\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Checking if required services are running...\\n\")\n",
    "\n",
    "# Check if Redis is running\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"ps\", \"--filter\", \"name=redis\", \"--format\", \"{{.Names}}\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    if \"redis\" in result.stdout:\n",
    "        print(\"‚úÖ Redis is running\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Redis is not running. Start it with: docker-compose up -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not check Redis status: {e}\")\n",
    "\n",
    "# Check if Agent Memory Server is running\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"ps\", \"--filter\", \"name=agent-memory\", \"--format\", \"{{.Names}}\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    if \"agent-memory\" in result.stdout or \"memory\" in result.stdout:\n",
    "        print(\"‚úÖ Agent Memory Server is running\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Agent Memory Server is not running. Start it with: docker-compose up -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not check Agent Memory Server status: {e}\")\n",
    "\n",
    "print(\"\\nIf services are not running, start them with:\")\n",
    "print(\"  cd ../..\")\n",
    "print(\"  docker-compose up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911ec87de846a67",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a2c9167d8c5b9",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "If you haven't already installed the reference-agent package, uncomment and run the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc5f86042f5c1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:38.732774Z",
     "iopub.status.busy": "2025-12-09T19:44:38.732639Z",
     "iopub.status.idle": "2025-12-09T19:44:38.734808Z",
     "shell.execute_reply": "2025-12-09T19:44:38.734254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to install the project package\n",
    "# %pip install -q -e ../..\n",
    "\n",
    "# Uncomment to install agent-memory-client\n",
    "# %pip install -q agent-memory-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517cc7d3a970f91d",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "We'll load environment variables from the `.env` file in the `reference-agent` directory.\n",
    "\n",
    "**Required variables:**\n",
    "- `OPENAI_API_KEY` - Your OpenAI API key\n",
    "- `REDIS_URL` - Redis connection URL (default: redis://localhost:6379)\n",
    "- `AGENT_MEMORY_URL` - Agent Memory Server URL (default: http://localhost:8088)\n",
    "\n",
    "If you haven't created the `.env` file yet, copy `.env.example` and add your OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c712b48760cc932c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:38.736225Z",
     "iopub.status.busy": "2025-12-09T19:44:38.736119Z",
     "iopub.status.idle": "2025-12-09T19:44:38.743556Z",
     "shell.execute_reply": "2025-12-09T19:44:38.742961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8088\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from project root directory\n",
    "env_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\n",
    "        f\"\"\"‚ùå OPENAI_API_KEY not found!\n",
    "\n",
    "    Please create a .env file at: {env_path.absolute()}\n",
    "\n",
    "    With the following content:\n",
    "    OPENAI_API_KEY=your_openai_api_key\n",
    "    REDIS_URL=redis://localhost:6379\n",
    "    AGENT_MEMORY_URL=http://localhost:8088\n",
    "    \"\"\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables loaded\")\n",
    "    print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "    print(f\"   AGENT_MEMORY_URL: {AGENT_MEMORY_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92aa2f60384e30d",
   "metadata": {},
   "source": [
    "### Import Core Libraries\n",
    "\n",
    "We'll import standard Python libraries and async support for our memory operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60eefefd58081b7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:38.744824Z",
     "iopub.status.busy": "2025-12-09T19:44:38.744743Z",
     "iopub.status.idle": "2025-12-09T19:44:38.746686Z",
     "shell.execute_reply": "2025-12-09T19:44:38.746294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core libraries imported\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "print(\"‚úÖ Core libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718bb5d2ac0595c",
   "metadata": {},
   "source": [
    "### Import Section 2 Components\n",
    "\n",
    "We're building on Section 2's RAG foundation, so we'll reuse the same components:\n",
    "- `redis_config` - Redis connection and configuration\n",
    "- `CourseManager` - Course search and management\n",
    "- `StudentProfile` and other models - Data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5172a46aa07a1cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:38.747718Z",
     "iopub.status.busy": "2025-12-09T19:44:38.747645Z",
     "iopub.status.idle": "2025-12-09T19:44:40.945713Z",
     "shell.execute_reply": "2025-12-09T19:44:40.945216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Section 2 components imported\n",
      "   CourseManager: Available\n",
      "   Redis Config: Available\n",
      "   Models: Course, StudentProfile, etc.\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import (\n",
    "    Course,\n",
    "    CourseFormat,\n",
    "    DifficultyLevel,\n",
    "    Semester,\n",
    "    StudentProfile,\n",
    ")\n",
    "\n",
    "# Import Section 2 components\n",
    "from redis_context_course.redis_config import redis_config\n",
    "\n",
    "print(\"‚úÖ Section 2 components imported\")\n",
    "print(f\"   CourseManager: Available\")\n",
    "print(f\"   Redis Config: Available\")\n",
    "print(f\"   Models: Course, StudentProfile, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccfa42b7a0cdf94",
   "metadata": {},
   "source": [
    "### Import LangChain Components\n",
    "\n",
    "We'll use LangChain for LLM interaction and message handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430df8f6e59d12b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:40.946955Z",
     "iopub.status.busy": "2025-12-09T19:44:40.946820Z",
     "iopub.status.idle": "2025-12-09T19:44:40.948774Z",
     "shell.execute_reply": "2025-12-09T19:44:40.948445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain components imported\n",
      "   ChatOpenAI: Available\n",
      "   Message types: HumanMessage, SystemMessage, AIMessage\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"‚úÖ LangChain components imported\")\n",
    "print(f\"   ChatOpenAI: Available\")\n",
    "print(f\"   Message types: HumanMessage, SystemMessage, AIMessage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42862eec4ae3b753",
   "metadata": {},
   "source": [
    "### Import Agent Memory Server Client\n",
    "\n",
    "The Agent Memory Server provides production-ready memory management. If it's not available, we'll note that and continue with limited functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb02858f71bebff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:40.949871Z",
     "iopub.status.busy": "2025-12-09T19:44:40.949793Z",
     "iopub.status.idle": "2025-12-09T19:44:40.951895Z",
     "shell.execute_reply": "2025-12-09T19:44:40.951509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent Memory Server client available\n",
      "   MemoryAPIClient: Ready\n",
      "   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\n"
     ]
    }
   ],
   "source": [
    "# Import Agent Memory Server client\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    from agent_memory_client.models import (\n",
    "        ClientMemoryRecord,\n",
    "        MemoryMessage,\n",
    "        WorkingMemory,\n",
    "    )\n",
    "\n",
    "    MEMORY_SERVER_AVAILABLE = True\n",
    "    print(\"‚úÖ Agent Memory Server client available\")\n",
    "    print(\"   MemoryAPIClient: Ready\")\n",
    "    print(\"   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\")\n",
    "except ImportError:\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Agent Memory Server not available\")\n",
    "    print(\"   Install with: pip install agent-memory-client\")\n",
    "    print(\"   Start server: See reference-agent/README.md\")\n",
    "    print(\"   Note: Some demos will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b94c4f6cd2ed12",
   "metadata": {},
   "source": [
    "### What We Just Did\n",
    "\n",
    "We've successfully set up our environment with all the necessary components:\n",
    "\n",
    "**Imported:**\n",
    "- ‚úÖ Section 2 RAG components (`CourseManager`, `redis_config`, models)\n",
    "- ‚úÖ LangChain for LLM interaction\n",
    "- ‚úÖ Agent Memory Server client (if available)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Building on Section 2's foundation (not starting from scratch)\n",
    "- Agent Memory Server provides scalable, persistent memory\n",
    "- Same Redis University domain for consistency\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Initialize Components\n",
    "\n",
    "Now let's initialize the components we'll use throughout this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6490ff7de0df7c4",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "The `CourseManager` handles course search and retrieval, just like in Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2d3b080e16bd3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:40.952934Z",
     "iopub.status.busy": "2025-12-09T19:44:40.952867Z",
     "iopub.status.idle": "2025-12-09T19:44:41.125356Z",
     "shell.execute_reply": "2025-12-09T19:44:41.124985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:40 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Course Manager initialized\n",
      "   Ready to search and retrieve courses\n"
     ]
    }
   ],
   "source": [
    "# Initialize Course Manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"‚úÖ Course Manager initialized\")\n",
    "print(\"   Ready to search and retrieve courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de7fcb447d889d",
   "metadata": {},
   "source": [
    "### Initialize LLM\n",
    "\n",
    "We'll use GPT-4o with temperature=0.0 for consistent, deterministic responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5321f905c99e4d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.126453Z",
     "iopub.status.busy": "2025-12-09T19:44:41.126375Z",
     "iopub.status.idle": "2025-12-09T19:44:41.134331Z",
     "shell.execute_reply": "2025-12-09T19:44:41.133784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf422c27fa939aba",
   "metadata": {},
   "source": [
    "### Initialize Memory Client\n",
    "\n",
    "If the Agent Memory Server is available, we'll initialize the memory client. This client handles both working memory (conversation history) and long-term memory (persistent facts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ae5b78a69a7813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.135401Z",
     "iopub.status.busy": "2025-12-09T19:44:41.135334Z",
     "iopub.status.idle": "2025-12-09T19:44:41.140201Z",
     "shell.execute_reply": "2025-12-09T19:44:41.139868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory Client initialized\n",
      "   Base URL: http://localhost:8088\n",
      "   Namespace: redis_university\n",
      "   Ready for working memory and long-term memory operations\n"
     ]
    }
   ],
   "source": [
    "# Initialize Memory Client\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=AGENT_MEMORY_URL, default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryAPIClient(config=config)\n",
    "    print(\"‚úÖ Memory Client initialized\")\n",
    "    print(f\"   Base URL: {config.base_url}\")\n",
    "    print(f\"   Namespace: {config.default_namespace}\")\n",
    "    print(\"   Ready for working memory and long-term memory operations\")\n",
    "else:\n",
    "    memory_client = None\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")\n",
    "    print(\"   Running with limited functionality\")\n",
    "    print(\"   Some demos will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22962c20e837fe5",
   "metadata": {},
   "source": [
    "### Create Sample Student Profile\n",
    "\n",
    "We'll create a sample student profile to use throughout our demos. This follows the same pattern from Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ba51694f18ea25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.141262Z",
     "iopub.status.busy": "2025-12-09T19:44:41.141194Z",
     "iopub.status.idle": "2025-12-09T19:44:41.143346Z",
     "shell.execute_reply": "2025-12-09T19:44:41.143046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Student profile created\n",
      "   Name: Sarah Chen\n",
      "   Major: Computer Science\n",
      "   Year: 2\n",
      "   Interests: machine learning, data science, algorithms\n",
      "   Completed: CS101, CS201\n",
      "   Preferred Format: online\n"
     ]
    }
   ],
   "source": [
    "# Create sample student profile\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"CS101\", \"CS201\"],\n",
    "    current_courses=[\"MATH301\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Student profile created\")\n",
    "print(f\"   Name: {sarah.name}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Year: {sarah.year}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")\n",
    "print(f\"   Completed: {', '.join(sarah.completed_courses)}\")\n",
    "print(f\"   Preferred Format: {sarah.preferred_format.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2876f73d8cc1a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.144647Z",
     "iopub.status.busy": "2025-12-09T19:44:41.144579Z",
     "iopub.status.idle": "2025-12-09T19:44:41.146538Z",
     "shell.execute_reply": "2025-12-09T19:44:41.146193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ INITIALIZATION SUMMARY\n",
      "\n",
      "‚úÖ Course Manager: Ready\n",
      "‚úÖ LLM (GPT-4o): Ready\n",
      "‚úÖ Memory Client: Ready\n",
      "‚úÖ Student Profile: Sarah Chen\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ INITIALIZATION SUMMARY\")\n",
    "print(f\"\\n‚úÖ Course Manager: Ready\")\n",
    "print(f\"‚úÖ LLM (GPT-4o): Ready\")\n",
    "print(\n",
    "    f\"{'‚úÖ' if MEMORY_SERVER_AVAILABLE else '‚ö†Ô∏è '} Memory Client: {'Ready' if MEMORY_SERVER_AVAILABLE else 'Not Available'}\"\n",
    ")\n",
    "print(f\"‚úÖ Student Profile: {sarah.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b81fa017798d6",
   "metadata": {},
   "source": [
    "### Initialization Done\n",
    "üìã What We're Building On:\n",
    "-  Section 2's RAG foundation (CourseManager, redis_config)\n",
    "-  Same StudentProfile model\n",
    "-  Same Redis configuration\n",
    "\n",
    "‚ú® What We're Adding:\n",
    "-  Memory Client for conversation history\n",
    "-  Working Memory for session context\n",
    "-  Long-term Memory for persistent knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb232f3d2509406",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 1: Working Memory Fundamentals\n",
    "\n",
    "### **What is Working Memory?**\n",
    "\n",
    "Working memory stores **conversation messages** for the current session. It enables:\n",
    "\n",
    "- ‚úÖ **Reference resolution** - \"it\", \"that course\", \"the one you mentioned\"\n",
    "- ‚úÖ **Context continuity** - Each message builds on previous messages\n",
    "- ‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "```\n",
    "Turn 1: Load working memory (empty) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 2: Load working memory (1 exchange) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 3: Load working memory (2 exchanges) ‚Üí Process query ‚Üí Save messages\n",
    "```\n",
    "\n",
    "Each turn has access to all previous messages in the session.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Working Memory in Action\n",
    "\n",
    "Let's simulate a multi-turn conversation with working memory. We'll break this down step-by-step to see how working memory enables natural conversation flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4c3dacf1beaff",
   "metadata": {},
   "source": [
    "### Setup: Create Session and Student IDs\n",
    "\n",
    "Now that we have our components initialized, let's create session and student identifiers for our working memory demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d44da725da024c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.147723Z",
     "iopub.status.busy": "2025-12-09T19:44:41.147656Z",
     "iopub.status.idle": "2025-12-09T19:44:41.149406Z",
     "shell.execute_reply": "2025-12-09T19:44:41.149119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Working Memory Demo Setup"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Student ID: sarah.chen\n",
      "   Session ID: session_sarah.chen_demo\n",
      "   Ready to demonstrate multi-turn conversation\n"
     ]
    }
   ],
   "source": [
    "# Setup for working memory demo\n",
    "student_id = sarah.email.split(\"@\")[0]  # \"sarah.chen\"\n",
    "session_id = f\"session_{student_id}_demo\"\n",
    "\n",
    "print(\"üéØ Working Memory Demo Setup\")\n",
    "print(f\"   Student ID: {student_id}\")\n",
    "print(f\"   Session ID: {session_id}\")\n",
    "print(\"   Ready to demonstrate multi-turn conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193929957ec58e3e",
   "metadata": {},
   "source": [
    "### Turn 1: Initial Query\n",
    "\n",
    "Let's start with a simple query about a course. This is the first turn, so working memory will be empty.\n",
    "\n",
    "We'll break this down into clear steps:\n",
    "1. We will use Memory Server\n",
    "2. Load working memory (will be empty on first turn)\n",
    "3. Search for the course\n",
    "4. Generate a response\n",
    "5. Save the conversation to working memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3990d104a25fa1",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the user query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc21436e9dcf0dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.150577Z",
     "iopub.status.busy": "2025-12-09T19:44:41.150507Z",
     "iopub.status.idle": "2025-12-09T19:44:41.152326Z",
     "shell.execute_reply": "2025-12-09T19:44:41.151943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìç TURN 1: User asks about a course\n",
      "================================================================================\n",
      "\n",
      "üë§ User: Tell me about Data Structures and Algorithms\n"
     ]
    }
   ],
   "source": [
    "# Check if Memory Server is available\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìç TURN 1: User asks about a course\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define the user's query\n",
    "turn1_query = \"Tell me about Data Structures and Algorithms\"\n",
    "print(f\"\\nüë§ User: {turn1_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b09b27ce726a2",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory\n",
    "\n",
    "On the first turn, working memory will be empty since this is a new session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefbddd80e873727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.153311Z",
     "iopub.status.busy": "2025-12-09T19:44:41.153241Z",
     "iopub.status.idle": "2025-12-09T19:44:41.179125Z",
     "shell.execute_reply": "2025-12-09T19:44:41.178727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:41 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Working Memory Status:\n",
      "   Messages in memory: 20\n",
      "   Status: Has history\n"
     ]
    }
   ],
   "source": [
    "# Load working memory (empty for first turn)\n",
    "_, turn1_working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print(f\"üìä Working Memory Status:\")\n",
    "print(f\"   Messages in memory: {len(turn1_working_memory.messages)}\")\n",
    "print(\n",
    "    f\"   Status: {'Empty (first turn)' if len(turn1_working_memory.messages) == 0 else 'Has history'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632be78f65633470",
   "metadata": {},
   "source": [
    "#### Step 3: Search for the course\n",
    "\n",
    "Use the course manager to search for courses matching the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c3f15020256def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:41.180196Z",
     "iopub.status.busy": "2025-12-09T19:44:41.180113Z",
     "iopub.status.idle": "2025-12-09T19:44:42.114697Z",
     "shell.execute_reply": "2025-12-09T19:44:42.113660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Searching for courses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:42 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 1 course(s)\n",
      "   - CS009: Data Structures and Algorithms\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîç Searching for courses...\")\n",
    "turn1_courses = await course_manager.search_courses(turn1_query, limit=1)\n",
    "\n",
    "if turn1_courses:\n",
    "    print(f\"   Found {len(turn1_courses)} course(s)\")\n",
    "\n",
    "    # print the course details\n",
    "    for course in turn1_courses:\n",
    "        print(f\"   - {course.course_code}: {course.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0da4579584d55f",
   "metadata": {},
   "source": [
    "#### Step 4: Generate response using LLM\n",
    "\n",
    "Use the LLM to generate a natural response based on the retrieved course information.\n",
    "\n",
    "This follows the **RAG pattern**: Retrieve (done in Step 3) ‚Üí Augment (add to context) ‚Üí Generate (use LLM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183b9954750e3342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:42.117003Z",
     "iopub.status.busy": "2025-12-09T19:44:42.116839Z",
     "iopub.status.idle": "2025-12-09T19:44:42.119984Z",
     "shell.execute_reply": "2025-12-09T19:44:42.119451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Course context: Course Information:\n",
      "- Code: CS009\n",
      "- Title: Data Structures and Algorithms\n",
      "- Description: Study of fundamental data structures and algorithms. Arrays, linked lists, trees, graphs, sorting, and searching.\n",
      "- Prerequisites: CS001, CS001\n",
      "- Credits: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = turn1_courses[0]\n",
    "\n",
    "course_context = f\"\"\"Course Information:\n",
    "- Code: {course.course_code}\n",
    "- Title: {course.title}\n",
    "- Description: {course.description}\n",
    "- Prerequisites: {', '.join([p.course_code for p in course.prerequisites]) if course.prerequisites else 'None'}\n",
    "- Credits: {course.credits}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"   Course context: {course_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83732656aa9bea58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:42.122001Z",
     "iopub.status.busy": "2025-12-09T19:44:42.121829Z",
     "iopub.status.idle": "2025-12-09T19:44:44.933860Z",
     "shell.execute_reply": "2025-12-09T19:44:44.933229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ Generating response using LLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:44 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: The course \"Data Structures and Algorithms\" (CS009) is a comprehensive study of fundamental data structures and algorithms. It covers essential topics such as arrays, linked lists, trees, graphs, sorting, and searching. This course is designed to provide a solid foundation in understanding how data can be organized and manipulated efficiently, which is crucial for solving complex computational problems.\n",
      "\n",
      "To enroll in this course, you must have completed the prerequisite course CS001. The course is worth 4 credits, indicating a significant time commitment and depth of study. This course is essential for anyone looking to deepen their understanding of computer science and improve their problem-solving skills in programming.\n"
     ]
    }
   ],
   "source": [
    "# Build messages for LLM\n",
    "turn1_messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful course advisor. Answer questions about courses based on the provided information.\"\n",
    "    ),\n",
    "    HumanMessage(content=f\"{course_context}\\n\\nUser question: {turn1_query}\"),\n",
    "]\n",
    "\n",
    "# Generate response using LLM\n",
    "print(f\"\\nüí≠ Generating response using LLM...\")\n",
    "turn1_response = llm.invoke(turn1_messages).content\n",
    "\n",
    "print(f\"\\nü§ñ Agent: {turn1_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b65c69382e61c",
   "metadata": {},
   "source": [
    "#### Step 5: Save to working memory\n",
    "\n",
    "Add both the user query and assistant response to working memory for future turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc3e623850cc0420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:44.936054Z",
     "iopub.status.busy": "2025-12-09T19:44:44.935868Z",
     "iopub.status.idle": "2025-12-09T19:44:44.953714Z",
     "shell.execute_reply": "2025-12-09T19:44:44.953105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:44 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved to working memory\n",
      "   Messages now in memory: 22\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Add messages to working memory\n",
    "    turn1_working_memory.messages.extend(\n",
    "        [\n",
    "            MemoryMessage(role=\"user\", content=turn1_query),\n",
    "            MemoryMessage(role=\"assistant\", content=turn1_response),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=turn1_working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved to working memory\")\n",
    "    print(f\"   Messages now in memory: {len(turn1_working_memory.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81aac22b5dee20",
   "metadata": {},
   "source": [
    "### What Just Happened in Turn 1?\n",
    "\n",
    "**Initial State:**\n",
    "- Working memory was empty (first turn)\n",
    "- No conversation history available\n",
    "\n",
    "**Actions (RAG Pattern):**\n",
    "1. **Retrieve:** Searched for Data Structures and Algorithms in the course database\n",
    "2. **Augment:** Added course information to LLM context\n",
    "3. **Generate:** LLM created a natural language response\n",
    "4. **Save:** Stored conversation in working memory\n",
    "\n",
    "**Result:**\n",
    "- Working memory now contains 2 messages (1 user, 1 assistant)\n",
    "- This history will be available for the next turn\n",
    "\n",
    "**Key Insight:** Even the first turn uses the LLM to generate natural responses based on retrieved information.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4b2dd6bc900eb",
   "metadata": {},
   "source": [
    "### Turn 2: Follow-up with Pronoun Reference\n",
    "\n",
    "Now let's ask a follow-up question using \"its\" - a pronoun that requires context from Turn 1.\n",
    "\n",
    "We'll break this down into steps:\n",
    "1. Set up the query with pronoun reference\n",
    "2. Load working memory (now contains Turn 1)\n",
    "3. Build context with conversation history\n",
    "4. Generate response using LLM\n",
    "5. Save to working memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514e2a3477f589a",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33bdfccd3e1dd8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:44.956006Z",
     "iopub.status.busy": "2025-12-09T19:44:44.955862Z",
     "iopub.status.idle": "2025-12-09T19:44:44.958819Z",
     "shell.execute_reply": "2025-12-09T19:44:44.958173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 2: User uses pronoun reference ('its')\n",
      "================================================================================\n",
      "\n",
      "üë§ User: What are its prerequisites?\n",
      "   Note: 'its' refers to Data Structures and Algorithms from Turn 1\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 2: User uses pronoun reference ('its')\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    turn2_query = \"What are its prerequisites?\"\n",
    "    print(f\"\\nüë§ User: {turn2_query}\")\n",
    "    print(f\"   Note: 'its' refers to Data Structures and Algorithms from Turn 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251400e6c872266e",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory\n",
    "\n",
    "This time, working memory will contain the conversation from Turn 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f829cbd34e3e664b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:44.960956Z",
     "iopub.status.busy": "2025-12-09T19:44:44.960812Z",
     "iopub.status.idle": "2025-12-09T19:44:44.972235Z",
     "shell.execute_reply": "2025-12-09T19:44:44.971655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:44 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Working Memory Status:\n",
      "   Messages in memory: 22\n",
      "   Contains: Turn 1 conversation\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Load working memory (now has 1 exchange from Turn 1)\n",
    "    _, turn2_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä Working Memory Status:\")\n",
    "    print(f\"   Messages in memory: {len(turn2_working_memory.messages)}\")\n",
    "    print(f\"   Contains: Turn 1 conversation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1b46d58f3b20d",
   "metadata": {},
   "source": [
    "#### Step 3: Build context with conversation history\n",
    "\n",
    "To resolve the pronoun \"its\", we need to include the conversation history in the LLM context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b9ded0ac51de86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:44.973788Z",
     "iopub.status.busy": "2025-12-09T19:44:44.973666Z",
     "iopub.status.idle": "2025-12-09T19:44:44.976737Z",
     "shell.execute_reply": "2025-12-09T19:44:44.976111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building context with conversation history...\n",
      "   Total messages in context: 24\n",
      "   Includes: System prompt + Turn 1 history + current query\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(f\"\\nüîß Building context with conversation history...\")\n",
    "\n",
    "    # Start with system message\n",
    "    turn2_messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful course advisor. Use conversation history to resolve references like 'it', 'that course', etc.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Add conversation history from working memory\n",
    "    for msg in turn2_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            turn2_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            turn2_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Add current query\n",
    "    turn2_messages.append(HumanMessage(content=turn2_query))\n",
    "\n",
    "    print(f\"   Total messages in context: {len(turn2_messages)}\")\n",
    "    print(f\"   Includes: System prompt + Turn 1 history + current query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680baddab86f534e",
   "metadata": {},
   "source": [
    "#### Step 4: Generate response using LLM\n",
    "\n",
    "The LLM can now resolve \"its\" by looking at the conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30ea9d9182b2beeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:44.978290Z",
     "iopub.status.busy": "2025-12-09T19:44:44.978183Z",
     "iopub.status.idle": "2025-12-09T19:44:47.775950Z",
     "shell.execute_reply": "2025-12-09T19:44:47.774761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ LLM resolving 'its' using conversation history...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:47 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: The prerequisite for the \"Data Structures and Algorithms\" course (CS009) is CS001. This prerequisite ensures that students have a foundational understanding of computer science principles and basic programming skills, which are essential for tackling the more advanced topics covered in data structures and algorithms.\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(f\"\\nüí≠ LLM resolving 'its' using conversation history...\")\n",
    "    turn2_response = llm.invoke(turn2_messages).content\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {turn2_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd00ff09f527aff",
   "metadata": {},
   "source": [
    "#### Step 5: Save to working memory\n",
    "\n",
    "Add this turn's conversation to working memory for future turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2c0ec81187f379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:47.779215Z",
     "iopub.status.busy": "2025-12-09T19:44:47.778926Z",
     "iopub.status.idle": "2025-12-09T19:44:47.800587Z",
     "shell.execute_reply": "2025-12-09T19:44:47.799031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:47 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved to working memory\n",
      "   Messages now in memory: 24\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Add messages to working memory\n",
    "    turn2_working_memory.messages.extend(\n",
    "        [\n",
    "            MemoryMessage(role=\"user\", content=turn2_query),\n",
    "            MemoryMessage(role=\"assistant\", content=turn2_response),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=turn2_working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved to working memory\")\n",
    "    print(f\"   Messages now in memory: {len(turn2_working_memory.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dc82b0b179c3a",
   "metadata": {},
   "source": [
    "### What Just Happened in Turn 2?\n",
    "\n",
    "**Initial State:**\n",
    "- Working memory contained Turn 1 conversation (2 messages)\n",
    "- User asked about \"its prerequisites\" - pronoun reference\n",
    "\n",
    "**Actions:**\n",
    "1. Loaded working memory with Turn 1 history\n",
    "2. Built context including conversation history\n",
    "3. LLM resolved \"its\" ‚Üí Data Structures and Algorithms (from Turn 1)\n",
    "4. Generated response about Data Structures and Algorithms's prerequisites\n",
    "5. Saved updated conversation to working memory\n",
    "\n",
    "**Result:**\n",
    "- Working memory now contains 4 messages (2 exchanges)\n",
    "- LLM successfully resolved pronoun reference using conversation history\n",
    "- Natural conversation flow maintained\n",
    "\n",
    "**Key Insight:** Without working memory, the LLM wouldn't know what \"its\" refers to!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8d7ec9cc0cd09",
   "metadata": {},
   "source": [
    "### Turn 3: Another Follow-up\n",
    "\n",
    "Let's ask one more follow-up question to demonstrate continued conversation continuity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e559273936233",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc4bc7899cdb4a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:47.803205Z",
     "iopub.status.busy": "2025-12-09T19:44:47.802997Z",
     "iopub.status.idle": "2025-12-09T19:44:47.806116Z",
     "shell.execute_reply": "2025-12-09T19:44:47.805517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 3: User asks another follow-up\n",
      "================================================================================\n",
      "\n",
      "üë§ User: Can I take it next semester?\n",
      "   Note: 'it' refers to Data Structures and Algorithms from Turn 1\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 3: User asks another follow-up\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    turn3_query = \"Can I take it next semester?\"\n",
    "    print(f\"\\nüë§ User: {turn3_query}\")\n",
    "    print(f\"   Note: 'it' refers to Data Structures and Algorithms from Turn 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822bee53d5f72aa",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory with full conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef1b5784db41cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:47.808340Z",
     "iopub.status.busy": "2025-12-09T19:44:47.808189Z",
     "iopub.status.idle": "2025-12-09T19:44:47.820879Z",
     "shell.execute_reply": "2025-12-09T19:44:47.820426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:47 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Working Memory Status:\n",
      "   Messages in memory: 24\n",
      "   Contains: Turns 1 and 2\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Load working memory (now has 2 exchanges)\n",
    "    _, turn3_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä Working Memory Status:\")\n",
    "    print(f\"   Messages in memory: {len(turn3_working_memory.messages)}\")\n",
    "    print(f\"   Contains: Turns 1 and 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108d55a0822552",
   "metadata": {},
   "source": [
    "#### Step 3: Build context and generate response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6385c7befbd151c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:47.822818Z",
     "iopub.status.busy": "2025-12-09T19:44:47.822690Z",
     "iopub.status.idle": "2025-12-09T19:44:50.945372Z",
     "shell.execute_reply": "2025-12-09T19:44:50.944594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total messages in context: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:50 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Yes, you can take the \"Data Structures and Algorithms\" course (CS009) next semester. It's important to ensure that you have completed the prerequisite course, CS001, before enrolling. If you meet the prerequisite requirement, you should be able to register for the course when enrollment opens for the next semester. Be sure to check with your academic advisor or the course catalog for specific enrollment dates and any additional requirements.\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Build context with full conversation history\n",
    "    turn3_messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful course advisor. Use conversation history to resolve references.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for msg in turn3_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            turn3_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            turn3_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    turn3_messages.append(HumanMessage(content=turn3_query))\n",
    "\n",
    "    print(f\"   Total messages in context: {len(turn3_messages)}\")\n",
    "\n",
    "    # Generate response\n",
    "    turn3_response = llm.invoke(turn3_messages).content\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {turn3_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac080d85ee7ab8aa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "‚úÖ DEMO COMPLETE: Working memory enabled natural conversation flow!\n",
    "\n",
    "---\n",
    "### Working Memory Demo Summary\n",
    "\n",
    "Let's review what we just demonstrated across three conversation turns.\n",
    "\n",
    "## üéØ Working Memory Demo Summary\n",
    "### üìä What Happened:\n",
    "**Turn 1:** 'Tell me about Data Structures and Algorithms'\n",
    "- Working memory: empty (first turn)\n",
    "- Stored query and response\n",
    "\n",
    "**Turn 2:** 'What are its prerequisites?'\n",
    "- Working memory: 1 exchange (Turn 1)\n",
    "- LLM resolved 'its' ‚Üí Data Structures and Algorithms using history\n",
    "- Generated accurate response\n",
    "\n",
    "**Turn 3:** 'Can I take it next semester?'\n",
    "- Working memory: 2 exchanges (Turns 1-2)\n",
    "- LLM resolved 'it' ‚Üí Data Structures and Algorithms using history\n",
    "- Maintained conversation continuity\n",
    "\n",
    "#### ‚úÖ Key Benefits:\n",
    "- Natural conversation flow\n",
    "- Pronoun reference resolution\n",
    "- No need to repeat context\n",
    "- Seamless user experience\n",
    "\n",
    "#### ‚ùå Without Working Memory:\n",
    "- 'What are its prerequisites?' ‚Üí 'What is its?' Or \"General information without data from the LLM's training\"\n",
    "- Each query is isolated\n",
    "- User must repeat context every time\n",
    "\n",
    "### Key Insight: Conversation Context Type\n",
    "\n",
    "Working memory provides the **Conversation Context** - the third context type from Section 1:\n",
    "\n",
    "1. **System Context** - Role and instructions (static)\n",
    "2. **User Context** - Profile and preferences (dynamic, user-specific)\n",
    "3. **Conversation Context** - Working memory (dynamic, session-specific) ‚Üê **We just demonstrated this!**\n",
    "4. **Retrieved Context** - RAG results (dynamic, query-specific)\n",
    "\n",
    "Without working memory, we only had 3 context types. Now we have all 4!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ac6fbfacb1a8c",
   "metadata": {},
   "source": [
    "---\n",
    "# üìö Part 2: Long-term Memory for Context Engineering\n",
    "\n",
    "## What is Long-term Memory?\n",
    "\n",
    "Long-term memory enables AI agents to store **persistent knowledge** across sessions‚Äîincluding user preferences, domain facts, business rules, and system configuration. This is crucial for context engineering because it allows agents to:\n",
    "\n",
    "- **Personalize** interactions by remembering user-specific preferences and history\n",
    "- **Apply domain knowledge** consistently (prerequisites, policies, regulations)\n",
    "- **Maintain organizational context** (business rules, schedules, procedures)\n",
    "- **Search efficiently** using semantic vector search across all knowledge types\n",
    "\n",
    "Long-term memory is a flexible storage mechanism: user-scoped memories enable personalization (\"Student prefers online courses\"), while application-scoped memories provide consistent behavior for everyone (\"CS401 requires CS201\", \"Registration opens 2 weeks before semester\").\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Session 1: User shares preferences ‚Üí Store in long-term memory\n",
    "Session 2: User asks for recommendations ‚Üí Search memory ‚Üí Personalized response\n",
    "Session 3: User updates preferences ‚Üí Update memory accordingly\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Three Types of Long-term Memory\n",
    "\n",
    "The Agent Memory Server supports three distinct memory types, each optimized for different kinds of information:\n",
    "\n",
    "### 1. Semantic Memory - Facts and Knowledge\n",
    "\n",
    "**Purpose:** Store timeless facts, preferences, and knowledge independent of when they were learned. Can be user-scoped (personalization) or application-scoped (domain knowledge).\n",
    "\n",
    "**User-Scoped Examples:**\n",
    "- \"Student's major is Computer Science\"\n",
    "- \"Student prefers online courses\"\n",
    "- \"Student wants to graduate in Spring 2026\"\n",
    "- \"Student is interested in machine learning\"\n",
    "\n",
    "**Application-Scoped Examples:**\n",
    "- \"CS401 requires CS201 and MATH301 as prerequisites\"\n",
    "- \"Online courses have asynchronous discussion forums\"\n",
    "- \"Academic advisors are available Monday-Friday 9am-5pm\"\n",
    "- \"Maximum file upload size for assignments is 50MB\"\n",
    "\n",
    "**When to use:** Information that remains true regardless of time context, whether user-specific or universally applicable.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Episodic Memory - Events and Experiences\n",
    "\n",
    "**Purpose:** Store time-bound events and experiences where sequence matters.\n",
    "\n",
    "**Examples:**\n",
    "- \"Student enrolled in CS101 on 2024-09-15\"\n",
    "- \"Student completed CS101 with grade A on 2024-12-10\"\n",
    "- \"Student asked about machine learning courses on 2024-09-20\"\n",
    "\n",
    "**When to use:** Timeline-based information where timing or sequence is important.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Message Memory - Context-Rich Conversations\n",
    "\n",
    "**Purpose:** Store full conversation snippets where complete context is crucial.\n",
    "\n",
    "**Examples:**\n",
    "- Detailed career planning discussion with nuanced advice\n",
    "- Professor's specific guidance about research opportunities\n",
    "- Student's explanation of personal learning challenges\n",
    "\n",
    "**When to use:** When summary would lose important nuance, tone, or exact wording.\n",
    "\n",
    "**‚ö†Ô∏è Use sparingly** - Message memories are token-expensive!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Choosing the Right Memory Type\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**Ask yourself these questions:**\n",
    "\n",
    "1. **Can you extract a simple fact?** ‚Üí Use **Semantic**\n",
    "2. **Does timing matter?** ‚Üí Use **Episodic**\n",
    "3. **Is full context crucial?** ‚Üí Use **Message** (rarely)\n",
    "\n",
    "**Default strategy: Prefer Semantic** - they're compact, searchable, and efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Reference Table\n",
    "\n",
    "| Information Type | Memory Type | Example |\n",
    "|-----------------|-------------|----------|\n",
    "| Preference | Semantic | \"Prefers morning classes\" |\n",
    "| Fact | Semantic | \"Major is Computer Science\" |\n",
    "| Goal | Semantic | \"Wants to graduate in 2026\" |\n",
    "| Event | Episodic | \"Enrolled in CS401 on 2024-09-15\" |\n",
    "| Timeline | Episodic | \"Completed CS101, then CS201\" |\n",
    "| Complex discussion | Message | [Full career planning conversation] |\n",
    "| Nuanced advice | Message | [Professor's detailed guidance] |\n",
    "\n",
    "---\n",
    "\n",
    "## Examples: Right vs. Wrong Choices\n",
    "\n",
    "### Scenario 1: Student States Preference\n",
    "\n",
    "**User says:** \"I prefer online courses because I work during the day.\"\n",
    "\n",
    "‚ùå **Wrong - Message memory (too verbose):**\n",
    "```python\n",
    "memory = \"Student said: 'I prefer online courses because I work during the day.'\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Semantic memories (extracted facts):**\n",
    "```python\n",
    "memory1 = \"Student prefers online courses\"\n",
    "memory2 = \"Student works during the day\"\n",
    "```\n",
    "\n",
    "**Why:** Simple facts don't need verbatim storage.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 2: Course Completion\n",
    "\n",
    "**User says:** \"I just finished CS101 last week!\"\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses temporal context):**\n",
    "```python\n",
    "memory = \"Student completed CS101\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Episodic (preserves timeline):**\n",
    "```python\n",
    "memory = \"Student completed CS101 on 2024-10-20\"\n",
    "```\n",
    "\n",
    "**Why:** Timeline matters for prerequisites and future planning.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 3: Complex Career Advice\n",
    "\n",
    "**Context:** 20-message discussion about career path including nuanced advice about research vs. industry, application timing, and specific companies to target.\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses too much context):**\n",
    "```python\n",
    "memory = \"Student discussed career planning\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Message memory (preserves full context):**\n",
    "```python\n",
    "memory = [Full conversation thread with all nuance]\n",
    "```\n",
    "\n",
    "**Why:** Details and context are critical; summary would be inadequate.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Most memories should be semantic** - efficient and searchable\n",
    "- **Use episodic when sequence matters** - track progress and timeline\n",
    "- **Use message rarely** - only when context cannot be summarized\n",
    "- **Effective memory selection improves personalization** and reduces token usage\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Long-term Memory in Action\n",
    "\n",
    "Let's put these concepts into practice with code examples..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e9f58388e9a5a",
   "metadata": {},
   "source": [
    "### Setup: Student ID for Long-term Memory\n",
    "\n",
    "Long-term memories are user-scoped, so we need a student ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546a97b8d4edcce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:50.947216Z",
     "iopub.status.busy": "2025-12-09T19:44:50.947088Z",
     "iopub.status.idle": "2025-12-09T19:44:50.949800Z",
     "shell.execute_reply": "2025-12-09T19:44:50.949211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Long-term Memory Demo Setup\n",
      "   Student ID: sarah_chen\n",
      "   Ready to store and search persistent memories\n"
     ]
    }
   ],
   "source": [
    "# Setup for long-term memory demo\n",
    "lt_student_id = \"sarah_chen\"\n",
    "\n",
    "print(\"üéØ Long-term Memory Demo Setup\")\n",
    "print(f\"   Student ID: {lt_student_id}\")\n",
    "print(\"   Ready to store and search persistent memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064a537054755e4",
   "metadata": {},
   "source": [
    "### Step 1: Store Semantic Memories (Facts)\n",
    "\n",
    "Semantic memories are timeless facts about the student. Let's store several facts about Sarah's preferences and academic status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f085eec1e55223e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:50.951269Z",
     "iopub.status.busy": "2025-12-09T19:44:50.951154Z",
     "iopub.status.idle": "2025-12-09T19:44:50.959928Z",
     "shell.execute_reply": "2025-12-09T19:44:50.959307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìç STEP 1: Storing Semantic Memories (Facts)\n",
      "================================================================================\n",
      "\n",
      "üìù Storing 6 semantic memories...\n",
      "14:44:50 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student is currently taking Linear Algebra\n",
      "\n",
      "‚úÖ Stored 6 semantic memories\n",
      "   Memory type: semantic (timeless facts)\n",
      "   Topics: preferences, academic_info\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìç STEP 1: Storing Semantic Memories (Facts)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define semantic memories (timeless facts)\n",
    "semantic_memories = [\n",
    "    \"Student prefers online courses over in-person classes\",\n",
    "    \"Student's major is Computer Science with focus on AI/ML\",\n",
    "    \"Student wants to graduate in Spring 2026\",\n",
    "    \"Student prefers morning classes, no classes on Fridays\",\n",
    "    \"Student has completed Introduction to Programming and Data Structures\",\n",
    "    \"Student is currently taking Linear Algebra\",\n",
    "]\n",
    "print(f\"\\nüìù Storing {len(semantic_memories)} semantic memories...\")\n",
    "\n",
    "# Store each semantic memory\n",
    "for memory_text in semantic_memories:\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=memory_text,\n",
    "        user_id=lt_student_id,\n",
    "        memory_type=\"semantic\",\n",
    "        topics=[\"preferences\", \"academic_info\"],\n",
    "    )\n",
    "await memory_client.create_long_term_memory([memory_record])\n",
    "print(f\"   ‚úÖ {memory_text}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Stored {len(semantic_memories)} semantic memories\")\n",
    "print(\"   Memory type: semantic (timeless facts)\")\n",
    "print(\"   Topics: preferences, academic_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e63cbfc1cb44f",
   "metadata": {},
   "source": [
    "### What We Just Did: Semantic Memories\n",
    "\n",
    "**Stored 6 semantic memories:**\n",
    "- Student preferences (online courses, morning classes)\n",
    "- Academic information (major, graduation date)\n",
    "- Course history (completed, current)\n",
    "\n",
    "**Why semantic?**\n",
    "- These are timeless facts\n",
    "- No specific date/time context needed\n",
    "- Compact and efficient\n",
    "\n",
    "**How they're stored:**\n",
    "- Vector-indexed for semantic search\n",
    "- Tagged with topics for organization\n",
    "- Automatically deduplicated\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e3f434ed5da5f",
   "metadata": {},
   "source": [
    "### Step 2: Store Episodic Memories (Events)\n",
    "\n",
    "Episodic memories are time-bound events. Let's store some events from Sarah's academic timeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b01e52eef818ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:50.962355Z",
     "iopub.status.busy": "2025-12-09T19:44:50.962105Z",
     "iopub.status.idle": "2025-12-09T19:44:50.975556Z",
     "shell.execute_reply": "2025-12-09T19:44:50.974773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç STEP 2: Storing Episodic Memories (Events)\n",
      "================================================================================\n",
      "\n",
      "üìù Storing 3 episodic memories...\n",
      "14:44:50 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student enrolled in Introduction to Programming on 2024-09-01\n",
      "14:44:50 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student completed Introduction to Programming with grade A on 2024-12-15\n",
      "14:44:50 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student asked about machine learning courses on 2024-09-20\n",
      "\n",
      "‚úÖ Stored 3 episodic memories\n",
      "   Memory type: episodic (time-bound events)\n",
      "   Topics: enrollment, courses\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìç STEP 2: Storing Episodic Memories (Events)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define episodic memories (time-bound events)\n",
    "episodic_memories = [\n",
    "    \"Student enrolled in Introduction to Programming on 2024-09-01\",\n",
    "    \"Student completed Introduction to Programming with grade A on 2024-12-15\",\n",
    "    \"Student asked about machine learning courses on 2024-09-20\",\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Storing {len(episodic_memories)} episodic memories...\")\n",
    "\n",
    "# Store each episodic memory\n",
    "for memory_text in episodic_memories:\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=memory_text,\n",
    "        user_id=lt_student_id,\n",
    "        memory_type=\"episodic\",\n",
    "        topics=[\"enrollment\", \"courses\"],\n",
    "    )\n",
    "    await memory_client.create_long_term_memory([memory_record])\n",
    "    print(f\"   ‚úÖ {memory_text}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Stored {len(episodic_memories)} episodic memories\")\n",
    "print(\"   Memory type: episodic (time-bound events)\")\n",
    "print(\"   Topics: enrollment, courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea4f9c84d09a7a",
   "metadata": {},
   "source": [
    "### What We Just Did: Episodic Memories\n",
    "\n",
    "**Stored 3 episodic memories:**\n",
    "- Enrollment event (Introduction to Programming on 2024-09-01)\n",
    "- Completion event (Introduction to Programming with grade A on 2024-12-15)\n",
    "- Interaction event (asked about ML courses on 2024-09-20)\n",
    "\n",
    "**Why episodic?**\n",
    "- These are time-bound events\n",
    "- Timing and sequence matter\n",
    "- Captures academic timeline\n",
    "\n",
    "**Difference from semantic:**\n",
    "- Semantic: \"Student has completed Introduction to Programming\" (timeless fact)\n",
    "- Episodic: \"Student completed Introduction to Programming with grade A on 2024-12-15\" (specific event)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83186a67c7e672a",
   "metadata": {},
   "source": [
    "### Step 3: Search Long-term Memory\n",
    "\n",
    "Now let's search our long-term memories using natural language queries. The system will use semantic search to find relevant memories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b0dada127fa7d",
   "metadata": {},
   "source": [
    "#### Query 1: What does the student prefer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c3238ee46c77879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:50.977757Z",
     "iopub.status.busy": "2025-12-09T19:44:50.977595Z",
     "iopub.status.idle": "2025-12-09T19:44:51.165000Z",
     "shell.execute_reply": "2025-12-09T19:44:51.164101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç STEP 3: Searching Long-term Memory\n",
      "================================================================================\n",
      "\n",
      "üîç Query: 'What does the student prefer?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:51 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìö Found 3 relevant memories:\n",
      "      1. The student prefers online courses over in-person classes.\n",
      "      2. Student prefers morning classes\n",
      "      3. Student prefers morning classes, no classes on Fridays\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    from agent_memory_client.filters import UserId\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç STEP 3: Searching Long-term Memory\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    search_query_1 = \"What does the student prefer?\"\n",
    "    print(f\"\\nüîç Query: '{search_query_1}'\")\n",
    "\n",
    "    search_results_1 = await memory_client.search_long_term_memory(\n",
    "        text=search_query_1, user_id=UserId(eq=lt_student_id), limit=3\n",
    "    )\n",
    "\n",
    "    if search_results_1.memories:\n",
    "        print(f\"   üìö Found {len(search_results_1.memories)} relevant memories:\")\n",
    "        for i, memory in enumerate(search_results_1.memories[:3], 1):\n",
    "            print(f\"      {i}. {memory.text}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No memories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325c38bbad26d5d",
   "metadata": {},
   "source": [
    "#### Query 2: What courses has the student completed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15bc0d7b3702d072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:51.167163Z",
     "iopub.status.busy": "2025-12-09T19:44:51.166998Z",
     "iopub.status.idle": "2025-12-09T19:44:51.865931Z",
     "shell.execute_reply": "2025-12-09T19:44:51.865224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: 'What courses has the student completed?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:51 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìö Found 5 relevant memories:\n",
      "      1. Student has completed Introduction to Programming and Data Structures\n",
      "      2. Student completed Introduction to Programming with grade A on 2024-12-15\n",
      "      3. Student's major is Computer Science\n",
      "      4. Student is currently taking Linear Algebra\n",
      "      5. Student asked about machine learning courses on 2024-09-20\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    search_query_2 = \"What courses has the student completed?\"\n",
    "    print(f\"\\nüîç Query: '{search_query_2}'\")\n",
    "\n",
    "    search_results_2 = await memory_client.search_long_term_memory(\n",
    "        text=search_query_2, user_id=UserId(eq=lt_student_id), limit=5\n",
    "    )\n",
    "\n",
    "    if search_results_2.memories:\n",
    "        print(f\"   üìö Found {len(search_results_2.memories)} relevant memories:\")\n",
    "        for i, memory in enumerate(search_results_2.memories[:5], 1):\n",
    "            print(f\"      {i}. {memory.text}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No memories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fae19b2652477",
   "metadata": {},
   "source": [
    "#### Query 3: What is the student's major?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d77f0e7fd8b40b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:51.867979Z",
     "iopub.status.busy": "2025-12-09T19:44:51.867810Z",
     "iopub.status.idle": "2025-12-09T19:44:52.545610Z",
     "shell.execute_reply": "2025-12-09T19:44:52.544568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: 'What is the student's major?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:52 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üìö Found 3 relevant memories:\n",
      "      1. Student's major is Computer Science\n",
      "      2. Student's major is Computer Science with focus on AI/ML\n",
      "      3. Student wants to graduate in Spring 2026\n",
      "\n",
      "================================================================================\n",
      "‚úÖ DEMO COMPLETE: Long-term memory enables persistent knowledge!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    search_query_3 = \"What is the student's major?\"\n",
    "    print(f\"\\nüîç Query: '{search_query_3}'\")\n",
    "\n",
    "    search_results_3 = await memory_client.search_long_term_memory(\n",
    "        text=search_query_3, user_id=UserId(eq=lt_student_id), limit=3\n",
    "    )\n",
    "\n",
    "    if search_results_3.memories:\n",
    "        print(f\"   üìö Found {len(search_results_3.memories)} relevant memories:\")\n",
    "        for i, memory in enumerate(search_results_3.memories[:3], 1):\n",
    "            print(f\"      {i}. {memory.text}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No memories found\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Long-term memory enables persistent knowledge!\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79f16661490755",
   "metadata": {},
   "source": [
    "### Long-term Memory Demo Summary\n",
    "\n",
    "Let's review what we demonstrated with long-term memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a54dd4fd398bfb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:52.549004Z",
     "iopub.status.busy": "2025-12-09T19:44:52.548728Z",
     "iopub.status.idle": "2025-12-09T19:44:52.553399Z",
     "shell.execute_reply": "2025-12-09T19:44:52.552573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ LONG-TERM MEMORY DEMO SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä What We Did:\n",
      "   Step 1: Stored 6 semantic memories (facts)\n",
      "           ‚Üí Student preferences, major, graduation date\n",
      "           ‚Üí Tagged with topics: preferences, academic_info\n",
      "\n",
      "   Step 2: Stored 3 episodic memories (events)\n",
      "           ‚Üí Enrollment, completion, interaction events\n",
      "           ‚Üí Tagged with topics: enrollment, courses\n",
      "\n",
      "   Step 3: Searched long-term memory\n",
      "           ‚Üí Used natural language queries\n",
      "           ‚Üí Semantic search found relevant memories\n",
      "           ‚Üí No exact keyword matching needed\n",
      "\n",
      "‚úÖ Key Benefits:\n",
      "   ‚Ä¢ Persistent knowledge across sessions\n",
      "   ‚Ä¢ Semantic search (not keyword matching)\n",
      "   ‚Ä¢ Automatic deduplication\n",
      "   ‚Ä¢ Topic-based organization\n",
      "\n",
      "üí° Key Insight:\n",
      "   Long-term memory enables personalization and knowledge\n",
      "   accumulation across sessions. It's the foundation for\n",
      "   building agents that remember and learn from users.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üéØ LONG-TERM MEMORY DEMO SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìä What We Did:\")\n",
    "print(\"   Step 1: Stored 6 semantic memories (facts)\")\n",
    "print(\"           ‚Üí Student preferences, major, graduation date\")\n",
    "print(\"           ‚Üí Tagged with topics: preferences, academic_info\")\n",
    "print(\"\\n   Step 2: Stored 3 episodic memories (events)\")\n",
    "print(\"           ‚Üí Enrollment, completion, interaction events\")\n",
    "print(\"           ‚Üí Tagged with topics: enrollment, courses\")\n",
    "print(\"\\n   Step 3: Searched long-term memory\")\n",
    "print(\"           ‚Üí Used natural language queries\")\n",
    "print(\"           ‚Üí Semantic search found relevant memories\")\n",
    "print(\"           ‚Üí No exact keyword matching needed\")\n",
    "print(\"\\n‚úÖ Key Benefits:\")\n",
    "print(\"   ‚Ä¢ Persistent knowledge across sessions\")\n",
    "print(\"   ‚Ä¢ Semantic search (not keyword matching)\")\n",
    "print(\"   ‚Ä¢ Automatic deduplication\")\n",
    "print(\"   ‚Ä¢ Topic-based organization\")\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   Long-term memory enables personalization and knowledge\")\n",
    "print(\"   accumulation across sessions. It's the foundation for\")\n",
    "print(\"   building agents that remember and learn from users.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e71eba49c4186c",
   "metadata": {},
   "source": [
    "### Key Insight: User Context Type\n",
    "\n",
    "Long-term memory provides part of the **User Context** - the second context type from Section 1:\n",
    "\n",
    "1. **System Context** - Role and instructions (static)\n",
    "2. **User Context** - Profile + long-term memories (dynamic, user-specific) ‚Üê **Long-term memories contribute here!**\n",
    "3. **Conversation Context** - Working memory (dynamic, session-specific)\n",
    "4. **Retrieved Context** - RAG results (dynamic, query-specific)\n",
    "\n",
    "Long-term memories enhance User Context by adding persistent knowledge about the user's preferences, history, and goals.\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑Ô∏è Advanced: Topics and Filtering\n",
    "\n",
    "Topics help organize and filter memories. Let's explore how to use them effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257eef2f0a46b70",
   "metadata": {},
   "source": [
    "### Step 1: Store memories with topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5195f3f351cb42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:52.555485Z",
     "iopub.status.busy": "2025-12-09T19:44:52.555319Z",
     "iopub.status.idle": "2025-12-09T19:44:52.570445Z",
     "shell.execute_reply": "2025-12-09T19:44:52.569879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üè∑Ô∏è  TOPICS AND FILTERING DEMO\n",
      "================================================================================\n",
      "\n",
      "üìç Storing Memories with Topics\n",
      "--------------------------------------------------------------------------------\n",
      "14:44:52 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student prefers online courses\n",
      "      Topics: preferences, course_format\n",
      "14:44:52 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student's major is Computer Science\n",
      "      Topics: academic_info, major\n",
      "14:44:52 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student wants to graduate in Spring 2026\n",
      "      Topics: goals, graduation\n",
      "14:44:52 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Student prefers morning classes\n",
      "      Topics: preferences, schedule\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    topics_student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üè∑Ô∏è  TOPICS AND FILTERING DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nüìç Storing Memories with Topics\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Define memories with their topics\n",
    "    memories_with_topics = [\n",
    "        (\"Student prefers online courses\", [\"preferences\", \"course_format\"]),\n",
    "        (\"Student's major is Computer Science\", [\"academic_info\", \"major\"]),\n",
    "        (\"Student wants to graduate in Spring 2026\", [\"goals\", \"graduation\"]),\n",
    "        (\"Student prefers morning classes\", [\"preferences\", \"schedule\"]),\n",
    "    ]\n",
    "\n",
    "    # Store each memory\n",
    "    for memory_text, topics in memories_with_topics:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=topics_student_id,\n",
    "            memory_type=\"semantic\",\n",
    "            topics=topics,\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ {memory_text}\")\n",
    "        print(f\"      Topics: {', '.join(topics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1795b81a16b4d63b",
   "metadata": {},
   "source": [
    "### Step 2: Filter memories by type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe9d3d303cb2f8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:52.572064Z",
     "iopub.status.busy": "2025-12-09T19:44:52.571937Z",
     "iopub.status.idle": "2025-12-09T19:44:53.153947Z",
     "shell.execute_reply": "2025-12-09T19:44:53.153181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç Filtering by Memory Type: Semantic\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:53 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 9 semantic memories:\n",
      "   1. The student prefers online courses over in-person classes.\n",
      "      Topics: preferences, course_format, academic_info\n",
      "   2. Student is currently taking Linear Algebra\n",
      "      Topics: preferences, academic_info\n",
      "   3. Student's major is Computer Science\n",
      "      Topics: academic_info, major\n",
      "   4. Student prefers morning classes\n",
      "      Topics: preferences, schedule\n",
      "   5. Student is interested in machine learning and AI\n",
      "      Topics: interests, AI\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Topics enable organized, filterable memory management!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\nüìç Filtering by Memory Type: Semantic\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    from agent_memory_client.filters import MemoryType, UserId\n",
    "\n",
    "    # Search for all semantic memories\n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=\"\",  # Empty query returns all\n",
    "        user_id=UserId(eq=topics_student_id),\n",
    "        memory_type=MemoryType(eq=\"semantic\"),\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    print(f\"   Found {len(results.memories)} semantic memories:\")\n",
    "    for i, memory in enumerate(results.memories[:5], 1):\n",
    "        topics_str = \", \".join(memory.topics) if memory.topics else \"none\"\n",
    "        print(f\"   {i}. {memory.text}\")\n",
    "        print(f\"      Topics: {topics_str}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Topics enable organized, filterable memory management!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d75fff675a3c0",
   "metadata": {},
   "source": [
    "### üéØ Why Topics Matter\n",
    "\n",
    "**Organization:**\n",
    "- Group related memories together\n",
    "- Easy to find memories by category\n",
    "\n",
    "**Filtering:**\n",
    "- Search within specific topics\n",
    "- Filter by memory type (semantic, episodic, message)\n",
    "\n",
    "**Best Practices:**\n",
    "- Use consistent topic names\n",
    "- Keep topics broad enough to be useful\n",
    "- Common topics: `preferences`, `academic_info`, `goals`, `schedule`, `courses`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Cross-Session Memory Persistence\n",
    "\n",
    "Let's verify that memories persist across sessions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f3d6a0081ec90",
   "metadata": {},
   "source": [
    "### Step 1: Session 1 - Store memories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6a79bf4d4bad524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:53.156508Z",
     "iopub.status.busy": "2025-12-09T19:44:53.156303Z",
     "iopub.status.idle": "2025-12-09T19:44:53.163159Z",
     "shell.execute_reply": "2025-12-09T19:44:53.162383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîÑ CROSS-SESSION MEMORY PERSISTENCE DEMO\n",
      "================================================================================\n",
      "\n",
      "üìç SESSION 1: Storing Memories\n",
      "--------------------------------------------------------------------------------\n",
      "14:44:53 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Stored: Student is interested in machine learning and AI\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    cross_session_student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîÑ CROSS-SESSION MEMORY PERSISTENCE DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nüìç SESSION 1: Storing Memories\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=\"Student is interested in machine learning and AI\",\n",
    "        user_id=cross_session_student_id,\n",
    "        memory_type=\"semantic\",\n",
    "        topics=[\"interests\", \"AI\"],\n",
    "    )\n",
    "    await memory_client.create_long_term_memory([memory_record])\n",
    "    print(\"   ‚úÖ Stored: Student is interested in machine learning and AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566b9b23eb6f60a",
   "metadata": {},
   "source": [
    "### Step 2: Session 2 - Create new client and retrieve memories\n",
    "\n",
    "Simulate a new session by creating a new memory client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "327c07072ee9f573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:53.165003Z",
     "iopub.status.busy": "2025-12-09T19:44:53.164861Z",
     "iopub.status.idle": "2025-12-09T19:44:53.358771Z",
     "shell.execute_reply": "2025-12-09T19:44:53.358026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç SESSION 2: New Session, Same Student\n",
      "--------------------------------------------------------------------------------\n",
      "   üîÑ New session started for the same student\n",
      "\n",
      "   üîç Searching: 'What are the student's interests?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:53 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ Memories accessible from new session:\n",
      "      1. Student is interested in machine learning and AI\n",
      "      2. Student's major is Computer Science\n",
      "      3. Student's major is Computer Science with focus on AI/ML\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Long-term memories persist across sessions!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Search for memories from the new session\n",
    "from agent_memory_client.filters import UserId\n",
    "\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\nüìç SESSION 2: New Session, Same Student\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Create a new memory client (simulating a new session)\n",
    "    new_session_config = MemoryClientConfig(\n",
    "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
    "        default_namespace=\"redis_university\",\n",
    "    )\n",
    "    new_session_client = MemoryAPIClient(config=new_session_config)\n",
    "\n",
    "    print(\"   üîÑ New session started for the same student\")\n",
    "\n",
    "    print(\"\\n   üîç Searching: 'What are the student's interests?'\")\n",
    "    cross_session_results = await new_session_client.search_long_term_memory(\n",
    "        text=\"What are the student's interests?\",\n",
    "        user_id=UserId(eq=cross_session_student_id),\n",
    "        limit=3,\n",
    "    )\n",
    "\n",
    "    if cross_session_results.memories:\n",
    "        print(f\"\\n   ‚úÖ Memories accessible from new session:\")\n",
    "        for i, memory in enumerate(cross_session_results.memories[:3], 1):\n",
    "            print(f\"      {i}. {memory.text}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No memories found\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Long-term memories persist across sessions!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973cb3f4b2576f9a",
   "metadata": {},
   "source": [
    "### üéØ Cross-Session Persistence\n",
    "\n",
    "**What We Demonstrated:**\n",
    "- **Session 1:** Stored memories about student interests\n",
    "- **Session 2:** Created new client (simulating new session)\n",
    "- **Result:** Memories from Session 1 are accessible in Session 2\n",
    "\n",
    "**Why This Matters:**\n",
    "- Users don't have to repeat themselves\n",
    "- Personalization works across days, weeks, months\n",
    "- Knowledge accumulates over time\n",
    "\n",
    "**Contrast with Working Memory:**\n",
    "- Working memory: Session-scoped (persists within the session, like ChatGPT conversations)\n",
    "- Long-term memory: User-scoped (persists across all sessions indefinitely)\n",
    "\n",
    "---\n",
    "\n",
    "## üîó What's Next: Memory-Enhanced RAG and Agents\n",
    "\n",
    "You've learned the fundamentals of memory architecture! Now it's time to put it all together.\n",
    "\n",
    "### **Next Notebook: `02_combining_memory_with_retrieved_context.ipynb`**\n",
    "\n",
    "In the next notebook, you'll:\n",
    "\n",
    "1. **Build** a complete memory-enhanced RAG system\n",
    "   - Integrate working memory + long-term memory + RAG\n",
    "   - Combine all four context types\n",
    "   - Show clear before/after comparisons\n",
    "\n",
    "2. **Convert** to LangGraph agent (Part 2, separate notebook)\n",
    "   - Add state management\n",
    "   - Improve control flow\n",
    "   - Prepare for Section 4 (tools and advanced capabilities)\n",
    "\n",
    "**Why Continue?**\n",
    "- See memory in action with real conversations\n",
    "- Learn how to build production-ready agents\n",
    "- Prepare for Section 4 (adding tools like enrollment, scheduling)\n",
    "\n",
    "**üìö Continue to:** `02_combining_memory_with_retrieved_context.ipynb`\n",
    "\n",
    "## ‚è∞ Memory Lifecycle & Persistence\n",
    "\n",
    "Understanding how working memory and long-term memory persist is crucial for building reliable systems.\n",
    "\n",
    "### **Working Memory Persistence**\n",
    "\n",
    "**How it works:** Just like ChatGPT or Claude conversations\n",
    "\n",
    "**What this means:**\n",
    "- When you return to a conversation, the working memory is still there\n",
    "- The conversation doesn't disappear when you close the tab\n",
    "- Full conversation history remains accessible within the session\n",
    "- **Backend optimization:** TTL for storage management (not user-facing)\n",
    "\n",
    "**User Experience:**\n",
    "\n",
    "```\n",
    "Day 1, 10:00 AM - User starts conversation\n",
    "Day 1, 10:25 AM - User closes browser\n",
    "    ‚Üì\n",
    "[User returns later]\n",
    "    ‚Üì\n",
    "Day 1, 3:00 PM - User reopens conversation\n",
    "                 ‚Üí Working memory still there ‚úÖ\n",
    "                 ‚Üí Conversation continues naturally ‚úÖ\n",
    "```\n",
    "\n",
    "**The Real Challenge: Context Window Limits**\n",
    "\n",
    "Working memory doesn't \"expire\" - but it can grow too large:\n",
    "- LLMs have context window limits (e.g., 128K tokens for GPT-4)\n",
    "- Long conversations eventually exceed these limits\n",
    "- **Solution:** Compression strategies (covered in Notebook 03)\n",
    "\n",
    "### **Long-term Memory Persistence**\n",
    "\n",
    "**Lifetime:** Indefinite (until manually deleted)\n",
    "\n",
    "**What this means:**\n",
    "- Long-term memories never expire automatically\n",
    "- Accessible across all sessions, forever\n",
    "- Must be explicitly deleted if no longer needed\n",
    "\n",
    "### **Why This Design?**\n",
    "\n",
    "**Working Memory (Session-Persistent):**\n",
    "- Stores full conversation history for the session\n",
    "- Persists when you return to the conversation (like ChatGPT)\n",
    "- **Challenge:** Can grow too large for context window\n",
    "- **Solution:** Compression strategies (Notebook 03)\n",
    "\n",
    "**Long-term Memory (Cross-Session Persistent):**\n",
    "- Important facts extracted from conversations\n",
    "- User preferences don't expire\n",
    "- Knowledge accumulates over time\n",
    "- Enables true personalization across sessions\n",
    "\n",
    "### **Important Implications**\n",
    "\n",
    "**1. Automatic Extraction to Long-term Memory**\n",
    "\n",
    "Important facts from conversations are automatically extracted to long-term memory.\n",
    "\n",
    "**Good news:** Agent Memory Server does this automatically in the background!\n",
    "\n",
    "**2. Long-term Memories are Permanent**\n",
    "\n",
    "Once stored, long-term memories persist indefinitely. Be thoughtful about what you store.\n",
    "\n",
    "**3. Cross-Session Behavior**\n",
    "\n",
    "```\n",
    "Session 1 (Day 1):\n",
    "- User: \"I'm interested in machine learning\"\n",
    "- Working memory: Stores full conversation\n",
    "- Long-term memory: Extracts \"Student interested in machine learning\"\n",
    "\n",
    "[User starts a NEW session on Day 3]\n",
    "\n",
    "Session 2 (Day 3):\n",
    "- Working memory: NEW session, starts empty ‚úÖ\n",
    "- Long-term memory: Still has \"Student interested in machine learning\" ‚úÖ\n",
    "- Agent retrieves long-term memory for personalization ‚úÖ\n",
    "- Agent makes relevant recommendations ‚úÖ\n",
    "```\n",
    "\n",
    "**Key Distinction:**\n",
    "- **Same session:** Working memory persists (like returning to a ChatGPT conversation)\n",
    "- **New session:** Working memory starts fresh, but long-term memories are available\n",
    "\n",
    "### **Practical Multi-Day Conversation Example**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f59dd2bae29f763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:44:53.361364Z",
     "iopub.status.busy": "2025-12-09T19:44:53.361170Z",
     "iopub.status.idle": "2025-12-09T19:44:53.690517Z",
     "shell.execute_reply": "2025-12-09T19:44:53.689500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚è∞ MULTI-DAY CONVERSATION SIMULATION\n",
      "================================================================================\n",
      "\n",
      "üìÖ DAY 1: Initial Conversation\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: Student is preparing for a career in AI research\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:53 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Stored in long-term memory: Career goal (AI research)\n",
      "   üí¨ Working memory: Active for session_day1\n",
      "   üìù Note: If user returns to THIS session, working memory persists\n",
      "\n",
      "üìÖ DAY 3: NEW Conversation (different session)\n",
      "--------------------------------------------------------------------------------\n",
      "   üÜï Working memory: NEW session, starts empty\n",
      "   ‚úÖ Long-term memory: Still available across all sessions\n",
      "\n",
      "Text: What are the student's career goals?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:44:53 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üîç Retrieved from long-term memory:\n",
      "      ‚Ä¢ Student wants to graduate in Spring 2026\n",
      "      ‚Ä¢ Student's major is Computer Science\n",
      "      ‚Ä¢ Student's major is Computer Science with focus on AI/ML\n",
      "\n",
      "   ‚úÖ Agent can still personalize recommendations!\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Long-term memories persist across sessions, working memory is session-scoped\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Multi-Day Conversation Simulation\n",
    "from agent_memory_client.filters import UserId\n",
    "\n",
    "\n",
    "async def multi_day_simulation():\n",
    "    \"\"\"Simulate conversations across multiple days\"\"\"\n",
    "\n",
    "    student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚è∞ MULTI-DAY CONVERSATION SIMULATION\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Day 1: Initial conversation\n",
    "    print(\"\\nüìÖ DAY 1: Initial Conversation\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    session_1 = f\"session_{student_id}_day1\"\n",
    "    text = \"Student is preparing for a career in AI research\"\n",
    "    print(f\"\\nText: {text}\\n\")\n",
    "    # Store a fact in long-term memory\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=text,\n",
    "        user_id=student_id,\n",
    "        memory_type=\"semantic\",\n",
    "        topics=[\"career\", \"goals\"],\n",
    "    )\n",
    "    await memory_client.create_long_term_memory([memory_record])\n",
    "    print(\"   ‚úÖ Stored in long-term memory: Career goal (AI research)\")\n",
    "\n",
    "    # Simulate working memory (would normally be conversation)\n",
    "    print(\"   üí¨ Working memory: Active for session_day1\")\n",
    "    print(\"   üìù Note: If user returns to THIS session, working memory persists\")\n",
    "\n",
    "    # Day 3: NEW conversation (different session)\n",
    "    print(\"\\nüìÖ DAY 3: NEW Conversation (different session)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    session_2 = f\"session_{student_id}_day3\"\n",
    "\n",
    "    print(\"   üÜï Working memory: NEW session, starts empty\")\n",
    "    print(\"   ‚úÖ Long-term memory: Still available across all sessions\")\n",
    "    text2 = \"What are the student's career goals?\"\n",
    "    print(f\"\\nText: {text2}\\n\")\n",
    "\n",
    "    # Search long-term memory\n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=text2, user_id=UserId(eq=student_id), limit=3\n",
    "    )\n",
    "\n",
    "    if results.memories:\n",
    "        print(\"\\n   üîç Retrieved from long-term memory:\")\n",
    "        for memory in results.memories[:3]:\n",
    "            print(f\"      ‚Ä¢ {memory.text}\")\n",
    "        print(\"\\n   ‚úÖ Agent can still personalize recommendations!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\n",
    "        \"‚úÖ Long-term memories persist across sessions, working memory is session-scoped\"\n",
    "    )\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "await multi_day_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313340c15849727",
   "metadata": {},
   "source": [
    "### üéØ Memory Lifecycle Best Practices\n",
    "\n",
    "**1. Trust Automatic Extraction**\n",
    "- Agent Memory Server automatically extracts important facts\n",
    "- Don't manually store everything in long-term memory\n",
    "- Let the system decide what's important\n",
    "\n",
    "**2. Use Appropriate Memory Types**\n",
    "- Working memory: Current conversation only\n",
    "- Long-term memory: Facts that should persist\n",
    "\n",
    "**3. Monitor Memory Growth**\n",
    "- Long-term memories accumulate over time\n",
    "- Implement cleanup for outdated information\n",
    "- Consider archiving old memories\n",
    "\n",
    "**4. Understand Session Management**\n",
    "- Working memory persists within a session\n",
    "- New sessions start with empty working memory\n",
    "- Important facts should be in long-term memory for cross-session access\n",
    "- Consider providing ways to resume or load previous session context\n",
    "\n",
    "**5. Plan for Context Window Limits**\n",
    "- Working memory doesn't expire, but can grow too large\n",
    "- LLMs have context window limits (e.g., 128K tokens)\n",
    "- Use compression strategies when conversations get long (covered in Notebook 03)\n",
    "- Monitor token usage in long conversations\n",
    "\n",
    "**6. Test Cross-Session Behavior**\n",
    "- Verify long-term memories are accessible across sessions\n",
    "- Test both same-session returns and new-session starts\n",
    "- Ensure personalization works in both scenarios\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c090ec7126ac4",
   "metadata": {},
   "source": [
    "## üß† Memory Extraction Strategies\n",
    "\n",
    "The Agent Memory Server automatically extracts important information from conversations and stores it in long-term memory. Understanding **how** this extraction works helps you choose the right strategy for your use case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab736ee516b94e",
   "metadata": {},
   "source": [
    "### How Memory Extraction Works\n",
    "\n",
    "**Key Distinction:**\n",
    "- **Working Memory:** Stores raw conversation messages (user/assistant exchanges)\n",
    "- **Long-term Memory:** Stores extracted facts, summaries, or preferences\n",
    "\n",
    "**The Question:** When promoting information from working memory to long-term memory, should we extract:\n",
    "- Individual discrete facts? (\"User prefers online courses\")\n",
    "- A summary of the conversation? (\"User discussed course preferences...\")\n",
    "- User preferences specifically? (\"User prefers email notifications\")\n",
    "- Custom domain-specific information?\n",
    "\n",
    "This is where **memory extraction strategies** come in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee3b159eb86d90",
   "metadata": {},
   "source": [
    "### Available Strategies\n",
    "\n",
    "The Agent Memory Server supports four memory extraction strategies that determine how memories are created:\n",
    "\n",
    "#### **1. Discrete Strategy (Default)** ‚úÖ\n",
    "\n",
    "**Purpose:** Extract individual facts and preferences from conversations\n",
    "\n",
    "**Best For:** General-purpose memory extraction, factual information, user preferences\n",
    "\n",
    "**Example Input (Conversation):**\n",
    "```\n",
    "User: \"I'm a Computer Science major interested in machine learning. I prefer online courses.\"\n",
    "```\n",
    "\n",
    "**Example Output (Long-term Memories):**\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"type\": \"semantic\",\n",
    "    \"text\": \"User's major is Computer Science\",\n",
    "    \"topics\": [\"education\", \"major\"],\n",
    "    \"entities\": [\"Computer Science\"]\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"semantic\",\n",
    "    \"text\": \"User interested in machine learning\",\n",
    "    \"topics\": [\"interests\", \"technology\"],\n",
    "    \"entities\": [\"machine learning\"]\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"semantic\",\n",
    "    \"text\": \"User prefers online courses\",\n",
    "    \"topics\": [\"preferences\", \"learning\"],\n",
    "    \"entities\": [\"online courses\"]\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- ‚úÖ Most agent interactions (default choice)\n",
    "- ‚úÖ When you want searchable individual facts\n",
    "- ‚úÖ When facts should be independently retrievable\n",
    "- ‚úÖ Building knowledge graphs or fact databases\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Summary Strategy**\n",
    "\n",
    "**Purpose:** Create concise summaries of entire conversations instead of extracting discrete facts\n",
    "\n",
    "**Best For:** Long conversations, meeting notes, comprehensive context preservation\n",
    "\n",
    "**Example Input (Same Conversation):**\n",
    "```\n",
    "User: \"I'm a Computer Science major interested in machine learning. I prefer online courses.\"\n",
    "```\n",
    "\n",
    "**Example Output (Long-term Memory):**\n",
    "```json\n",
    "{\n",
    "  \"type\": \"semantic\",\n",
    "  \"text\": \"User is a Computer Science major with interest in machine learning, preferring online course formats for their studies.\",\n",
    "  \"topics\": [\"education\", \"preferences\", \"technology\"],\n",
    "  \"entities\": [\"Computer Science\", \"machine learning\", \"online courses\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- ‚úÖ Long consultations or advising sessions\n",
    "- ‚úÖ Meeting notes or session summaries\n",
    "- ‚úÖ When context of entire conversation matters\n",
    "- ‚úÖ Reducing storage while preserving conversational context\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Preferences Strategy**\n",
    "\n",
    "**Purpose:** Focus specifically on extracting user preferences and personal characteristics\n",
    "\n",
    "**Best For:** Personalization systems, user profile building, preference learning\n",
    "\n",
    "**Example Output:**\n",
    "```json\n",
    "{\n",
    "  \"type\": \"semantic\",\n",
    "  \"text\": \"User prefers online courses over in-person instruction\",\n",
    "  \"topics\": [\"preferences\", \"learning_style\"],\n",
    "  \"entities\": [\"online courses\", \"in-person\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- ‚úÖ User onboarding flows\n",
    "- ‚úÖ Building user profiles\n",
    "- ‚úÖ Personalization-focused applications\n",
    "- ‚úÖ Preference learning systems\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Custom Strategy**\n",
    "\n",
    "**Purpose:** Use domain-specific extraction prompts for specialized needs\n",
    "\n",
    "**Best For:** Domain-specific extraction (technical, legal, medical), specialized workflows\n",
    "\n",
    "**Security Note:** ‚ö†Ô∏è Custom prompts require validation to prevent prompt injection attacks. See the [Security Guide](https://redis.github.io/agent-memory-server/security/) for details.\n",
    "\n",
    "**When to Use:**\n",
    "- ‚úÖ Specialized domains (legal, medical, technical)\n",
    "- ‚úÖ Custom extraction logic needed\n",
    "- ‚úÖ Domain-specific memory structures\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ffa2ee69019f5",
   "metadata": {},
   "source": [
    "### Strategy Comparison\n",
    "\n",
    "| Strategy | Output Type | Use Case | Example |\n",
    "|----------|------------|----------|---------|\n",
    "| **Discrete** | Individual facts | General agents | \"User's major is Computer Science\" |\n",
    "| **Summary** | Conversation summary | Long sessions | \"User discussed CS major, interested in ML courses...\" |\n",
    "| **Preferences** | User preferences | Personalization | \"User prefers online courses over in-person\" |\n",
    "| **Custom** | Domain-specific | Specialized domains | Custom extraction logic |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ca666a553fb37",
   "metadata": {},
   "source": [
    "### Default Behavior in This Course\n",
    "\n",
    "**In this course, we use the Discrete Strategy (default)** because:\n",
    "\n",
    "‚úÖ **Works well for course advising conversations**\n",
    "- Students ask specific questions\n",
    "- Facts are independently useful\n",
    "- Each fact can be searched separately\n",
    "\n",
    "‚úÖ **Creates searchable individual facts**\n",
    "- \"User's major is Computer Science\"\n",
    "- \"User completed RU101\"\n",
    "- \"User interested in machine learning\"\n",
    "\n",
    "‚úÖ **Balances detail with storage efficiency**\n",
    "- Not too granular (every sentence)\n",
    "- Not too broad (entire conversations)\n",
    "- Just right for Q&A interactions\n",
    "\n",
    "‚úÖ **No configuration required**\n",
    "- Default behavior\n",
    "- Works out of the box\n",
    "- Production-ready\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1695a490a2165f",
   "metadata": {},
   "source": [
    "### When Would You Use Different Strategies?\n",
    "\n",
    "**Scenario 1: Long Academic Advising Session (Summary Strategy)**\n",
    "\n",
    "```\n",
    "Student has 30-minute conversation discussing:\n",
    "- Academic goals and graduation timeline\n",
    "- Career aspirations and internship plans\n",
    "- Course preferences and learning style\n",
    "- Schedule constraints and work commitments\n",
    "- Extracurricular interests\n",
    "```\n",
    "\n",
    "**Discrete Strategy:** Extracts 20+ individual facts\n",
    "- \"User wants to graduate Spring 2026\"\n",
    "- \"User interested in tech startup internship\"\n",
    "- \"User prefers online courses\"\n",
    "- ... (17 more facts)\n",
    "\n",
    "**Summary Strategy:** Creates 1-2 comprehensive summaries\n",
    "- \"Student discussed academic planning for Spring 2026 graduation, expressing strong interest in ML/AI courses and tech startup internships. Prefers online format due to part-time work commitments. Interested in vector databases and modern AI applications.\"\n",
    "\n",
    "**Trade-off:**\n",
    "- Discrete: More searchable, more storage\n",
    "- Summary: Less storage, preserves context\n",
    "\n",
    "---\n",
    "\n",
    "**Scenario 2: User Onboarding (Preferences Strategy)**\n",
    "\n",
    "```\n",
    "New student onboarding flow:\n",
    "- Communication preferences\n",
    "- Learning style preferences\n",
    "- Schedule preferences\n",
    "- Notification preferences\n",
    "```\n",
    "\n",
    "**Preferences Strategy:** Focuses on extracting preferences\n",
    "- \"User prefers email over SMS notifications\"\n",
    "- \"User prefers morning study sessions\"\n",
    "- \"User prefers video content over text\"\n",
    "\n",
    "**Why Preferences Strategy:**\n",
    "- Optimized for preference extraction\n",
    "- Builds user profile efficiently\n",
    "- Personalization-focused\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6964aab793ef5a",
   "metadata": {},
   "source": [
    "### How Strategies Work Behind the Scenes\n",
    "\n",
    "**Discrete Strategy (Default):**\n",
    "```\n",
    "Conversation Messages\n",
    "    ‚Üì\n",
    "[Background Worker]\n",
    "    ‚Üì\n",
    "Extract individual facts using LLM\n",
    "    ‚Üì\n",
    "Store each fact as separate long-term memory\n",
    "    ‚Üì\n",
    "Vector index for semantic search\n",
    "```\n",
    "\n",
    "**Summary Strategy:**\n",
    "```\n",
    "Conversation Messages\n",
    "    ‚Üì\n",
    "[Background Worker]\n",
    "    ‚Üì\n",
    "Summarize conversation using LLM\n",
    "    ‚Üì\n",
    "Store summary as long-term memory\n",
    "    ‚Üì\n",
    "Vector index for semantic search\n",
    "```\n",
    "\n",
    "**üìö Learn More:** See the [Memory Extraction Strategies Guide](https://redis.github.io/agent-memory-server/memory-extraction-strategies/) for detailed examples and hands-on demos in Notebook 2.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904c018fda2fbc0",
   "metadata": {},
   "source": [
    "### üéØ Memory Lifecycle Best Practices\n",
    "\n",
    "**1. Trust Automatic Extraction**\n",
    "- Agent Memory Server automatically extracts important facts\n",
    "- Don't manually store everything in long-term memory\n",
    "- Let the system decide what's important\n",
    "\n",
    "**2. Use Appropriate Memory Types**\n",
    "- Working memory: Current conversation only\n",
    "- Long-term memory: Facts that should persist\n",
    "\n",
    "**3. Monitor Memory Growth**\n",
    "- Long-term memories accumulate over time\n",
    "- Implement cleanup for outdated information\n",
    "- Consider archiving old memories\n",
    "\n",
    "**4. Understand Session Management**\n",
    "- Working memory persists within a session (like ChatGPT conversations)\n",
    "- New sessions start with empty working memory\n",
    "- Important facts should be in long-term memory for cross-session access\n",
    "- Consider providing ways to resume or load previous session context\n",
    "\n",
    "**5. Plan for Context Window Limits**\n",
    "- Working memory doesn't expire, but can grow too large\n",
    "- LLMs have context window limits (e.g., 128K tokens)\n",
    "- Use compression strategies when conversations get long (covered in Notebook 03)\n",
    "- Monitor token usage in long conversations\n",
    "\n",
    "**6. Test Cross-Session Behavior**\n",
    "- Verify long-term memories are accessible across sessions\n",
    "- Test both same-session returns and new-session starts\n",
    "- Ensure personalization works in both scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Solves the Grounding Problem**\n",
    "\n",
    "Without memory, agents can't resolve references:\n",
    "- ‚ùå \"What are **its** prerequisites?\" ‚Üí Agent doesn't know what \"its\" refers to\n",
    "- ‚úÖ With working memory ‚Üí Agent resolves \"its\" from conversation history\n",
    "\n",
    "### **2. Two Types of Memory Serve Different Purposes**\n",
    "\n",
    "**Working Memory (Session-Scoped):**\n",
    "- Conversation messages from current session\n",
    "- Enables reference resolution and conversation continuity\n",
    "- Persists within the session (like ChatGPT conversations)\n",
    "- Challenge: Can grow too large for context window limits\n",
    "\n",
    "**Long-term Memory (Cross-Session):**\n",
    "- Persistent knowledge: user preferences, domain facts, business rules\n",
    "- Enables personalization AND consistent application behavior\n",
    "- Can be user-scoped (personalization) or application-scoped (domain knowledge)\n",
    "- Searchable via semantic vector search\n",
    "\n",
    "### **3. Memory Completes the Four Context Types**\n",
    "\n",
    "From Section 1, we learned about four context types. Memory enables two of them:\n",
    "\n",
    "1. **System Context** (Static) - ‚úÖ Section 2\n",
    "2. **User Context** (Dynamic, User-Specific) - ‚úÖ Section 2 + Long-term Memory\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - ‚ú® **Working Memory**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - ‚úÖ Section 2 RAG\n",
    "\n",
    "### **4. Memory + RAG = Complete Context Engineering**\n",
    "\n",
    "The integration pattern:\n",
    "```\n",
    "1. Load working memory (conversation history)\n",
    "2. Search long-term memory (user facts)\n",
    "3. RAG search (relevant documents)\n",
    "4. Assemble all context types\n",
    "5. Generate response\n",
    "6. Save working memory (updated conversation)\n",
    "```\n",
    "\n",
    "This gives us **stateful, personalized, context-aware conversations**.\n",
    "\n",
    "### **5. Agent Memory Server is Production-Ready**\n",
    "\n",
    "Why use Agent Memory Server instead of simple in-memory storage:\n",
    "- ‚úÖ **Scalable** - Redis-backed, handles thousands of users\n",
    "- ‚úÖ **Automatic** - Extracts important facts to long-term storage\n",
    "- ‚úÖ **Semantic search** - Vector-indexed memory retrieval\n",
    "- ‚úÖ **Deduplication** - Prevents redundant memories\n",
    "- ‚úÖ **Session management** - Efficient storage and retrieval of conversation history\n",
    "\n",
    "### **6. LangChain is Sufficient for Memory + RAG**\n",
    "\n",
    "We didn't need LangGraph for this section because:\n",
    "- Simple linear flow (load ‚Üí search ‚Üí generate ‚Üí save)\n",
    "- No conditional branching or complex state management\n",
    "- No tool calling required\n",
    "\n",
    "**LangGraph becomes necessary in Section 4** when we add tools and multi-step workflows.\n",
    "\n",
    "### **7. Memory Management Best Practices**\n",
    "\n",
    "**Choose the Right Memory Type:**\n",
    "- **Semantic** for facts and preferences (most common)\n",
    "- **Episodic** for time-bound events and timeline\n",
    "- **Message** for context-rich conversations (use sparingly)\n",
    "\n",
    "**Understand Memory Lifecycle:**\n",
    "- **Working memory:** Session-scoped, persists within session\n",
    "- **Long-term memory:** Indefinite persistence, user-scoped, cross-session\n",
    "- **Automatic extraction:** Trust the system to extract important facts\n",
    "- **Context window limits:** Working memory can grow too large (use compression strategies)\n",
    "\n",
    "**Benefits of Proper Memory Management:**\n",
    "- ‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "- ‚úÖ **Cross-session personalization** - Knowledge persists over time\n",
    "- ‚úÖ **Efficient storage** - Automatic deduplication prevents bloat\n",
    "- ‚úÖ **Semantic search** - Find relevant memories without exact keywords\n",
    "- ‚úÖ **Scalable** - Redis-backed, production-ready architecture\n",
    "\n",
    "**Key Principle:** Memory transforms stateless RAG into stateful, personalized, context-aware conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## üí™ Practice Exercises\n",
    "\n",
    "### **Exercise 1: Cross-Session Personalization**\n",
    "\n",
    "Modify the `memory_enhanced_rag_query` function to:\n",
    "1. Store user preferences in long-term memory when mentioned\n",
    "2. Use those preferences in future sessions\n",
    "3. Test with two different sessions for the same student\n",
    "\n",
    "**Hint:** Look for phrases like \"I prefer...\", \"I like...\", \"I want...\" and store them as semantic memories.\n",
    "\n",
    "### **Exercise 2: Memory-Aware Filtering**\n",
    "\n",
    "Enhance the RAG search to use long-term memories as filters:\n",
    "1. Search long-term memory for preferences (format, difficulty, schedule)\n",
    "2. Apply those preferences as filters to `course_manager.search_courses()`\n",
    "3. Compare results with and without memory-aware filtering\n",
    "\n",
    "**Hint:** Use the `filters` parameter in `course_manager.search_courses()`.\n",
    "\n",
    "### **Exercise 3: Conversation Summarization**\n",
    "\n",
    "Implement a function that summarizes long conversations:\n",
    "1. When working memory exceeds 10 messages, summarize the conversation\n",
    "2. Store the summary in long-term memory\n",
    "3. Clear old messages from working memory (keep only recent 4)\n",
    "4. Test that reference resolution still works with summarized history\n",
    "\n",
    "**Hint:** Use the LLM to generate summaries, then store as semantic memories.\n",
    "\n",
    "### **Exercise 4: Multi-User Memory Management**\n",
    "\n",
    "Create a simple CLI that:\n",
    "1. Supports multiple students (different user IDs)\n",
    "2. Maintains separate working memory per session\n",
    "3. Maintains separate long-term memory per user\n",
    "4. Demonstrates cross-session continuity for each user\n",
    "\n",
    "**Hint:** Use different `session_id` and `user_id` for each student.\n",
    "\n",
    "### **Exercise 5: Memory Search Quality**\n",
    "\n",
    "Experiment with long-term memory search:\n",
    "1. Store 20+ diverse memories for a student\n",
    "2. Try different search queries\n",
    "3. Analyze which memories are retrieved\n",
    "4. Adjust memory text to improve search relevance\n",
    "\n",
    "**Hint:** More specific memory text leads to better semantic search results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. **The Grounding Problem** - Why agents need memory to resolve references\n",
    "2. **Working Memory** - Session-scoped conversation history for continuity\n",
    "3. **Long-term Memory** - Cross-session persistent knowledge for personalization\n",
    "4. **Memory Integration** - Combining memory with Section 2's RAG system\n",
    "5. **Complete Context Engineering** - All four context types working together\n",
    "6. **Production Architecture** - Using Agent Memory Server for scalable memory\n",
    "\n",
    "### **What You Built:**\n",
    "\n",
    "- ‚úÖ Working memory demo (multi-turn conversations)\n",
    "- ‚úÖ Long-term memory demo (persistent knowledge)\n",
    "- ‚úÖ Complete memory-enhanced RAG system\n",
    "- ‚úÖ Integration of all four context types\n",
    "\n",
    "### **Key Functions:**\n",
    "\n",
    "- `memory_enhanced_rag_query()` - Complete memory + RAG pipeline\n",
    "- `working_memory_demo()` - Demonstrates conversation continuity\n",
    "- `longterm_memory_demo()` - Demonstrates persistent knowledge\n",
    "- `complete_demo()` - End-to-end multi-turn conversation\n",
    "\n",
    "### **Architecture Pattern:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "Load Working Memory (conversation history)\n",
    "    ‚Üì\n",
    "Search Long-term Memory (user facts)\n",
    "    ‚Üì\n",
    "RAG Search (relevant courses)\n",
    "    ‚Üì\n",
    "Assemble Context (System + User + Conversation + Retrieved)\n",
    "    ‚Üì\n",
    "Generate Response\n",
    "    ‚Üì\n",
    "Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **From Section 2 to Section 3:**\n",
    "\n",
    "**Section 2 (Stateless RAG):**\n",
    "- ‚ùå No conversation history\n",
    "- ‚ùå Each query independent\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚úÖ Retrieves relevant documents\n",
    "\n",
    "**Section 3 (Memory-Enhanced RAG):**\n",
    "- ‚úÖ Conversation history (working memory)\n",
    "- ‚úÖ Multi-turn conversations\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Persistent user knowledge (long-term memory)\n",
    "- ‚úÖ Personalization across sessions\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "**Section 4** will add **tools** and **agentic workflows** using **LangGraph**, completing your journey from context engineering fundamentals to production-ready AI agents.\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully built a **memory-enhanced RAG system** that:\n",
    "- Remembers conversations (working memory)\n",
    "- Accumulates knowledge (long-term memory)\n",
    "- Resolves references naturally\n",
    "- Personalizes responses\n",
    "- Integrates all four context types\n",
    "\n",
    "**You're now ready for Section 4: Tools & Agentic Workflows!** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [Agent Memory Server Documentation](https://github.com/redis/agent-memory-server) - Production-ready memory management\n",
    "- [Agent Memory Client](https://pypi.org/project/agent-memory-client/) - Python client for Agent Memory Server\n",
    "- [RedisVL Documentation](https://redisvl.com/) - Redis Vector Library\n",
    "- [LangChain Guide](https://python.langchain.com/docs/modules/memory/) - Langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2ac5376e38a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
