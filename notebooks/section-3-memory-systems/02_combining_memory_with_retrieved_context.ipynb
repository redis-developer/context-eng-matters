{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e21de5ad28ededc",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üîó Combining Memory with Retrieved Context\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 60-75 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Build** a memory-enhanced RAG system that combines all four context types\n",
    "2. **Demonstrate** the benefits of memory for natural conversations\n",
    "3. **Convert** a simple RAG system into a LangGraph agent\n",
    "4. **Prepare** for Section 4 (adding tools and advanced agent capabilities)\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Bridge from Previous Notebooks\n",
    "\n",
    "### **What You've Learned:**\n",
    "\n",
    "**Section 1:** Four Context Types\n",
    "- System Context (static instructions)\n",
    "- User Context (profile, preferences)\n",
    "- Conversation Context (enabled by working memory)\n",
    "- Retrieved Context (RAG results)\n",
    "\n",
    "**Section 2:** RAG Fundamentals\n",
    "- Semantic search with vector embeddings\n",
    "- Context assembly\n",
    "- LLM generation\n",
    "\n",
    "**Section 3 (Notebook 1):** Memory Fundamentals\n",
    "- Working memory for conversation continuity\n",
    "- Long-term memory for persistent knowledge\n",
    "- Memory types (semantic, episodic, message)\n",
    "- Memory lifecycle and persistence\n",
    "\n",
    "### **What We'll Build:**\n",
    "\n",
    "**Part 1:** Memory-Enhanced RAG\n",
    "- Integrate working memory + long-term memory + RAG\n",
    "- Show clear before/after comparisons\n",
    "- Demonstrate benefits of memory systems\n",
    "\n",
    "**Part 2:** LangGraph Agent (Separate Notebook)\n",
    "- Convert memory-enhanced RAG to LangGraph agent\n",
    "- Add state management and control flow\n",
    "- Prepare for Section 4 (tools and advanced capabilities)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä The Complete Picture\n",
    "\n",
    "### **Memory-Enhanced RAG Flow:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "1. Load Working Memory (conversation history)\n",
    "2. Search Long-term Memory (user preferences, facts)\n",
    "3. RAG Search (relevant courses)\n",
    "4. Assemble Context (System + User + Conversation + Retrieved)\n",
    "5. Generate Response\n",
    "6. Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **All Four Context Types Working Together:**\n",
    "\n",
    "| Context Type | Source | Purpose |\n",
    "|-------------|--------|---------|\n",
    "| **System** | Static prompt | Role, instructions, guidelines |\n",
    "| **User** | Profile + Long-term Memory | Personalization, preferences |\n",
    "| **Conversation** | Working Memory | Reference resolution, continuity |\n",
    "| **Retrieved** | RAG Search | Relevant courses, information |\n",
    "\n",
    "**üí° Key Insight:** Memory transforms stateless RAG into stateful, personalized conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Setup and Environment\n",
    "\n",
    "Let's set up our environment with the necessary dependencies and connections. We'll build on Section 2's RAG foundation and add memory capabilities.\n",
    "\n",
    "### ‚ö†Ô∏è Prerequisites\n",
    "\n",
    "**Before running this notebook, make sure you have:**\n",
    "\n",
    "1. **Docker Desktop running** - Required for Redis and Agent Memory Server\n",
    "\n",
    "2. **Environment variables** - Create a `.env` file in the project root directory:\n",
    "   ```bash\n",
    "   # Copy the example file (if it exists)\n",
    "   cd ../..\n",
    "   # Or create .env manually with:\n",
    "   # OPENAI_API_KEY=your_actual_openai_api_key_here\n",
    "   # REDIS_URL=redis://localhost:6379\n",
    "   # AGENT_MEMORY_URL=http://localhost:8088\n",
    "   ```\n",
    "\n",
    "3. **Start services** - Make sure Redis and Agent Memory Server are running:\n",
    "   ```bash\n",
    "   # Start Redis and Agent Memory Server using docker-compose\n",
    "   cd ../..\n",
    "   docker-compose up -d\n",
    "   ```\n",
    "\n",
    "**Note:** Using docker-compose will:\n",
    "- ‚úÖ Start Redis on port 6379\n",
    "- ‚úÖ Start Agent Memory Server on port 8088\n",
    "- ‚úÖ Configure networking between services\n",
    "- ‚úÖ Persist data in Docker volumes\n",
    "\n",
    "If the Memory Server is not available, the notebook will skip memory-related demos but will still run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e6d5b346b6755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:06.541458Z",
     "iopub.status.busy": "2025-10-31T14:27:06.541296Z",
     "iopub.status.idle": "2025-10-31T14:27:08.268475Z",
     "shell.execute_reply": "2025-10-31T14:27:08.268022Z"
    }
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc66a54eb849c6",
   "metadata": {},
   "source": [
    "### Automated Setup Check\n",
    "\n",
    "Let's run the setup script to ensure all services are running properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd141310064ba82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:04.402755Z",
     "iopub.status.busy": "2025-12-09T19:50:04.402499Z",
     "iopub.status.idle": "2025-12-09T19:50:04.475817Z",
     "shell.execute_reply": "2025-12-09T19:50:04.475143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if required services are running...\n",
      "\n",
      "‚úÖ Redis is running\n",
      "‚úÖ Agent Memory Server is running\n",
      "\n",
      "If services are not running, start them with:\n",
      "  cd ../..\n",
      "  docker-compose up -d\n"
     ]
    }
   ],
   "source": [
    "# Check if services are running\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Checking if required services are running...\\n\")\n",
    "\n",
    "# Check if Redis is running\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"ps\", \"--filter\", \"name=redis\", \"--format\", \"{{.Names}}\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    if \"redis\" in result.stdout:\n",
    "        print(\"‚úÖ Redis is running\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Redis is not running. Start it with: docker-compose up -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not check Redis status: {e}\")\n",
    "\n",
    "# Check if Agent Memory Server is running\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"ps\", \"--filter\", \"name=agent-memory\", \"--format\", \"{{.Names}}\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    if \"agent-memory\" in result.stdout or \"memory\" in result.stdout:\n",
    "        print(\"‚úÖ Agent Memory Server is running\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Agent Memory Server is not running. Start it with: docker-compose up -d\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not check Agent Memory Server status: {e}\")\n",
    "\n",
    "print(\"\\nIf services are not running, start them with:\")\n",
    "print(\"  cd ../..\")\n",
    "print(\"  docker-compose up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221bf3835cda63e",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c01bfe255ff0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:08.387999Z",
     "iopub.status.busy": "2025-10-31T14:27:08.387932Z",
     "iopub.status.idle": "2025-10-31T14:27:19.029786Z",
     "shell.execute_reply": "2025-10-31T14:27:19.029077Z"
    }
   },
   "source": [
    "### Install Dependencies\n",
    "\n",
    "If you haven't already installed the reference-agent package, uncomment and run the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb296c50e53337f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:04.477507Z",
     "iopub.status.busy": "2025-12-09T19:50:04.477377Z",
     "iopub.status.idle": "2025-12-09T19:50:04.479381Z",
     "shell.execute_reply": "2025-12-09T19:50:04.478866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to install the project package\n",
    "# %pip install -q -e ../..\n",
    "\n",
    "# Uncomment to install agent-memory-client\n",
    "# %pip install -q agent-memory-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577d8576496593a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:19.031485Z",
     "iopub.status.busy": "2025-10-31T14:27:19.031347Z",
     "iopub.status.idle": "2025-10-31T14:27:19.324283Z",
     "shell.execute_reply": "2025-10-31T14:27:19.323806Z"
    }
   },
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "We'll load environment variables from the `.env` file in the `reference-agent` directory.\n",
    "\n",
    "**Required variables:**\n",
    "- `OPENAI_API_KEY` - Your OpenAI API key\n",
    "- `REDIS_URL` - Redis connection URL (default: redis://localhost:6379)\n",
    "- `AGENT_MEMORY_URL` - Agent Memory Server URL (default: http://localhost:8088)\n",
    "\n",
    "If you haven't created the `.env` file yet, copy `.env.example` and add your OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f541ee37bd9e94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:04.480719Z",
     "iopub.status.busy": "2025-12-09T19:50:04.480602Z",
     "iopub.status.idle": "2025-12-09T19:50:04.487904Z",
     "shell.execute_reply": "2025-12-09T19:50:04.487591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8088\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from project root directory\n",
    "env_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\n",
    "        f\"\"\"‚ùå OPENAI_API_KEY not found!\n",
    "\n",
    "    Please create a .env file at: {env_path.absolute()}\n",
    "\n",
    "    With the following content:\n",
    "    OPENAI_API_KEY=your_openai_api_key\n",
    "    REDIS_URL=redis://localhost:6379\n",
    "    AGENT_MEMORY_URL=http://localhost:8088\n",
    "    \"\"\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables loaded\")\n",
    "    print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "    print(f\"   AGENT_MEMORY_URL: {AGENT_MEMORY_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97c53e10f44716",
   "metadata": {},
   "source": [
    "### Import Core Libraries\n",
    "\n",
    "We'll import standard Python libraries and async support for our memory operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4fabcf00d1fdda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:04.489326Z",
     "iopub.status.busy": "2025-12-09T19:50:04.489236Z",
     "iopub.status.idle": "2025-12-09T19:50:04.491172Z",
     "shell.execute_reply": "2025-12-09T19:50:04.490785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core libraries imported\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "print(\"‚úÖ Core libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6cc99aac5193e",
   "metadata": {},
   "source": [
    "### Import Section 2 Components\n",
    "\n",
    "We're building on Section 2's RAG foundation, so we'll reuse the same components:\n",
    "- `redis_config` - Redis connection and configuration\n",
    "- `CourseManager` - Course search and management\n",
    "- `StudentProfile` and other models - Data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f84446a6969a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:04.492339Z",
     "iopub.status.busy": "2025-12-09T19:50:04.492273Z",
     "iopub.status.idle": "2025-12-09T19:50:06.742020Z",
     "shell.execute_reply": "2025-12-09T19:50:06.741516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Section 2 components imported\n",
      "   CourseManager: Available\n",
      "   Redis Config: Available\n",
      "   Models: Course, StudentProfile, etc.\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import (\n",
    "    Course,\n",
    "    CourseFormat,\n",
    "    DifficultyLevel,\n",
    "    Semester,\n",
    "    StudentProfile,\n",
    ")\n",
    "\n",
    "# Import Section 2 components\n",
    "from redis_context_course.redis_config import redis_config\n",
    "\n",
    "print(\"‚úÖ Section 2 components imported\")\n",
    "print(f\"   CourseManager: Available\")\n",
    "print(f\"   Redis Config: Available\")\n",
    "print(f\"   Models: Course, StudentProfile, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c424c857e0b63",
   "metadata": {},
   "source": [
    "### Import LangChain Components\n",
    "\n",
    "We'll use LangChain for LLM interaction and message handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f591bf327805dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.743378Z",
     "iopub.status.busy": "2025-12-09T19:50:06.743251Z",
     "iopub.status.idle": "2025-12-09T19:50:06.745163Z",
     "shell.execute_reply": "2025-12-09T19:50:06.744810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain components imported\n",
      "   ChatOpenAI: Available\n",
      "   Message types: HumanMessage, SystemMessage, AIMessage\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "print(\"‚úÖ LangChain components imported\")\n",
    "print(f\"   ChatOpenAI: Available\")\n",
    "print(f\"   Message types: HumanMessage, SystemMessage, AIMessage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a129328fb75fc3",
   "metadata": {},
   "source": [
    "### Import Agent Memory Server Client\n",
    "\n",
    "The Agent Memory Server provides production-ready memory management. If it's not available, we'll note that and continue with limited functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e19c1f57084b6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.746369Z",
     "iopub.status.busy": "2025-12-09T19:50:06.746303Z",
     "iopub.status.idle": "2025-12-09T19:50:06.748344Z",
     "shell.execute_reply": "2025-12-09T19:50:06.747934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent Memory Server client available\n",
      "   MemoryAPIClient: Ready\n",
      "   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\n"
     ]
    }
   ],
   "source": [
    "# Import Agent Memory Server client\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    from agent_memory_client.models import (\n",
    "        ClientMemoryRecord,\n",
    "        MemoryMessage,\n",
    "        WorkingMemory,\n",
    "    )\n",
    "\n",
    "    MEMORY_SERVER_AVAILABLE = True\n",
    "    print(\"‚úÖ Agent Memory Server client available\")\n",
    "    print(\"   MemoryAPIClient: Ready\")\n",
    "    print(\"   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\")\n",
    "except ImportError:\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Agent Memory Server not available\")\n",
    "    print(\"   Install with: pip install agent-memory-client\")\n",
    "    print(\"   Start server: See reference-agent/README.md\")\n",
    "    print(\"   Note: Some demos will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c7b6a987f3977",
   "metadata": {},
   "source": [
    "### Environment Summary\n",
    "\n",
    "Let's verify everything is set up correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193e3a1353afb7b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.749457Z",
     "iopub.status.busy": "2025-12-09T19:50:06.749394Z",
     "iopub.status.idle": "2025-12-09T19:50:06.751665Z",
     "shell.execute_reply": "2025-12-09T19:50:06.751276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîß ENVIRONMENT SETUP SUMMARY\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Core Libraries: Imported\n",
      "‚úÖ Section 2 Components: Imported\n",
      "‚úÖ LangChain: Imported\n",
      "‚úÖ Agent Memory Server: Available\n",
      "\n",
      "üìã Configuration:\n",
      "   OPENAI_API_KEY: ‚úì Set\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8088\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üîß ENVIRONMENT SETUP SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Core Libraries: Imported\")\n",
    "print(f\"‚úÖ Section 2 Components: Imported\")\n",
    "print(f\"‚úÖ LangChain: Imported\")\n",
    "print(\n",
    "    f\"{'‚úÖ' if MEMORY_SERVER_AVAILABLE else '‚ö†Ô∏è '} Agent Memory Server: {'Available' if MEMORY_SERVER_AVAILABLE else 'Not Available'}\"\n",
    ")\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   OPENAI_API_KEY: {'‚úì Set' if OPENAI_API_KEY else '‚úó Not set'}\")\n",
    "print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "print(f\"   AGENT_MEMORY_URL: {AGENT_MEMORY_URL}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83febaebad1682ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Initialize Components\n",
    "\n",
    "Now let's initialize the components we'll use throughout this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbea50ae1ff08b",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "The `CourseManager` handles course search and retrieval, just like in Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236f04d3923aa764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.752698Z",
     "iopub.status.busy": "2025-12-09T19:50:06.752633Z",
     "iopub.status.idle": "2025-12-09T19:50:06.881851Z",
     "shell.execute_reply": "2025-12-09T19:50:06.881351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:06 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Course Manager initialized\n",
      "   Ready to search and retrieve courses\n"
     ]
    }
   ],
   "source": [
    "# Initialize Course Manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"‚úÖ Course Manager initialized\")\n",
    "print(\"   Ready to search and retrieve courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5f50d1886133e",
   "metadata": {},
   "source": [
    "### Initialize LLM\n",
    "\n",
    "We'll use GPT-4o with temperature=0.0 for consistent, deterministic responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad8a7d2061efec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.882989Z",
     "iopub.status.busy": "2025-12-09T19:50:06.882912Z",
     "iopub.status.idle": "2025-12-09T19:50:06.891460Z",
     "shell.execute_reply": "2025-12-09T19:50:06.891010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized\n",
      "   Model: gpt-4o\n",
      "   Temperature: 0.0 (deterministic)\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "print(\"‚úÖ LLM initialized\")\n",
    "print(\"   Model: gpt-4o\")\n",
    "print(\"   Temperature: 0.0 (deterministic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60063cef6b46a8",
   "metadata": {},
   "source": [
    "### Initialize Memory Client\n",
    "\n",
    "If the Agent Memory Server is available, we'll initialize the memory client. This client handles both working memory (conversation history) and long-term memory (persistent facts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514603f5fdcf043a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.892594Z",
     "iopub.status.busy": "2025-12-09T19:50:06.892513Z",
     "iopub.status.idle": "2025-12-09T19:50:06.897579Z",
     "shell.execute_reply": "2025-12-09T19:50:06.897146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory Client initialized\n",
      "   Base URL: http://localhost:8088\n",
      "   Namespace: redis_university\n",
      "   Ready for working memory and long-term memory operations\n"
     ]
    }
   ],
   "source": [
    "# Initialize Memory Client\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=AGENT_MEMORY_URL, default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryAPIClient(config=config)\n",
    "    print(\"‚úÖ Memory Client initialized\")\n",
    "    print(f\"   Base URL: {config.base_url}\")\n",
    "    print(f\"   Namespace: {config.default_namespace}\")\n",
    "    print(\"   Ready for working memory and long-term memory operations\")\n",
    "else:\n",
    "    memory_client = None\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")\n",
    "    print(\"   Running with limited functionality\")\n",
    "    print(\"   Some demos will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec158470f51831",
   "metadata": {},
   "source": [
    "### Create Sample Student Profile\n",
    "\n",
    "We'll create a sample student profile to use throughout our demos. This follows the same pattern from Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907614be8182a320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.898734Z",
     "iopub.status.busy": "2025-12-09T19:50:06.898670Z",
     "iopub.status.idle": "2025-12-09T19:50:06.900797Z",
     "shell.execute_reply": "2025-12-09T19:50:06.900534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Student profile created\n",
      "   Name: Sarah Chen\n",
      "   Major: Computer Science\n",
      "   Year: 2\n",
      "   Interests: machine learning, data science, algorithms\n",
      "   Completed: Introduction to Programming, Data Structures\n",
      "   Preferred Format: online\n"
     ]
    }
   ],
   "source": [
    "# Create sample student profile\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"Introduction to Programming\", \"Data Structures\"],\n",
    "    current_courses=[\"Linear Algebra\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Student profile created\")\n",
    "print(f\"   Name: {sarah.name}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Year: {sarah.year}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")\n",
    "print(f\"   Completed: {', '.join(sarah.completed_courses)}\")\n",
    "print(f\"   Preferred Format: {sarah.preferred_format.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603e9dd9cf82e45",
   "metadata": {},
   "source": [
    "### üí° Key Insight\n",
    "\n",
    "We're reusing:\n",
    "- ‚úÖ **Same `CourseManager`** from Section 2\n",
    "- ‚úÖ **Same `StudentProfile`** model\n",
    "- ‚úÖ **Same Redis configuration**\n",
    "\n",
    "We're adding:\n",
    "- ‚ú® **Memory Client** for conversation history\n",
    "- ‚ú® **Working Memory** for session context\n",
    "- ‚ú® **Long-term Memory** for persistent knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Part 1: Memory-Enhanced RAG\n",
    "\n",
    "### **Goal:** Build a simple, inline memory-enhanced RAG system that demonstrates the benefits of memory.\n",
    "\n",
    "### **Approach:**\n",
    "- Start with Section 2's stateless RAG\n",
    "- Add working memory for conversation continuity\n",
    "- Add long-term memory for personalization\n",
    "- Show clear before/after comparisons\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ Before: Stateless RAG (Section 2 Approach)\n",
    "\n",
    "Let's first recall how Section 2's stateless RAG worked, and see its limitations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd9aaee3e7f7805",
   "metadata": {},
   "source": [
    "### Query 1: Initial query (works fine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336f4f8e806ff089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:06.902076Z",
     "iopub.status.busy": "2025-12-09T19:50:06.902008Z",
     "iopub.status.idle": "2025-12-09T19:50:10.384005Z",
     "shell.execute_reply": "2025-12-09T19:50:10.383365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üö´ STATELESS RAG DEMO\n",
      "================================================================================\n",
      "\n",
      "üë§ User: I'm interested in machine learning courses\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:08 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:10 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Based on your interest in machine learning and your background in computer science, I recommend the \"Machine Learning\" course from the list. This course will introduce you to machine learning algorithms and applications, including supervised and unsupervised learning and neural networks. It is an advanced course, so it will build on your existing knowledge from your completed courses in programming and data structures. Additionally, you might consider taking \"Linear Algebra\" as it is essential for understanding many concepts in data science and machine learning.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üö´ STATELESS RAG DEMO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stateless_query_1 = \"I'm interested in machine learning courses\"\n",
    "print(f\"\\nüë§ User: {stateless_query_1}\\n\\n\")\n",
    "\n",
    "# Search courses\n",
    "stateless_courses_1 = await course_manager.search_courses(stateless_query_1, limit=3)\n",
    "\n",
    "# Assemble context (System + User + Retrieved only - NO conversation history)\n",
    "stateless_system_prompt = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- ONLY discuss and recommend courses from the \"Relevant Courses\" list provided below\n",
    "- Do NOT mention, suggest, or make up any courses that are not in the provided list\n",
    "- If the available courses don't perfectly match the request, recommend the best options from what IS available\"\"\"\n",
    "\n",
    "stateless_user_context = f\"\"\"Student: {sarah.name}\n",
    "Major: {sarah.major}\n",
    "Interests: {', '.join(sarah.interests)}\n",
    "Completed: {', '.join(sarah.completed_courses)}\n",
    "\"\"\"\n",
    "\n",
    "stateless_retrieved_context = \"Relevant Courses:\\n\"\n",
    "for i, course in enumerate(stateless_courses_1, 1):\n",
    "    stateless_retrieved_context += f\"\\n{i}. {course.title}\"\n",
    "    stateless_retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "    stateless_retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "\n",
    "# Generate response\n",
    "stateless_messages_1 = [\n",
    "    SystemMessage(content=stateless_system_prompt),\n",
    "    HumanMessage(\n",
    "        content=f\"{stateless_user_context}\\n\\n{stateless_retrieved_context}\\n\\nQuery: {stateless_query_1}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "stateless_response_1 = llm.invoke(stateless_messages_1).content\n",
    "print(f\"\\nü§ñ Agent: {stateless_response_1}\")\n",
    "\n",
    "# ‚ùå No conversation history stored\n",
    "# ‚ùå Next query won't remember this interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5f16248ede0b2",
   "metadata": {},
   "source": [
    "### Query 2: Follow-up with pronoun reference (fails)\n",
    "\n",
    "Now let's try a follow-up that requires conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6391be25ebb1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:10.386327Z",
     "iopub.status.busy": "2025-12-09T19:50:10.386187Z",
     "iopub.status.idle": "2025-12-09T19:50:13.144480Z",
     "shell.execute_reply": "2025-12-09T19:50:13.143391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: What are the prerequisites for the first one?\n",
      "   Note: 'the first one' refers to the first course from Query 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:10 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: The course list provided only includes \"Calculus I\" courses, and they all have the same description and difficulty level. Typically, prerequisites for a Calculus I course might include a solid understanding of pre-calculus topics such as algebra and trigonometry. However, since the list does not specify prerequisites, I recommend checking with the course provider or institution for specific requirements. If Sarah is interested in machine learning, data science, and algorithms, a strong foundation in calculus can be beneficial, so taking Calculus I could be a good step forward.\n",
      "\n",
      "‚ùå Agent can't resolve 'the first one' - no conversation history!\n"
     ]
    }
   ],
   "source": [
    "stateless_query_2 = \"What are the prerequisites for the first one?\"\n",
    "print(f\"üë§ User: {stateless_query_2}\")\n",
    "print(f\"   Note: 'the first one' refers to the first course from Query 1\\n\\n\")\n",
    "\n",
    "# Search courses (will search for \"prerequisites first one\" - not helpful)\n",
    "stateless_courses_2 = await course_manager.search_courses(stateless_query_2, limit=3)\n",
    "\n",
    "# Assemble context (NO conversation history from Query 1)\n",
    "stateless_retrieved_context_2 = \"Relevant Courses:\\n\"\n",
    "for i, course in enumerate(stateless_courses_2, 1):\n",
    "    stateless_retrieved_context_2 += f\"\\n{i}. {course.title}\"\n",
    "    stateless_retrieved_context_2 += f\"\\n   Description: {course.description}\"\n",
    "    stateless_retrieved_context_2 += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "\n",
    "# Generate response\n",
    "stateless_messages_2 = [\n",
    "    SystemMessage(content=stateless_system_prompt),\n",
    "    HumanMessage(\n",
    "        content=f\"{stateless_user_context}\\n\\n{stateless_retrieved_context_2}\\n\\nQuery: {stateless_query_2}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "stateless_response_2 = llm.invoke(stateless_messages_2).content\n",
    "print(f\"\\nü§ñ Agent: {stateless_response_2}\")\n",
    "print(\"\\n‚ùå Agent can't resolve 'the first one' - no conversation history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495edbb86ca8989",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üéØ What Just Happened?\n",
    "\n",
    "**Query 1:** \"I'm interested in machine learning courses\"\n",
    "- ‚úÖ Works fine - searches and returns ML courses\n",
    "\n",
    "**Query 2:** \"What are the prerequisites for **the first one**?\"\n",
    "- ‚ùå **Fails** - Agent doesn't know what \"the first one\" refers to\n",
    "- ‚ùå No conversation history stored\n",
    "- ‚ùå Each query is completely independent\n",
    "\n",
    "**The Problem:** Natural conversation requires context from previous turns.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ After: Memory-Enhanced RAG\n",
    "\n",
    "Now let's add memory to enable natural conversations.\n",
    "\n",
    "### **Step 1: Load Working Memory**\n",
    "\n",
    "Working memory stores conversation history for the current session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2306e6cdcf19fcdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.147123Z",
     "iopub.status.busy": "2025-12-09T19:50:13.146657Z",
     "iopub.status.idle": "2025-12-09T19:50:13.158324Z",
     "shell.execute_reply": "2025-12-09T19:50:13.157990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded working memory for session: demo_session_001\n",
      "   Messages: 8\n"
     ]
    }
   ],
   "source": [
    "# Set up session and student identifiers\n",
    "session_id = \"demo_session_001\"\n",
    "student_id = sarah.email.split(\"@\")[0]\n",
    "\n",
    "# Load working memory\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Loaded working memory for session: {session_id}\")\n",
    "    print(f\"   Messages: {len(working_memory.messages)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaeb0a04fb2b00b",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Loaded Working Memory:**\n",
    "- Created or retrieved conversation history for this session\n",
    "- Session ID: `demo_session_001` (unique per conversation)\n",
    "- User ID: `sarah_chen` (from student email)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Working memory persists across turns in the same session\n",
    "- Enables reference resolution (\"it\", \"that course\", \"the first one\")\n",
    "- Conversation context is maintained\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Search Long-term Memory**\n",
    "\n",
    "Long-term memory stores persistent facts and preferences across sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a07e0aefe7250bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.160010Z",
     "iopub.status.busy": "2025-12-09T19:50:13.159740Z",
     "iopub.status.idle": "2025-12-09T19:50:13.466908Z",
     "shell.execute_reply": "2025-12-09T19:50:13.466054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'What does the student prefer?'\n",
      "üìö Found 5 relevant memories:\n",
      "   1. User is interested in machine learning courses.\n",
      "   2. User asked about the availability of machine learning courses online, indicating an interest in flexible learning options.\n",
      "   3. User has interests in data science and algorithms\n",
      "   4. User is interested in machine learning courses.\n",
      "   5. Data Structures and Algorithms (CS301) could be a good fit for User\n"
     ]
    }
   ],
   "source": [
    "# Search long-term memory\n",
    "longterm_query = \"What does the student prefer?\"\n",
    "\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    from agent_memory_client.filters import UserId\n",
    "\n",
    "    longterm_results = await memory_client.search_long_term_memory(\n",
    "        text=longterm_query, user_id=UserId(eq=student_id), limit=5\n",
    "    )\n",
    "\n",
    "    longterm_memories = (\n",
    "        [m.text for m in longterm_results.memories] if longterm_results.memories else []\n",
    "    )\n",
    "\n",
    "    print(f\"üîç Query: '{longterm_query}'\")\n",
    "    print(f\"üìö Found {len(longterm_memories)} relevant memories:\")\n",
    "    for i, memory in enumerate(longterm_memories, 1):\n",
    "        print(f\"   {i}. {memory}\")\n",
    "else:\n",
    "    longterm_memories = []\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3cb7ac45a690b",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Searched Long-term Memory:**\n",
    "- Used semantic search to find relevant facts\n",
    "- Query: \"What does the student prefer?\"\n",
    "- Results: Memories about preferences, goals, academic info\n",
    "\n",
    "**Why This Matters:**\n",
    "- Long-term memory enables personalization\n",
    "- Facts persist across sessions (days, weeks, months)\n",
    "- Semantic search finds relevant memories without exact keyword matching\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Assemble All Four Context Types**\n",
    "\n",
    "Now let's combine everything: System + User + Conversation + Retrieved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd1140f19fa2e",
   "metadata": {},
   "source": [
    "#### 3.1: System Context (static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a97ccafff01934d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.469258Z",
     "iopub.status.busy": "2025-12-09T19:50:13.469060Z",
     "iopub.status.idle": "2025-12-09T19:50:13.472000Z",
     "shell.execute_reply": "2025-12-09T19:50:13.471468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ System Context created\n",
      "   Length: 927 chars\n"
     ]
    }
   ],
   "source": [
    "# 1. System Context (static)\n",
    "context_system_prompt = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Your role:\n",
    "- Help students find and enroll in courses from our catalog\n",
    "- Provide personalized recommendations based on available courses\n",
    "- Answer questions about courses, prerequisites, schedules\n",
    "\n",
    "CRITICAL RULES - READ CAREFULLY:\n",
    "- You can ONLY recommend courses that appear in the \"Relevant Courses\" list below\n",
    "- Do NOT suggest courses that are not in the \"Relevant Courses\" list\n",
    "- Do NOT say things like \"you might want to consider X course\" if X is not in the list\n",
    "- Do NOT mention courses from other platforms or external resources\n",
    "- If the available courses don't perfectly match the request, recommend the best options from what IS in the list\n",
    "- Use conversation history to resolve references (\"it\", \"that course\", \"the first one\")\n",
    "- Use long-term memories to personalize your recommendations\n",
    "- Be helpful, supportive, and encouraging while staying within the available courses\"\"\"\n",
    "\n",
    "print(\"‚úÖ System Context created\")\n",
    "print(f\"   Length: {len(context_system_prompt)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c82066a191acc9",
   "metadata": {},
   "source": [
    "#### 3.2: User Context (profile + long-term memories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f526b51861566d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.473908Z",
     "iopub.status.busy": "2025-12-09T19:50:13.473774Z",
     "iopub.status.idle": "2025-12-09T19:50:13.809569Z",
     "shell.execute_reply": "2025-12-09T19:50:13.808747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ User Context created\n",
      "   Length: 682 chars\n"
     ]
    }
   ],
   "source": [
    "# 2. User Context (profile + long-term memories)\n",
    "context_user_context = f\"\"\"Student Profile:\n",
    "- Name: {sarah.name}\n",
    "- Major: {sarah.major}\n",
    "- Year: {sarah.year}\n",
    "- Interests: {', '.join(sarah.interests)}\n",
    "- Completed: {', '.join(sarah.completed_courses)}\n",
    "- Current: {', '.join(sarah.current_courses)}\n",
    "- Preferred Format: {sarah.preferred_format.value}\n",
    "- Preferred Difficulty: {sarah.preferred_difficulty.value}\"\"\"\n",
    "\n",
    "# Search long-term memory for this query\n",
    "context_query = \"machine learning courses\"\n",
    "\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    from agent_memory_client.filters import UserId\n",
    "\n",
    "    context_longterm_results = await memory_client.search_long_term_memory(\n",
    "        text=context_query, user_id=UserId(eq=student_id), limit=5\n",
    "    )\n",
    "    context_longterm_memories = (\n",
    "        [m.text for m in context_longterm_results.memories]\n",
    "        if context_longterm_results.memories\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if context_longterm_memories:\n",
    "        context_user_context += f\"\\n\\nLong-term Memories:\\n\" + \"\\n\".join(\n",
    "            [f\"- {m}\" for m in context_longterm_memories]\n",
    "        )\n",
    "\n",
    "print(\"‚úÖ User Context created\")\n",
    "print(f\"   Length: {len(context_user_context)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4b7343d483871",
   "metadata": {},
   "source": [
    "#### 3.3: Conversation Context (working memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74eae47e96155df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.811715Z",
     "iopub.status.busy": "2025-12-09T19:50:13.811539Z",
     "iopub.status.idle": "2025-12-09T19:50:13.820663Z",
     "shell.execute_reply": "2025-12-09T19:50:13.820178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversation Context loaded\n",
      "   Messages: 8\n"
     ]
    }
   ],
   "source": [
    "# 3. Conversation Context (working memory)\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    _, context_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    context_conversation_messages = []\n",
    "    for msg in context_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            context_conversation_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            context_conversation_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    print(\"‚úÖ Conversation Context loaded\")\n",
    "    print(f\"   Messages: {len(context_conversation_messages)}\")\n",
    "else:\n",
    "    context_conversation_messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef065750cd38f76b",
   "metadata": {},
   "source": [
    "#### 3.4: Retrieved Context (RAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd97d65955272e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:13.822016Z",
     "iopub.status.busy": "2025-12-09T19:50:13.821906Z",
     "iopub.status.idle": "2025-12-09T19:50:14.007317Z",
     "shell.execute_reply": "2025-12-09T19:50:14.006341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:13 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved Context created\n",
      "   Length: 596 chars\n"
     ]
    }
   ],
   "source": [
    "# 4. Retrieved Context (RAG)\n",
    "context_courses = await course_manager.search_courses(context_query, limit=3)\n",
    "\n",
    "context_retrieved_context = \"Relevant Courses:\\n\"\n",
    "for i, course in enumerate(context_courses, 1):\n",
    "    context_retrieved_context += f\"\\n{i}. {course.title}\"\n",
    "    context_retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "    context_retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "    context_retrieved_context += f\"\\n   Format: {course.format.value}\"\n",
    "    if course.prerequisites:\n",
    "        prereq_names = [p.course_title for p in course.prerequisites]\n",
    "        context_retrieved_context += f\"\\n   Prerequisites: {', '.join(prereq_names)}\"\n",
    "\n",
    "print(\"‚úÖ Retrieved Context created\")\n",
    "print(f\"   Length: {len(context_retrieved_context)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0cc30ca49faa54",
   "metadata": {},
   "source": [
    "#### Summary: All Four Context Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cbf570051f9b121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:14.010066Z",
     "iopub.status.busy": "2025-12-09T19:50:14.009888Z",
     "iopub.status.idle": "2025-12-09T19:50:14.012434Z",
     "shell.execute_reply": "2025-12-09T19:50:14.011996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä ASSEMBLED CONTEXT\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£ System Context: 927 chars\n",
      "2Ô∏è‚É£ User Context: 682 chars\n",
      "3Ô∏è‚É£ Conversation Context: 8 messages\n",
      "4Ô∏è‚É£ Retrieved Context: 596 chars\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä ASSEMBLED CONTEXT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1Ô∏è‚É£ System Context: {len(context_system_prompt)} chars\")\n",
    "print(f\"2Ô∏è‚É£ User Context: {len(context_user_context)} chars\")\n",
    "print(f\"3Ô∏è‚É£ Conversation Context: {len(context_conversation_messages)} messages\")\n",
    "print(f\"4Ô∏è‚É£ Retrieved Context: {len(context_retrieved_context)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df0d7a4b1c6c60",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Assembled All Four Context Types:**\n",
    "\n",
    "1. **System Context** - Role, instructions, guidelines (static)\n",
    "2. **User Context** - Profile + long-term memories (dynamic, user-specific)\n",
    "3. **Conversation Context** - Working memory messages (dynamic, session-specific)\n",
    "4. **Retrieved Context** - RAG search results (dynamic, query-specific)\n",
    "\n",
    "**Why This Matters:**\n",
    "- All four context types from Section 1 are now working together\n",
    "- System knows WHO the user is (User Context)\n",
    "- System knows WHAT was discussed (Conversation Context)\n",
    "- System knows WHAT's relevant (Retrieved Context)\n",
    "- System knows HOW to behave (System Context)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Generate Response and Save Memory**\n",
    "\n",
    "Now let's put it all together: generate a response and save the conversation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262b0b1942da424",
   "metadata": {},
   "source": [
    "#### 4.1: Set up the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24e7abcead19bcc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:14.014227Z",
     "iopub.status.busy": "2025-12-09T19:50:14.014084Z",
     "iopub.status.idle": "2025-12-09T19:50:14.016228Z",
     "shell.execute_reply": "2025-12-09T19:50:14.015664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: I'm interested in machine learning courses\n"
     ]
    }
   ],
   "source": [
    "test_query = \"I'm interested in machine learning courses\"\n",
    "print(f\"üë§ User: {test_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125bd64e3023243",
   "metadata": {},
   "source": [
    "#### 4.2: Assemble all context types\n",
    "\n",
    "We'll reuse the context assembly logic from Step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "997ec6e54c450371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:14.017791Z",
     "iopub.status.busy": "2025-12-09T19:50:14.017680Z",
     "iopub.status.idle": "2025-12-09T19:50:14.580699Z",
     "shell.execute_reply": "2025-12-09T19:50:14.579763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:14 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context assembled\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Load working memory\n",
    "    _, test_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Build conversation messages\n",
    "    test_conversation_messages = []\n",
    "    for msg in test_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            test_conversation_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            test_conversation_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Search for courses\n",
    "    test_courses = await course_manager.search_courses(test_query, limit=3)\n",
    "\n",
    "    # Build retrieved context\n",
    "    test_retrieved_context = \"Relevant Courses:\\n\"\n",
    "    for i, course in enumerate(test_courses, 1):\n",
    "        test_retrieved_context += f\"\\n{i}. {course.title}\"\n",
    "        test_retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "        test_retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "        if course.prerequisites:\n",
    "            prereq_names = [p.course_title for p in course.prerequisites]\n",
    "            test_retrieved_context += f\"\\n   Prerequisites: {', '.join(prereq_names)}\"\n",
    "\n",
    "    print(\"‚úÖ Context assembled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2eed52c74ef1a3",
   "metadata": {},
   "source": [
    "#### 4.3: Build messages and generate response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41033fb0b272936a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:14.583949Z",
     "iopub.status.busy": "2025-12-09T19:50:14.583697Z",
     "iopub.status.idle": "2025-12-09T19:50:16.995380Z",
     "shell.execute_reply": "2025-12-09T19:50:16.994626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Hi Sarah! I see you're interested in machine learning courses. Currently, we have an advanced Machine Learning course available. It covers topics such as supervised and unsupervised learning, as well as neural networks. Given your background in computer science and your current study of Linear Algebra, you might find this course challenging but rewarding.\n",
      "\n",
      "While it is at an advanced level, your strong foundation in programming and data structures, along with your ongoing study of Linear Algebra, could help you tackle the material. If you're ready to take on the challenge, this course could be a great way to deepen your understanding of machine learning.\n",
      "\n",
      "Let me know if you have any questions or need more information about the course!\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Build complete message list\n",
    "    test_messages = [SystemMessage(content=context_system_prompt)]\n",
    "    test_messages.extend(test_conversation_messages)  # Add conversation history\n",
    "    test_messages.append(\n",
    "        HumanMessage(\n",
    "            content=f\"{context_user_context}\\n\\n{test_retrieved_context}\\n\\nQuery: {test_query}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Generate response using LLM\n",
    "    test_response = llm.invoke(test_messages).content\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {test_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b591cf34b3351",
   "metadata": {},
   "source": [
    "#### 4.4: Save to working memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a7782164d5e152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:16.997502Z",
     "iopub.status.busy": "2025-12-09T19:50:16.997173Z",
     "iopub.status.idle": "2025-12-09T19:50:17.012357Z",
     "shell.execute_reply": "2025-12-09T19:50:17.011778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:17 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Conversation saved to working memory\n",
      "   Total messages: 10\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Add messages to working memory\n",
    "    test_working_memory.messages.extend(\n",
    "        [\n",
    "            MemoryMessage(role=\"user\", content=test_query),\n",
    "            MemoryMessage(role=\"assistant\", content=test_response),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=test_working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Conversation saved to working memory\")\n",
    "    print(f\"   Total messages: {len(test_working_memory.messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcd4af8b39ecbd",
   "metadata": {},
   "source": [
    "#### Helper function for the demo\n",
    "\n",
    "For the complete demo below, we'll use a helper function that combines all these steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ed86c043eddff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:17.014771Z",
     "iopub.status.busy": "2025-12-09T19:50:17.014475Z",
     "iopub.status.idle": "2025-12-09T19:50:17.019833Z",
     "shell.execute_reply": "2025-12-09T19:50:17.019166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper function created for demo\n"
     ]
    }
   ],
   "source": [
    "# Helper function for demo (combines all steps above)\n",
    "\n",
    "\n",
    "async def generate_and_save(\n",
    "    user_query: str, student_profile: StudentProfile, session_id: str, top_k: int = 3\n",
    ") -> str:\n",
    "    \"\"\"Generate response and save to working memory\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        return \"‚ö†Ô∏è Memory Server not available\"\n",
    "\n",
    "    from agent_memory_client.filters import UserId\n",
    "\n",
    "    student_id = student_profile.email.split(\"@\")[0]\n",
    "\n",
    "    # Load working memory\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id, user_id=student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Build conversation messages\n",
    "    conversation_messages = []\n",
    "    for msg in working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            conversation_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            conversation_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Search courses\n",
    "    courses = await course_manager.search_courses(user_query, limit=top_k)\n",
    "\n",
    "    # Build retrieved context\n",
    "    retrieved_context = \"Relevant Courses:\\n\"\n",
    "    for i, course in enumerate(courses, 1):\n",
    "        retrieved_context += f\"\\n{i}. {course.title}\"\n",
    "        retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "        retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "        if course.prerequisites:\n",
    "            prereq_names = [p.course_title for p in course.prerequisites]\n",
    "            retrieved_context += f\"\\n   Prerequisites: {', '.join(prereq_names)}\"\n",
    "\n",
    "    # Build messages\n",
    "    messages = [SystemMessage(content=context_system_prompt)]\n",
    "    messages.extend(conversation_messages)\n",
    "    messages.append(\n",
    "        HumanMessage(\n",
    "            content=f\"{context_user_context}\\n\\n{retrieved_context}\\n\\nQuery: {user_query}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(messages).content\n",
    "\n",
    "    # Save to working memory\n",
    "    working_memory.messages.extend(\n",
    "        [\n",
    "            MemoryMessage(role=\"user\", content=user_query),\n",
    "            MemoryMessage(role=\"assistant\", content=response),\n",
    "        ]\n",
    "    )\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper function created for demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d57045c52dd02c",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Generated Response:**\n",
    "- Assembled all four context types\n",
    "- Built message list with conversation history\n",
    "- Generated response using LLM\n",
    "- **Saved updated conversation to working memory**\n",
    "\n",
    "**Why This Matters:**\n",
    "- Next query will have access to this conversation\n",
    "- Reference resolution will work (\"it\", \"that course\")\n",
    "- Conversation continuity is maintained\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Complete Demo: Memory-Enhanced RAG\n",
    "\n",
    "Now let's test the complete system with a multi-turn conversation.\n",
    "\n",
    "We'll break this down into three turns:\n",
    "1. Initial query about machine learning courses\n",
    "2. Follow-up asking about prerequisites (with pronoun reference)\n",
    "3. Another follow-up checking if student meets prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee62ecce47bf926",
   "metadata": {},
   "source": [
    "### Turn 1: Initial Query\n",
    "\n",
    "Let's start with a query about machine learning courses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f50093afecca2c8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:17.021853Z",
     "iopub.status.busy": "2025-12-09T19:50:17.021488Z",
     "iopub.status.idle": "2025-12-09T19:50:17.024570Z",
     "shell.execute_reply": "2025-12-09T19:50:17.024066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ MEMORY-ENHANCED RAG DEMO\n",
      "================================================================================\n",
      "\n",
      "üë§ Student: Sarah Chen\n",
      "üìß Session: complete_demo_session\n",
      "\n",
      "================================================================================\n",
      "üìç TURN 1: Initial Query\n",
      "================================================================================\n",
      "\n",
      "üë§ User: I'm interested in machine learning courses\n"
     ]
    }
   ],
   "source": [
    "# Set up demo session\n",
    "demo_session_id = \"complete_demo_session\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ MEMORY-ENHANCED RAG DEMO\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüë§ Student: {sarah.name}\")\n",
    "print(f\"üìß Session: {demo_session_id}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìç TURN 1: Initial Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "demo_query_1 = \"I'm interested in machine learning courses\"\n",
    "print(f\"\\nüë§ User: {demo_query_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4ade39bc1104b",
   "metadata": {},
   "source": [
    "#### Generate response and save to memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d247655a8b83820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:17.026116Z",
     "iopub.status.busy": "2025-12-09T19:50:17.026018Z",
     "iopub.status.idle": "2025-12-09T19:50:18.513655Z",
     "shell.execute_reply": "2025-12-09T19:50:18.512590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:17 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:17 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:18 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:18 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Hi Sarah! It's great to see your continued interest in machine learning. While we currently don't have an intermediate-level machine learning course available, I recommend considering the \"Machine Learning\" course we offer. It covers a range of topics including supervised and unsupervised learning, as well as neural networks. However, please note that this course is at an advanced difficulty level.\n",
      "\n",
      "Since you're currently taking Linear Algebra, which is essential for understanding many machine learning concepts, you might find that it helps prepare you for the advanced course. If you feel ready to take on the challenge, this could be a great opportunity to deepen your knowledge in machine learning. Let me know if you have any questions or need further assistance!\n",
      "\n",
      "‚úÖ Conversation saved to working memory\n"
     ]
    }
   ],
   "source": [
    "demo_response_1 = await generate_and_save(demo_query_1, sarah, demo_session_id)\n",
    "\n",
    "print(f\"\\nü§ñ Agent: {demo_response_1}\")\n",
    "print(f\"\\n‚úÖ Conversation saved to working memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c4094d7248e1",
   "metadata": {},
   "source": [
    "### Turn 2: Follow-up with Pronoun Reference\n",
    "\n",
    "Now let's ask about \"the first one\" - a reference that requires conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27bc4cd9dfab64aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:18.516743Z",
     "iopub.status.busy": "2025-12-09T19:50:18.516632Z",
     "iopub.status.idle": "2025-12-09T19:50:18.518613Z",
     "shell.execute_reply": "2025-12-09T19:50:18.518265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 2: Follow-up with Pronoun Reference\n",
      "================================================================================\n",
      "\n",
      "üë§ User: What are the prerequisites for the first one?\n",
      "   Note: 'the first one' refers to the first course mentioned in Turn 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìç TURN 2: Follow-up with Pronoun Reference\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "demo_query_2 = \"What are the prerequisites for the first one?\"\n",
    "print(f\"\\nüë§ User: {demo_query_2}\")\n",
    "print(f\"   Note: 'the first one' refers to the first course mentioned in Turn 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b0d543f855a68",
   "metadata": {},
   "source": [
    "#### Load conversation history and generate response\n",
    "\n",
    "The system will load Turn 1 from working memory to resolve \"the first one\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33f0859c03577c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:18.520181Z",
     "iopub.status.busy": "2025-12-09T19:50:18.520090Z",
     "iopub.status.idle": "2025-12-09T19:50:20.180809Z",
     "shell.execute_reply": "2025-12-09T19:50:20.179774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:18 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:18 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:20 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: The first \"Calculus I\" course listed does not have any specified prerequisites, making it accessible for students who have a foundational understanding of mathematics. Given your background in Computer Science and your current study of Linear Algebra, you should be well-prepared to enroll in this intermediate-level course. It will provide you with essential mathematical skills that are beneficial for your interests in machine learning and data science. If you have any more questions or need further assistance, feel free to ask!\n",
      "\n",
      "‚úÖ Agent resolved 'the first one' using conversation history!\n"
     ]
    }
   ],
   "source": [
    "demo_response_2 = await generate_and_save(demo_query_2, sarah, demo_session_id)\n",
    "\n",
    "print(f\"\\nü§ñ Agent: {demo_response_2}\")\n",
    "print(\"\\n‚úÖ Agent resolved 'the first one' using conversation history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c58d592048c0c",
   "metadata": {},
   "source": [
    "### Turn 3: Another Follow-up\n",
    "\n",
    "Let's ask if the student meets the prerequisites mentioned in Turn 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e81a28aff710f634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:20.183371Z",
     "iopub.status.busy": "2025-12-09T19:50:20.183173Z",
     "iopub.status.idle": "2025-12-09T19:50:20.186824Z",
     "shell.execute_reply": "2025-12-09T19:50:20.186151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 3: Another Follow-up\n",
      "================================================================================\n",
      "\n",
      "üë§ User: Do I meet those prerequisites?\n",
      "   Note: 'those prerequisites' refers to prerequisites from Turn 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìç TURN 3: Another Follow-up\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "demo_query_3 = \"Do I meet those prerequisites?\"\n",
    "print(f\"\\nüë§ User: {demo_query_3}\")\n",
    "print(f\"   Note: 'those prerequisites' refers to prerequisites from Turn 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30907ab5fb2c1a",
   "metadata": {},
   "source": [
    "#### Load full conversation history and check student profile\n",
    "\n",
    "The system will:\n",
    "1. Load Turns 1-2 from working memory\n",
    "2. Resolve \"those prerequisites\"\n",
    "3. Check student's completed courses from profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f69f77c1e8619b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:20.188732Z",
     "iopub.status.busy": "2025-12-09T19:50:20.188577Z",
     "iopub.status.idle": "2025-12-09T19:50:23.169823Z",
     "shell.execute_reply": "2025-12-09T19:50:23.168796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:20 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:23 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:23 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/complete_demo_session?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Based on the information provided, the first \"Calculus I\" course lists prerequisites as Prerequisite Course 3 and Prerequisite Course 6. Unfortunately, without more details on what those specific courses entail, it's difficult to determine if you meet them.\n",
      "\n",
      "However, the second and third \"Calculus I\" courses do not have any specified prerequisites, making them accessible for students with a foundational understanding of mathematics. Given your background in Computer Science and your current study of Linear Algebra, you should be well-prepared to enroll in one of these intermediate-level Calculus I courses. This will provide you with essential mathematical skills that are beneficial for your interests in machine learning and data science.\n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask!\n",
      "\n",
      "‚úÖ Agent resolved 'those prerequisites' and checked student's transcript!\n",
      "\n",
      "================================================================================\n",
      "‚úÖ DEMO COMPLETE: Memory-enhanced RAG enables natural conversations!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "demo_response_3 = await generate_and_save(demo_query_3, sarah, demo_session_id)\n",
    "\n",
    "print(f\"\\nü§ñ Agent: {demo_response_3}\")\n",
    "print(\"\\n‚úÖ Agent resolved 'those prerequisites' and checked student's transcript!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ DEMO COMPLETE: Memory-enhanced RAG enables natural conversations!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83059c5567f43c57",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "**Turn 1:** \"I'm interested in machine learning courses\"\n",
    "- System searches courses\n",
    "- Finds ML-related courses\n",
    "- Responds with recommendations\n",
    "- **Saves conversation to working memory**\n",
    "\n",
    "**Turn 2:** \"What are the prerequisites for **the first one**?\"\n",
    "- System loads working memory (Turn 1)\n",
    "- Resolves \"the first one\" ‚Üí first course mentioned in Turn 1\n",
    "- Responds with prerequisites\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**Turn 3:** \"Do I meet **those prerequisites**?\"\n",
    "- System loads working memory (Turns 1-2)\n",
    "- Resolves \"those prerequisites\" ‚Üí prerequisites from Turn 2\n",
    "- Checks student's completed courses (from profile)\n",
    "- Responds with personalized answer\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**üí° Key Insight:** Memory + RAG = **Natural, stateful, personalized conversations**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Before vs. After Comparison\n",
    "\n",
    "Let's visualize the difference between stateless and memory-enhanced RAG.\n",
    "\n",
    "### **Stateless RAG (Section 2):**\n",
    "\n",
    "```\n",
    "Query 1: \"I'm interested in ML courses\"\n",
    "  ‚Üí ‚úÖ Works (searches and returns courses)\n",
    "\n",
    "Query 2: \"What are the prerequisites for the first one?\"\n",
    "  ‚Üí ‚ùå Fails (no conversation history)\n",
    "  ‚Üí Agent: \"Which course are you referring to?\"\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "- ‚ùå No conversation continuity\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚ùå Each query is independent\n",
    "- ‚ùå Poor user experience\n",
    "\n",
    "### **Memory-Enhanced RAG (This Notebook):**\n",
    "\n",
    "```\n",
    "Query 1: \"I'm interested in ML courses\"\n",
    "  ‚Üí ‚úÖ Works (searches and returns courses)\n",
    "  ‚Üí Saves to working memory\n",
    "\n",
    "Query 2: \"What are the prerequisites for the first one?\"\n",
    "  ‚Üí ‚úÖ Works (loads conversation history)\n",
    "  ‚Üí Resolves \"the first one\" ‚Üí first course from Query 1\n",
    "  ‚Üí Responds with prerequisites\n",
    "  ‚Üí Saves updated conversation\n",
    "\n",
    "Query 3: \"Do I meet those prerequisites?\"\n",
    "  ‚Üí ‚úÖ Works (loads conversation history)\n",
    "  ‚Üí Resolves \"those prerequisites\" ‚Üí prerequisites from Query 2\n",
    "  ‚Üí Checks student transcript\n",
    "  ‚Üí Responds with personalized answer\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Conversation continuity\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Personalization\n",
    "- ‚úÖ Natural user experience\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Transforms RAG**\n",
    "\n",
    "**Without Memory (Section 2):**\n",
    "- Stateless queries\n",
    "- No conversation continuity\n",
    "- Limited to 3 context types (System, User, Retrieved)\n",
    "\n",
    "**With Memory (This Notebook):**\n",
    "- Stateful conversations\n",
    "- Reference resolution\n",
    "- All 4 context types (System, User, Conversation, Retrieved)\n",
    "\n",
    "### **2. Two Types of Memory Work Together**\n",
    "\n",
    "**Working Memory:**\n",
    "- Session-scoped conversation history\n",
    "- Enables reference resolution\n",
    "- Persists within the session (like ChatGPT conversations)\n",
    "\n",
    "**Long-term Memory:**\n",
    "- User-scoped persistent facts\n",
    "- Enables personalization\n",
    "- Persists indefinitely\n",
    "\n",
    "### **3. Simple, Inline Approach**\n",
    "\n",
    "**What We Built:**\n",
    "- Small, focused functions\n",
    "- Inline code (no large classes)\n",
    "- Progressive learning\n",
    "- Clear demonstrations\n",
    "\n",
    "**Why This Matters:**\n",
    "- Easy to understand\n",
    "- Easy to modify\n",
    "- Easy to extend\n",
    "- Foundation for LangGraph agents (Part 2)\n",
    "\n",
    "### **4. All Four Context Types**\n",
    "\n",
    "**System Context:** Role, instructions, guidelines\n",
    "**User Context:** Profile + long-term memories\n",
    "**Conversation Context:** Working memory\n",
    "**Retrieved Context:** RAG results\n",
    "\n",
    "**Together:** Natural, stateful, personalized conversations\n",
    "\n",
    "**üí° Research Insight (From Section 1):** Context Rot research demonstrates that context structure and organization affect LLM attention. Memory systems that selectively retrieve and organize context outperform systems that dump all available information. This validates our approach: quality over quantity, semantic similarity, and selective retrieval. ([Context Rot paper](https://research.trychroma.com/context-rot))\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "### **Part 2: Converting to LangGraph Agent (Separate Notebook)**\n",
    "\n",
    "In the next notebook (`03_langgraph_agent_conversion.ipynb`), we'll:\n",
    "\n",
    "1. **Convert** memory-enhanced RAG to LangGraph agent\n",
    "2. **Add** state management and control flow\n",
    "3. **Prepare** for Section 4 (tools and advanced capabilities)\n",
    "4. **Build** a foundation for production-ready agents\n",
    "\n",
    "**Why LangGraph?**\n",
    "- Better state management\n",
    "- More control over agent flow\n",
    "- Easier to add tools (Section 4)\n",
    "- Production-ready architecture\n",
    "\n",
    "### **Section 4: Tools and Advanced Agents**\n",
    "\n",
    "After completing Part 2, you'll be ready for Section 4.\n",
    "\n",
    "**üí° What's Next:**\n",
    "\n",
    "In Section 4, you'll build an agent that can actively decide when to use memory tools, rather than having memory operations hardcoded in your application flow.\n",
    "\n",
    "---\n",
    "\n",
    "## üèãÔ∏è Practice Exercises\n",
    "\n",
    "### **Exercise 1: Add Personalization**\n",
    "\n",
    "Modify the system to use long-term memories for personalization:\n",
    "\n",
    "1. Store student preferences in long-term memory\n",
    "2. Search long-term memory in `assemble_context()`\n",
    "3. Use memories to personalize recommendations\n",
    "\n",
    "**Hint:** Use `memory_client.create_long_term_memory()` and `memory_client.search_long_term_memory()`\n",
    "\n",
    "### **Exercise 2: Add Error Handling**\n",
    "\n",
    "Add error handling for memory operations:\n",
    "\n",
    "1. Handle case when Memory Server is unavailable\n",
    "2. Fallback to stateless RAG\n",
    "3. Log warnings appropriately\n",
    "\n",
    "**Hint:** Check `MEMORY_SERVER_AVAILABLE` flag\n",
    "\n",
    "### **Exercise 3: Add Conversation Summary**\n",
    "\n",
    "Add a function to summarize the conversation:\n",
    "\n",
    "1. Load working memory\n",
    "2. Extract key points from conversation\n",
    "3. Display summary to user\n",
    "\n",
    "**Hint:** Use LLM to generate summary from conversation history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850ca00-5255-45e3-ac2a-e332f1a64cea",
   "metadata": {},
   "source": [
    "### **Exercise 4: Compare Memory Extraction Strategies** üÜï\n",
    "\n",
    "In Notebook 1, we learned about memory extraction strategies. Now let's see them in action!\n",
    "\n",
    "**Goal:** Compare how discrete vs summary strategies extract different types of memories from the same conversation.\n",
    "\n",
    "**Scenario:** A student has a long advising session discussing their academic goals, course preferences, and career aspirations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435601dec8615ec",
   "metadata": {},
   "source": [
    "#### **Understanding the Difference**\n",
    "\n",
    "**Discrete Strategy (Default):**\n",
    "- Extracts individual facts: \"User's major is CS\", \"User interested in ML\", \"User wants to graduate Spring 2026\"\n",
    "- Each fact is independently searchable\n",
    "- Good for: Most conversations, factual Q&A\n",
    "\n",
    "**Summary Strategy:**\n",
    "- Creates conversation summary: \"User discussed academic planning, expressing interest in ML courses for Spring 2026 graduation...\"\n",
    "- Preserves conversational context\n",
    "- Good for: Long sessions, meeting notes, comprehensive context\n",
    "\n",
    "**Let's see the difference with real code!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc3e83167dc6e1a",
   "metadata": {},
   "source": [
    "#### **Demo: Discrete Strategy (Current Default)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97b9702ef4347804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:23.172201Z",
     "iopub.status.busy": "2025-12-09T19:50:23.172011Z",
     "iopub.status.idle": "2025-12-09T19:50:25.617465Z",
     "shell.execute_reply": "2025-12-09T19:50:25.616362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Testing DISCRETE Strategy (Default)\n",
      "================================================================================\n",
      "Session ID: demo_discrete_584f315e\n",
      "Student ID: student_discrete_afd4621f\n",
      "\n",
      "14:50:23 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_discrete_584f315e?user_id=student_discrete_afd4621f&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:23 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_discrete_584f315e?user_id=student_discrete_afd4621f&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:23 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_discrete_584f315e?user_id=student_discrete_afd4621f&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversation stored with DISCRETE strategy\n",
      "   Messages: 6\n",
      "\n",
      "‚è≥ Waiting for automatic memory extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:25 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä DISCRETE Strategy Results:\n",
      "   Extracted 0 individual memories\n",
      "\n",
      "   ‚è≥ No memories extracted yet (background processing may take time)\n",
      "   Note: In production, extraction happens asynchronously\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    import uuid\n",
    "\n",
    "    from agent_memory_client.models import MemoryStrategyConfig\n",
    "    from agent_memory_client.filters import UserId\n",
    "\n",
    "    # Create a test session with discrete strategy (default)\n",
    "    discrete_session_id = f\"demo_discrete_{uuid.uuid4().hex[:8]}\"\n",
    "    discrete_student_id = f\"student_discrete_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "    print(\"üéØ Testing DISCRETE Strategy (Default)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Session ID: {discrete_session_id}\")\n",
    "    print(f\"Student ID: {discrete_student_id}\\n\")\n",
    "\n",
    "    # Simulate a long advising conversation\n",
    "    advising_conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hi! I'm a Computer Science major planning to graduate in Spring 2026. I'm really interested in machine learning and AI.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Great to meet you! I can help you plan your ML/AI coursework. What's your current experience level with machine learning?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I've taken intro to Python and data structures. I prefer online courses because I work part-time. I'm hoping to get an internship at a tech startup next summer.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Perfect! Based on your goals, I'd recommend starting with RU301 (Querying, Indexing, and Full-Text Search) and RU330 (Trading Engine). Both are available online.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"That sounds good. I'm also interested in vector databases since they're used in AI applications. Do you have courses on that?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Absolutely! RU401 (Running Redis at Scale) covers vector search capabilities. It's a great fit for your AI interests.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Store conversation in working memory (discrete strategy is default)\n",
    "    messages = [\n",
    "        MemoryMessage(role=msg[\"role\"], content=msg[\"content\"])\n",
    "        for msg in advising_conversation\n",
    "    ]\n",
    "\n",
    "    # Get or create working memory\n",
    "    _, discrete_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=discrete_session_id, user_id=discrete_student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Add messages to working memory\n",
    "    discrete_working_memory.messages.extend(messages)\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=discrete_session_id,\n",
    "        memory=discrete_working_memory,\n",
    "        user_id=discrete_student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Conversation stored with DISCRETE strategy\")\n",
    "    print(f\"   Messages: {len(messages)}\")\n",
    "    print(\"\\n‚è≥ Waiting for automatic memory extraction...\")\n",
    "\n",
    "    # Wait a moment for background extraction\n",
    "    import asyncio\n",
    "\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    # Search for extracted memories\n",
    "    discrete_results = await memory_client.search_long_term_memory(\n",
    "        text=\"student preferences and goals\",\n",
    "        user_id=UserId(eq=discrete_student_id),\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    discrete_memories = discrete_results.memories if discrete_results.memories else []\n",
    "\n",
    "    print(f\"\\nüìä DISCRETE Strategy Results:\")\n",
    "    print(f\"   Extracted {len(discrete_memories)} individual memories\\n\")\n",
    "\n",
    "    if discrete_memories:\n",
    "        for i, mem in enumerate(discrete_memories[:5], 1):\n",
    "            print(f\"   {i}. {mem.text[:100]}...\")\n",
    "    else:\n",
    "        print(\"   ‚è≥ No memories extracted yet (background processing may take time)\")\n",
    "        print(\"   Note: In production, extraction happens asynchronously\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available - skipping demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36519930b77297f3",
   "metadata": {},
   "source": [
    "#### **Demo: Summary Strategy**\n",
    "\n",
    "Now let's see how the SUMMARY strategy handles the same conversation differently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90262aaa860ae39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:50:25.619851Z",
     "iopub.status.busy": "2025-12-09T19:50:25.619638Z",
     "iopub.status.idle": "2025-12-09T19:50:28.245654Z",
     "shell.execute_reply": "2025-12-09T19:50:28.244452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Testing SUMMARY Strategy\n",
      "================================================================================\n",
      "Session ID: demo_summary_2aa10f68\n",
      "Student ID: student_summary_9eac115c\n",
      "\n",
      "14:50:25 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_summary_2aa10f68?user_id=student_summary_9eac115c&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:25 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_summary_2aa10f68?user_id=student_summary_9eac115c&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:25 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_summary_2aa10f68?user_id=student_summary_9eac115c&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversation stored with SUMMARY strategy\n",
      "   Messages: 6\n",
      "   Strategy: summary (max_summary_length=500)\n",
      "\n",
      "‚è≥ Waiting for automatic memory extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:28 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä SUMMARY Strategy Results:\n",
      "   Extracted 0 conversation summaries\n",
      "\n",
      "   ‚è≥ No summaries extracted yet (background processing may take time)\n",
      "   Note: In production, extraction happens asynchronously\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Create a test session with SUMMARY strategy\n",
    "    summary_session_id = f\"demo_summary_{uuid.uuid4().hex[:8]}\"\n",
    "    summary_student_id = f\"student_summary_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "    print(\"\\nüéØ Testing SUMMARY Strategy\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Session ID: {summary_session_id}\")\n",
    "    print(f\"Student ID: {summary_student_id}\\n\")\n",
    "\n",
    "    # Configure summary strategy\n",
    "    summary_strategy = MemoryStrategyConfig(\n",
    "        strategy=\"summary\", config={\"max_summary_length\": 500}\n",
    "    )\n",
    "\n",
    "    # Store the SAME conversation with summary strategy\n",
    "    messages = [\n",
    "        MemoryMessage(role=msg[\"role\"], content=msg[\"content\"])\n",
    "        for msg in advising_conversation\n",
    "    ]\n",
    "\n",
    "    # Get or create working memory\n",
    "    _, summary_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=summary_session_id, user_id=summary_student_id, model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Set the long-term memory strategy\n",
    "    summary_working_memory.long_term_memory_strategy = summary_strategy  # ‚Üê Key difference!\n",
    "\n",
    "    # Add messages to working memory\n",
    "    summary_working_memory.messages.extend(messages)\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=summary_session_id,\n",
    "        memory=summary_working_memory,\n",
    "        user_id=summary_student_id,\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Conversation stored with SUMMARY strategy\")\n",
    "    print(f\"   Messages: {len(messages)}\")\n",
    "    print(f\"   Strategy: summary (max_summary_length=500)\")\n",
    "    print(\"\\n‚è≥ Waiting for automatic memory extraction...\")\n",
    "\n",
    "    # Wait for background extraction\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "    # Search for extracted memories\n",
    "    summary_results = await memory_client.search_long_term_memory(\n",
    "        text=\"student preferences and goals\",\n",
    "        user_id=UserId(eq=summary_student_id),\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    summary_memories = summary_results.memories if summary_results.memories else []\n",
    "\n",
    "    print(f\"\\nüìä SUMMARY Strategy Results:\")\n",
    "    print(f\"   Extracted {len(summary_memories)} conversation summaries\\n\")\n",
    "\n",
    "    if summary_memories:\n",
    "        for i, mem in enumerate(summary_memories[:3], 1):\n",
    "            print(f\"   {i}. {mem.text}\\n\")\n",
    "    else:\n",
    "        print(\"   ‚è≥ No summaries extracted yet (background processing may take time)\")\n",
    "        print(\"   Note: In production, extraction happens asynchronously\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available - skipping demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefdf0ba5d5621b",
   "metadata": {},
   "source": [
    "#### **Comparison: When to Use Each Strategy**\n",
    "\n",
    "**Use DISCRETE Strategy (Default) when:**\n",
    "- ‚úÖ You want individual, searchable facts\n",
    "- ‚úÖ Facts should be independently retrievable\n",
    "- ‚úÖ Building knowledge graphs or fact databases\n",
    "- ‚úÖ Most general-purpose agent interactions\n",
    "\n",
    "**Example:** Course advisor agent (our use case)\n",
    "- \"User's major is Computer Science\"\n",
    "- \"User interested in machine learning\"\n",
    "- \"User prefers online courses\"\n",
    "- \"User wants to graduate Spring 2026\"\n",
    "\n",
    "**Use SUMMARY Strategy when:**\n",
    "- ‚úÖ Long conversations need to be preserved as context\n",
    "- ‚úÖ Meeting notes or session summaries\n",
    "- ‚úÖ Comprehensive context matters more than individual facts\n",
    "- ‚úÖ Reducing storage while preserving meaning\n",
    "\n",
    "**Example:** Academic advising session summary\n",
    "- \"Student discussed academic planning for Spring 2026 graduation, expressing strong interest in ML/AI courses. Prefers online format due to part-time work. Seeking tech startup internship. Recommended RU301, RU330, and RU401 based on AI career goals.\"\n",
    "\n",
    "**Use PREFERENCES Strategy when:**\n",
    "- ‚úÖ Building user profiles\n",
    "- ‚úÖ Personalization is primary goal\n",
    "- ‚úÖ User onboarding flows\n",
    "\n",
    "**Example:** User profile building\n",
    "- \"User prefers email over SMS notifications\"\n",
    "- \"User works best in morning hours\"\n",
    "- \"User prefers dark mode interfaces\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836d12f1ac55727",
   "metadata": {},
   "source": [
    "#### **Key Takeaway**\n",
    "\n",
    "**For this course, we use Discrete Strategy (default)** because:\n",
    "1. Course advising benefits from searchable individual facts\n",
    "2. Students ask specific questions (\"What are my prerequisites?\")\n",
    "3. Facts are independently useful (\"User completed RU101\")\n",
    "4. Balances detail with storage efficiency\n",
    "\n",
    "**In production**, you might use:\n",
    "- **Discrete** for most interactions\n",
    "- **Summary** for long consultation sessions\n",
    "- **Preferences** during onboarding\n",
    "- **Custom** for domain-specific needs (legal, medical, technical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e7ad698521ca8",
   "metadata": {},
   "source": [
    "#### **Configuration Reference**\n",
    "\n",
    "**Discrete Strategy (Default - No Config Needed):**\n",
    "```python\n",
    "# This is the default - no configuration required\n",
    "_, working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id, user_id=user_id, model_name=\"gpt-4o\"\n",
    ")\n",
    "working_memory.messages.extend(messages)\n",
    "await memory_client.put_working_memory(\n",
    "    session_id=session_id,\n",
    "    memory=working_memory,\n",
    "    user_id=user_id,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Summary Strategy:**\n",
    "```python\n",
    "from agent_memory_client.models import MemoryStrategyConfig\n",
    "\n",
    "summary_strategy = MemoryStrategyConfig(\n",
    "    strategy=\"summary\",\n",
    "    config={\"max_summary_length\": 500}\n",
    ")\n",
    "\n",
    "_, working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id, user_id=user_id, model_name=\"gpt-4o\"\n",
    ")\n",
    "working_memory.long_term_memory_strategy = summary_strategy\n",
    "working_memory.messages.extend(messages)\n",
    "await memory_client.put_working_memory(\n",
    "    session_id=session_id,\n",
    "    memory=working_memory,\n",
    "    user_id=user_id,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Preferences Strategy:**\n",
    "```python\n",
    "preferences_strategy = MemoryStrategyConfig(\n",
    "    strategy=\"preferences\",\n",
    "    config={}\n",
    ")\n",
    "\n",
    "_, working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id, user_id=user_id, model_name=\"gpt-4o\"\n",
    ")\n",
    "working_memory.long_term_memory_strategy = preferences_strategy\n",
    "working_memory.messages.extend(messages)\n",
    "await memory_client.put_working_memory(\n",
    "    session_id=session_id,\n",
    "    memory=working_memory,\n",
    "    user_id=user_id,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd903461d805026",
   "metadata": {},
   "source": [
    "#### **üìö Learn More**\n",
    "\n",
    "For complete documentation and advanced configuration:\n",
    "- [Memory Extraction Strategies Documentation](https://redis.github.io/agent-memory-server/memory-extraction-strategies/)\n",
    "- [Working Memory Configuration](https://redis.github.io/agent-memory-server/working-memory/)\n",
    "- [Long-term Memory Best Practices](https://redis.github.io/agent-memory-server/long-term-memory/)\n",
    "\n",
    "**Next:** In Section 4, we'll see how agents use these strategies in production workflows.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. ‚úÖ **Built** memory-enhanced RAG system\n",
    "2. ‚úÖ **Integrated** all four context types\n",
    "3. ‚úÖ **Demonstrated** benefits of memory\n",
    "4. ‚úÖ **Prepared** for LangGraph conversion\n",
    "\n",
    "### **Key Concepts:**\n",
    "\n",
    "- **Working Memory** - Session-scoped conversation history\n",
    "- **Long-term Memory** - User-scoped persistent facts\n",
    "- **Context Assembly** - Combining all four context types\n",
    "- **Reference Resolution** - Resolving pronouns and references\n",
    "- **Stateful Conversations** - Natural, continuous dialogue\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "1. Complete practice exercises\n",
    "2. Experiment with different queries\n",
    "3. Move to Part 2 (LangGraph agent conversion)\n",
    "4. Prepare for Section 4 (tools and advanced agents)\n",
    "\n",
    "**üéâ Congratulations!** You've built a complete memory-enhanced RAG system!\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- **Section 1:** Four Context Types\n",
    "- **Section 2:** RAG Fundamentals\n",
    "- **Section 3 (Notebook 1):** Memory Fundamentals\n",
    "- **Section 3 (Notebook 3):** LangGraph Agent Conversion (Next)\n",
    "- **Section 4:** Tools and Advanced Agents\n",
    "\n",
    "**Agent Memory Server:**\n",
    "- GitHub: `reference-agent/`\n",
    "- Documentation: See README.md\n",
    "- API Client: `agent-memory-client`\n",
    "\n",
    "**LangChain:**\n",
    "- Documentation: https://python.langchain.com/\n",
    "- LangGraph: https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "---\n",
    "\n",
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "**Redis University - Context Engineering Course**\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [Agent Memory Server Documentation](https://github.com/redis/agent-memory-server) - Production-ready memory management\n",
    "- [Agent Memory Client](https://pypi.org/project/agent-memory-client/) - Python client for Agent Memory Server\n",
    "- [RedisVL Documentation](https://redisvl.com/) - Redis Vector Library\n",
    "- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401) - Original RAG research\n",
    "- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/) - Building RAG systems\n",
    "- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/) - Building agents with LangGraph\n",
    "- [Agent Architectures](https://python.langchain.com/docs/modules/agents/) - Different agent patterns\n",
    "- [ReAct: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629) - Reasoning + acting in LLMs\n",
    "- [Anthropic's Guide to Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) - Agent design patterns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68f27c65d3b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
